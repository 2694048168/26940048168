<!DOCTYPE html><html class="theme-next pisces" lang="zh-CN"><head><meta charset="UTF-8"><meta name="generator" content="Hexo 3.9.0"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=2"><meta name="theme-color" content="#222"><meta http-equiv="X-UA-Compatible" content="IE=edge"><link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=7.3.0"><link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=7.3.0"><link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=7.3.0"><link rel="mask-icon" href="/images/logo.svg?v=7.3.0" color="#222"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><meta name="google-site-verification" content=""><meta name="baidu-site-verification" content="8gbQ8pd371"><link rel="stylesheet" href="/css/main.css?v=7.3.0"><link rel="stylesheet" href="//cdn.jsdelivr.net/npm/font-awesome@4/css/font-awesome.min.css"><link rel="stylesheet" href="//cdn.jsdelivr.net/gh/theme-next/theme-next-needmoreshare2@1/needsharebutton.min.css"><script src="//cdn.jsdelivr.net/npm/pace-js@1/pace.min.js"></script><link rel="stylesheet" href="//cdn.jsdelivr.net/npm/pace-js@1/themes/blue/pace-theme-minimal.css"><script id="hexo-configurations">var NexT=window.NexT||{},CONFIG={root:"/",scheme:"Pisces",version:"7.3.0",exturl:!0,sidebar:{position:"right",display:"post",offset:12,onmobile:!1},back2top:{enable:!0,sidebar:!0,scrollpercent:!0},save_scroll:!0,copycode:{enable:!0,show_result:!1,style:null},fancybox:!1,mediumzoom:!1,lazyload:!1,pangu:!1,algolia:{applicationID:"",apiKey:"",indexName:"",hits:{per_page:10},labels:{input_placeholder:"Search for Posts",hits_empty:"We didn't find any results for the search: ${query}",hits_stats:"${hits} results found in ${time} ms"}},localsearch:{enable:!0,trigger:"auto",top_n_per_article:-1,unescape:!1,preload:!0},path:"search.xml",motion:{enable:!1,async:!1,transition:{post_block:"fadeIn",post_header:"slideDownIn",post_body:"slideDownIn",coll_header:"slideLeftIn",sidebar:"slideUpIn"}},translation:{copy_button:"复制",copy_success:"复制成功",copy_failure:"复制失败"}}</script><meta name="description" content="实验目的&amp;emsp;&amp;emsp;利用搭建好的大数据平台 Hadoop，对 HDFS 中的文本文件进行处理，采用 Hadoop Steaming 方式，使用 Python 语言实现英文单词的统计功能，并输出单词统计结果。   实验内容&amp;emsp;&amp;emsp;将附件”COPYING_LGPL.txt”上传 Hadoop 集群的 HDFS 中，采用 Hadoop Steaming方式，使用 Python"><meta name="keywords" content="Hadoop"><meta property="og:type" content="article"><meta property="og:title" content="Hadoop之wordcount实例-MapReduce程序"><meta property="og:url" content="https://2694048168.github.io/Hadoop之wordcount实例-MapReduce程序/index.html"><meta property="og:site_name" content="云主宰苍穹"><meta property="og:description" content="实验目的&amp;emsp;&amp;emsp;利用搭建好的大数据平台 Hadoop，对 HDFS 中的文本文件进行处理，采用 Hadoop Steaming 方式，使用 Python 语言实现英文单词的统计功能，并输出单词统计结果。   实验内容&amp;emsp;&amp;emsp;将附件”COPYING_LGPL.txt”上传 Hadoop 集群的 HDFS 中，采用 Hadoop Steaming方式，使用 Python"><meta property="og:locale" content="zh-CN"><meta property="og:image" content="https://2694048168.github.io/images/MapReduce-wordcount.png"><meta property="og:image" content="https://2694048168.github.io/images/MapReduce.png"><meta property="og:image" content="https://2694048168.github.io/images/WordCount%E7%9A%84%E6%B5%81%E7%A8%8B%E5%88%86%E6%9E%90.png"><meta property="og:updated_time" content="2020-02-19T08:02:16.735Z"><meta name="twitter:card" content="summary"><meta name="twitter:title" content="Hadoop之wordcount实例-MapReduce程序"><meta name="twitter:description" content="实验目的&amp;emsp;&amp;emsp;利用搭建好的大数据平台 Hadoop，对 HDFS 中的文本文件进行处理，采用 Hadoop Steaming 方式，使用 Python 语言实现英文单词的统计功能，并输出单词统计结果。   实验内容&amp;emsp;&amp;emsp;将附件”COPYING_LGPL.txt”上传 Hadoop 集群的 HDFS 中，采用 Hadoop Steaming方式，使用 Python"><meta name="twitter:image" content="https://2694048168.github.io/images/MapReduce-wordcount.png"><link rel="alternate" href="/atom.xml" title="云主宰苍穹" type="application/atom+xml"><link rel="canonical" href="https://2694048168.github.io/Hadoop之wordcount实例-MapReduce程序/"><script id="page-configurations">CONFIG.page={sidebar:"",isHome:!1,isPost:!0,isPage:!1,isArchive:!1}</script><title>Hadoop之wordcount实例-MapReduce程序 | 云主宰苍穹</title><noscript><style>.sidebar-inner,.use-motion .brand,.use-motion .collection-title,.use-motion .comments,.use-motion .menu-item,.use-motion .motion-element,.use-motion .pagination,.use-motion .post-block,.use-motion .post-body,.use-motion .post-header{opacity:initial}.use-motion .logo,.use-motion .site-subtitle,.use-motion .site-title{opacity:initial;top:initial}.use-motion .logo-line-before i{left:initial}.use-motion .logo-line-after i{right:initial}</style></noscript></head><body itemscope itemtype="http://schema.org/WebPage" lang="zh-CN"><div class="container sidebar-position-right"><div class="headband"></div><header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="header-inner"><div class="site-brand-wrapper"><div class="site-meta"><div class="custom-logo-site-title"><a href="/" class="brand" rel="start"><span class="logo-line-before"><i></i></span> <span class="site-title">云主宰苍穹</span><span class="logo-line-after"><i></i></span></a></div><h1 class="site-subtitle" itemprop="description">Stay Hungry, Stay Foolish.</h1></div><div class="site-nav-toggle"> <button aria-label="切换导航栏"><span class="btn-bar"></span><span class="btn-bar"></span><span class="btn-bar"></span></button></div></div><nav class="site-nav"><ul id="menu" class="menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i><br>首页</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="menu-item-icon fa fa-fw fa-user"></i><br>关于</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="menu-item-icon fa fa-fw fa-tags"></i><br>标签</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="menu-item-icon fa fa-fw fa-th"></i><br>分类</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i><br>归档</a></li><li class="menu-item menu-item-commonweal"><a href="/404/" rel="section"><i class="menu-item-icon fa fa-fw fa-heartbeat"></i><br>公益 404</a></li><li class="menu-item menu-item-search"><a href="javascript:;" class="popup-trigger"><i class="menu-item-icon fa fa-search fa-fw"></i><br>搜索</a></li></ul><div class="site-search"><div class="popup search-popup local-search-popup"><div class="local-search-header clearfix"><span class="search-icon"><i class="fa fa-search"></i></span><span class="popup-btn-close"><i class="fa fa-times-circle"></i></span><div class="local-search-input-wrapper"> <input autocomplete="off" placeholder="搜索..." spellcheck="false" type="text" id="local-search-input"></div></div><div id="local-search-result"></div></div></div></nav></div></header> <span class="exturl github-corner" data-url="aHR0cHM6Ly9naXRodWIuY29tLzI2OTQwNDgxNjg=" title="Follow me on GitHub" aria-label="Follow me on GitHub"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0 0 115 115 130 115 142 142 250 250 250 0Z"></path><path d="M128.3 109C113.8 99.7 119 89.6 119 89.6 122 82.7 120.5 78.6 120.5 78.6 119.2 72 123.4 76.3 123.4 76.3 127.3 80.9 125.5 87.3 125.5 87.3 122.9 97.6 130.6 101.9 134.4 103.2" fill="currentColor" style="transform-origin:130px 106px" class="octo-arm"></path><path d="M115 115C114.9 115.1 118.7 116.5 119.8 115.4L133.7 101.6C136.9 99.2 139.9 98.4 142.2 98.6 133.8 88 127.5 74.4 143.8 58 148.5 53.4 154 51.2 159.7 51 160.3 49.4 163.2 43.6 171.4 40.1 171.4 40.1 176.1 42.5 178.8 56.2 183.1 58.6 187.2 61.8 190.9 65.4 194.5 69 197.7 73.2 200.1 77.6 213.8 80.2 216.3 84.9 216.3 84.9 212.7 93.1 206.9 96 205.4 96.6 205.1 102.4 203 107.8 198.3 112.5 181.9 128.9 168.3 122.5 157.7 114.1 157.9 116.9 156.7 120.9 152.7 124.9L141 136.5C139.8 137.7 141.6 141.9 141.8 141.8Z" fill="currentColor" class="octo-body"></path></svg></span><main id="main" class="main"><div class="main-inner"><div class="content-wrap"><div id="content" class="content page-post-detail"><div id="posts" class="posts-expand"><article class="post post-type-normal" itemscope itemtype="http://schema.org/Article"><div class="post-block"><link itemprop="mainEntityOfPage" href="https://2694048168.github.io/Hadoop之wordcount实例-MapReduce程序/"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="name" content="云主宰苍穹"><meta itemprop="description" content="云主宰苍穹,物联网,计算机视觉、图形处理、深度学习、人工智能、机器学习"><meta itemprop="image" content="/images/liwei.jpg"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="云主宰苍穹"></span><header class="post-header"><h2 class="post-title" itemprop="name headline">Hadoop之wordcount实例-MapReduce程序</h2><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="fa fa-calendar-o"></i></span> <span class="post-meta-item-text">发表于</span> <time title="创建时间：2019-08-11 23:24:08" itemprop="dateCreated datePublished" datetime="2019-08-11T23:24:08+08:00">2019-08-11</time></span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="fa fa-calendar-check-o"></i></span> <span class="post-meta-item-text">更新于</span> <time title="修改时间：2020-02-19 16:02:16" itemprop="dateModified" datetime="2020-02-19T16:02:16+08:00">2020-02-19</time></span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="fa fa-folder-o"></i></span> <span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Hadoop/" itemprop="url" rel="index"><span itemprop="name">Hadoop</span></a></span></span><br><span class="post-meta-item" title="本文字数"><span class="post-meta-item-icon"><i class="fa fa-file-word-o"></i></span> <span class="post-meta-item-text">本文字数：</span> <span>6.6k</span></span><span class="post-meta-item" title="阅读时长"><span class="post-meta-item-icon"><i class="fa fa-clock-o"></i></span> <span class="post-meta-item-text">阅读时长 &asymp;</span> <span>6 分钟</span></span></div></header><div class="post-body" itemprop="articleBody"><h4 id="实验目的"><a href="#实验目的" class="headerlink" title="实验目的"></a>实验目的</h4><p>&emsp;&emsp;利用搭建好的大数据平台 Hadoop，对 HDFS 中的文本文件进行处理，采用 Hadoop Steaming 方式，使用 Python 语言实现英文单词的统计功能，并输出单词统计结果。</p><p><img src="/images/MapReduce-wordcount.png" alt="self"></p><h4 id="实验内容"><a href="#实验内容" class="headerlink" title="实验内容"></a>实验内容</h4><p>&emsp;&emsp;将附件”COPYING_LGPL.txt”上传 Hadoop 集群的 HDFS 中，采用 Hadoop Steaming方式，使用 Python语言实现字词统计功能，输出字词统计结果，即实现文本单词的词频统计功能。要求将实验原理，过程，代码分析，结果分析记录在实验报告中。</p><h4 id="实验步骤"><a href="#实验步骤" class="headerlink" title="实验步骤"></a>实验步骤</h4><ul><li>实验原理：<br>&emsp;&emsp;简述 MapReduce 的 Data Flow 如下图所示，原始数据经过 mapper 处理，再进行 partition 和 sort，到达 reducer，输出最后结果。Hadoop 的MapReduce处理框架，一般的编程模型如下图所示， 将一个业务拆分为 Mapper 和 Reducer 两个阶段。使用 Python 语言背后的“技巧”是我们将使用 Hadoop Streaming API 来帮助我们通过 STDIN（标准输入）和 STDOUT（标准输出）在 Map 和 Reduce 代码之间传递数据。我们将简单地使用 Python 的 sys.stdin 来读取输入数据并将我们自己的输出打印到 sys.stdout。这就是我们需要做的全部，因为 Hadoop Streaming 会帮助我们处理其他所有事情！<br>&emsp;&emsp;使用 Python 来调用 Hadoop Streaming API，其基本流程如下图。用 Python 写MapReduce 还需要了解 HadoopStreaming ，在 Apache 的 Hadoop 官网可以查看HadoopStreaming 的运行机制，简单来说就是 HadoopStreaming 是可运行特殊脚本的MapReduce 作业的工具 ，使用格式如下：<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">hadoop jar \</span><br><span class="line">/home/hadoop/app/hadoop-2.7.7/share/hadoop/tools/lib/hadoopstreaming-2.7.7.jar\</span><br><span class="line">-files /home/hadoop/mapper.py -mapper /home/hadoop/mapper.py \</span><br><span class="line">-files /home/hadoop/reducer.py -reducer /home/hadoop/reducer.py \</span><br><span class="line">-input /wordcount/COPYING_LGPL.txt -output /wordcount/output</span><br></pre></td></tr></table></figure></li></ul><p><img src="/images/MapReduce.png" alt="self"></p><ul><li>实验过程<br>&emsp;&emsp;将本地物理机的测试文本文件 COPYING_LGPL.txt 上传到虚拟主机 Master 上，在从 Master 上传到 Hadoop 集群的 HDFS 文件系统上/wordcount/COPYING_LGPL.txt。<br>&emsp;&emsp;使用 Python 编写 MapReduce 程序，分别根据实现原理编写 Mapper 程序和Reducer 程序，使用 Vim 编写 Mapper 和 Reducer 脚本，并使两个脚本具有可执行权限，及使用命令： chmod +x mapper.py reducer.py。<br>&emsp;&emsp;使用 HadoopStreaming 命令来运行自己编写的程序，其命令如下：<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">hadoop jar \</span><br><span class="line">/home/hadoop/app/hadoop-2.7.7/share/hadoop/tools/lib/hadoopstreaming-2.7.7.jar \</span><br><span class="line">-files /usr/bin/mapper.py \</span><br><span class="line">-files /usr/bin/reducer.py \</span><br><span class="line">-mapper "python /usr/bin/mapper.py" \</span><br><span class="line">-reducer "python /usr/bin/reducer.py" \</span><br><span class="line">-input /wordcount/input/COPYING_LGPL.txt \</span><br><span class="line">-output /wordcount/output</span><br></pre></td></tr></table></figure></li></ul><p>&emsp;&emsp;可以编写一个 shell 脚本命令，来运行 HadoopStreaming 命令，这样在 shell 脚本<br>中首先使用删掉输出目录文件的命令（hdfs dfs -rm -r -f /wordcount/output），防止多次测试出错， 同时每次测试只需要运行 shell 脚本即可，这样在做实验的时候更加方便操作，而不用每次都敲命令。</p><h3 id="对HadoopStreaming-命令进行解释："><a href="#对HadoopStreaming-命令进行解释：" class="headerlink" title="对HadoopStreaming 命令进行解释："></a>对HadoopStreaming 命令进行解释：</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">hadoop jar    #指调用hadoop jar包的命令</span><br><span class="line">/home/hadoop/app/hadoop-2.7.7/share/hadoop/tools/lib/hadoopstreaming-2.7.7.jar              #调用HadoopStreaming 命令的jar包</span><br><span class="line">-files /usr/bin/mapper.py     #提交的作业的路径</span><br><span class="line">-files /usr/bin/reducer.py    #提交的作业的路径</span><br><span class="line">-mapper "python /usr/bin/mapper.py"     #mapper程序的解释器python以及程序路径</span><br><span class="line">-reducer "python /usr/bin/reducer.py"    #reducer程序的解释器python以及程序路径</span><br><span class="line">-input /wordcount/input/COPYING_LGPL.txt     #HDFS上的输入文件的路径</span><br><span class="line">-output /wordcount/output     #HDFS上的输出文件的路径</span><br></pre></td></tr></table></figure><p>&emsp;&emsp;HadoopStreaming API 的调用接口说明： 调用 python 中的标准输入流 sys.stdin ，MAP 具体过程是， HadoopStream 每次从 input 文件读取一行数据，然后传到 sys.stdin中，运行 payhon 的 map 函数脚本，然后用 print 输出回 HadoopStreeam。 REDUCE 过程一样。所以 M 和 R 函数的输入格式为 for line in sys.stdin:line=line.strip。Mapper 过程如下： 第一步，在每个节点上运行我们编写的 map 程序 ，即就是 调用标准输入流 ， 读取文本内容，对文本内容分词，形成一个列表，读取列表中每一个元素的值 ， Map 函数输出， key 为 word，下一步将进行 shuffle 过程，将按照key 排序，输出，这两步为 map 阶段工作为，在本地节点进行，第二步， hadoop 框架，把我们运行的结果，进入 shuffle 过程，每个节点对 key 单独进行排序，然后输出。Reducer 过程：第一步， merge 过程，把所有节点汇总到一个节点，合并并且按照 key排序。第二步，运行 reducer 函数。</p><p><img src="/images/WordCount%E7%9A%84%E6%B5%81%E7%A8%8B%E5%88%86%E6%9E%90.png" alt="self"></p><h3 id="Python源代码"><a href="#Python源代码" class="headerlink" title="Python源代码"></a>Python源代码</h3><p>&emsp;&emsp;分析 WordCount 程序实例的实现原理步骤，具体 Python 代码如下源代码所示，前面是简要原理的实现，后面是使用 Python 的迭代器和生成器升级 mapper 程序和 reducer 程序。<br><strong>MapReduce 的 WordCount 简要原理 Python 实现源代码如下</strong><br><strong>Mapper阶段</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="comment"># filename:mapper.py</span></span><br><span class="line"><span class="comment"># date:2019-06-18</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"></span><br><span class="line"><span class="comment"># input comes from STDIN (standard input)</span></span><br><span class="line"><span class="keyword">for</span> line <span class="keyword">in</span> sys.stdin:</span><br><span class="line">    <span class="comment"># remove leading and trailing whitespace</span></span><br><span class="line">    line = line.strip()</span><br><span class="line">    <span class="comment"># split the line into words</span></span><br><span class="line">    words = line.split()</span><br><span class="line">    <span class="comment"># increase counters</span></span><br><span class="line">    <span class="keyword">for</span> word <span class="keyword">in</span> words:</span><br><span class="line">        <span class="comment"># write the results to STDOUT (standard output);</span></span><br><span class="line">        <span class="comment"># what we output here will be the input for the</span></span><br><span class="line">        <span class="comment"># Reduce step, i.e. the input for reducer.py</span></span><br><span class="line">        <span class="comment"># tab-delimited; the trivial word count is 1</span></span><br><span class="line">        <span class="keyword">print</span> <span class="string">'%s\t%s'</span> % (word, <span class="number">1</span>)</span><br></pre></td></tr></table></figure><p><strong>Reducer阶段</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="comment"># filename:reducer.py</span></span><br><span class="line"><span class="comment"># date:2019-06-18</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> operator <span class="keyword">import</span> itemgetter</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"></span><br><span class="line">current_word = <span class="literal">None</span></span><br><span class="line">current_count = <span class="number">0</span></span><br><span class="line">word = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># input comes from STDIN</span></span><br><span class="line"><span class="keyword">for</span> line <span class="keyword">in</span> sys.stdin:</span><br><span class="line">    <span class="comment"># remove leading and trailing whitespace</span></span><br><span class="line">    line = line.strip()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># parse the input we got from mapper.py</span></span><br><span class="line">    word, count = line.split(<span class="string">'\t'</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># convert count (currently a string) to int</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        count = int(count)</span><br><span class="line">    <span class="keyword">except</span> ValueError:</span><br><span class="line">        <span class="comment"># count was not a number, so silently</span></span><br><span class="line">        <span class="comment"># ignore/discard this line</span></span><br><span class="line">        <span class="keyword">continue</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># this IF-switch only works because Hadoop sorts map output</span></span><br><span class="line">    <span class="comment"># by key (here: word) before it is passed to the reducer</span></span><br><span class="line">    <span class="keyword">if</span> current_word == word:</span><br><span class="line">        current_count += count</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">if</span> current_word:</span><br><span class="line">            <span class="comment"># write result to STDOUT</span></span><br><span class="line">            <span class="keyword">print</span> <span class="string">'%s\t%s'</span> % (current_word, current_count)</span><br><span class="line">        current_count = count</span><br><span class="line">        current_word = word</span><br><span class="line"></span><br><span class="line"><span class="comment"># do not forget to output the last word if needed!</span></span><br><span class="line"><span class="keyword">if</span> current_word == word:</span><br><span class="line">    <span class="keyword">print</span> <span class="string">'%s\t%s'</span> % (current_word, current_count)</span><br></pre></td></tr></table></figure><p><strong>MapReduce 的 WordCount 简要原理 Python 的迭代器与生成器实现源代码如下：</strong><br><strong>Mapper阶段</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="comment"># filename:mapper.py</span></span><br><span class="line"><span class="comment"># date:2019-06-18</span></span><br><span class="line"><span class="comment"># detail:A more advanced Mapper, using Python iterators and generators.</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">read_input</span><span class="params">(file)</span>:</span></span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> file:</span><br><span class="line">        <span class="comment"># split the line into words</span></span><br><span class="line">        <span class="keyword">yield</span> line.split()</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">(separator=<span class="string">'\t'</span>)</span>:</span></span><br><span class="line">    <span class="comment"># input comes from STDIN (standard input)</span></span><br><span class="line">    data = read_input(sys.stdin)</span><br><span class="line">    <span class="keyword">for</span> words <span class="keyword">in</span> data:</span><br><span class="line">        <span class="comment"># write the results to STDOUT (standard output);</span></span><br><span class="line">        <span class="comment"># what we output here will be the input for the</span></span><br><span class="line">        <span class="comment"># Reduce step, i.e. the input for reducer.py</span></span><br><span class="line">        <span class="comment">#</span></span><br><span class="line">        <span class="comment"># tab-delimited; the trivial word count is 1</span></span><br><span class="line">        <span class="keyword">for</span> word <span class="keyword">in</span> words:</span><br><span class="line">            <span class="keyword">print</span> <span class="string">'%s%s%d'</span> % (word, separator, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure><p><strong>Reducer阶段</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="comment"># filename:reducer.py</span></span><br><span class="line"><span class="comment"># date:2019-06-18</span></span><br><span class="line"><span class="comment"># detail:A more advanced Reducer, using Python iterators and generators.</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> itertools <span class="keyword">import</span> groupby</span><br><span class="line"><span class="keyword">from</span> operator <span class="keyword">import</span> itemgetter</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">read_mapper_output</span><span class="params">(file, separator=<span class="string">'\t'</span>)</span>:</span></span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> file:</span><br><span class="line">        <span class="keyword">yield</span> line.rstrip().split(separator, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">(separator=<span class="string">'\t'</span>)</span>:</span></span><br><span class="line">    <span class="comment"># input comes from STDIN (standard input)</span></span><br><span class="line">    data = read_mapper_output(sys.stdin, separator=separator)</span><br><span class="line">    <span class="comment"># groupby groups multiple word-count pairs by word,</span></span><br><span class="line">    <span class="comment"># and creates an iterator that returns consecutive keys and their group:</span></span><br><span class="line">    <span class="comment">#   current_word - string containing a word (the key)</span></span><br><span class="line">    <span class="comment">#   group - iterator yielding all ["&amp;lt;current_word&amp;gt;", "&amp;lt;count&amp;gt;"] items</span></span><br><span class="line">    <span class="keyword">for</span> current_word, group <span class="keyword">in</span> groupby(data, itemgetter(<span class="number">0</span>)):</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            total_count = sum(int(count) <span class="keyword">for</span> current_word, count <span class="keyword">in</span> group)</span><br><span class="line">            <span class="keyword">print</span> <span class="string">"%s%s%d"</span> % (current_word, separator, total_count)</span><br><span class="line">        <span class="keyword">except</span> ValueError:</span><br><span class="line">            <span class="comment"># count was not a number, so silently discard this item</span></span><br><span class="line">            <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure></div><div class="popular-posts-header">相关文章</div><ul class="popular-posts"><li class="popular-posts-item"><div class="popular-posts-title"><a href="\Hadoop的高可用HA部署\" rel="bookmark">Hadoop的高可用HA部署</a></div></li><li class="popular-posts-item"><div class="popular-posts-title"><a href="\大数据框架Hadoop的前世今生\" rel="bookmark">大数据框架Hadoop的前世今生</a></div></li></ul><div><div><div style="text-align:center;color:#ccc;font-size:14px">-------------本文结束<i class="fa fa-paw"></i>感谢您的阅读，欢迎分享！-------------</div></div></div><div><div class="my_post_copyright"><script src="//cdn.bootcss.com/clipboard.js/1.5.10/clipboard.min.js"></script><script type="text/javascript" src="http://jslibs.wuxubj.cn/sweetalert_mini/jquery-1.7.1.min.js"></script><script src="http://jslibs.wuxubj.cn/sweetalert_mini/sweetalert.min.js"></script><link rel="stylesheet" type="text/css" href="http://jslibs.wuxubj.cn/sweetalert_mini/sweetalert.mini.css"><p><span>本文标题:</span>Hadoop之wordcount实例-MapReduce程序</p><p><span>文章作者:</span>云主宰苍穹</p><p><span>原始链接:</span><a href="/Hadoop之wordcount实例-MapReduce程序/" title="Hadoop之wordcount实例-MapReduce程序">https://2694048168.github.io/Hadoop之wordcount实例-MapReduce程序/</a><span class="copy-path" title="点击复制文章链接"><i class="fa fa-clipboard" data-clipboard-text="https://2694048168.github.io/Hadoop之wordcount实例-MapReduce程序/" aria-label="复制成功！"></i></span></p><p><span>许可协议:</span><i class="fa fa-creative-commons"></i> <a rel="license" href="https://creativecommons.org/licenses/by-nc-nd/4.0/" target="_blank" title="Attribution-NonCommercial-NoDerivatives 4.0 International (CC BY-NC-ND 4.0)">署名-非商业性使用-禁止演绎 4.0 国际</a> 转载请保留原文链接及作者。</p></div><script>var clipboard=new Clipboard(".fa-clipboard");clipboard.on("success",$(function(){$(".fa-clipboard").click(function(){swal({title:"",text:"复制成功",html:!1,timer:500,showConfirmButton:!1})})}))</script></div><div id="reward-container"><div></div> <button id="reward-button" disable="enable" onclick="var qr = document.getElementById(&quot;qr&quot;); qr.style.display = (qr.style.display === 'none') ? 'block' : 'none';"> 打赏</button><div id="qr" style="display:none"><div style="display:inline-block"> <img src="/images/wechatpay.png" alt="云主宰苍穹 微信支付"><p>微信支付</p></div><div style="display:inline-block"> <img src="/images/alipay.png" alt="云主宰苍穹 支付宝"><p>支付宝</p></div></div></div><footer class="post-footer"><div class="post-tags"> <a href="/tags/Hadoop/" rel="tag"># Hadoop</a></div><div class="post-widgets"><div class="social-share"><div id="needsharebutton-postbottom"><span class="btn"><i class="fa fa-share-alt" aria-hidden="true"></i></span></div></div></div><div class="post-nav"><div class="post-nav-next post-nav-item"><a href="/Hadoop分布式环境搭建/" rel="next" title="Hadoop分布式环境搭建"><i class="fa fa-chevron-left"></i> Hadoop分布式环境搭建</a></div><span class="post-nav-divider"></span><div class="post-nav-prev post-nav-item"> <a href="/大数据框架Hadoop的前世今生/" rel="prev" title="大数据框架Hadoop的前世今生">大数据框架Hadoop的前世今生<i class="fa fa-chevron-right"></i></a></div></div></footer></div></article></div></div><div class="comments" id="gitalk-container"></div></div><div class="sidebar-toggle"><div class="sidebar-toggle-line-wrap"><span class="sidebar-toggle-line sidebar-toggle-line-first"></span><span class="sidebar-toggle-line sidebar-toggle-line-middle"></span><span class="sidebar-toggle-line sidebar-toggle-line-last"></span></div></div><aside id="sidebar" class="sidebar"><div class="sidebar-inner"><ul class="sidebar-nav motion-element"><li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap"> 文章目录</li><li class="sidebar-nav-overview" data-target="site-overview-wrap"> 站点概览</li></ul><div class="site-overview-wrap sidebar-panel"><div class="site-overview"><div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person"> <img class="site-author-image" itemprop="image" src="/images/liwei.jpg" alt="云主宰苍穹"><p class="site-author-name" itemprop="name">云主宰苍穹</p><div class="site-description motion-element" itemprop="description">云主宰苍穹,物联网,计算机视觉、图形处理、深度学习、人工智能、机器学习</div></div><nav class="site-state motion-element"><div class="site-state-item site-state-posts"> <a href="/archives/"><span class="site-state-item-count">43</span> <span class="site-state-item-name">日志</span></a></div><div class="site-state-item site-state-categories"> <a href="/categories/"><span class="site-state-item-count">10</span> <span class="site-state-item-name">分类</span></a></div><div class="site-state-item site-state-tags"> <a href="/tags/"><span class="site-state-item-count">31</span> <span class="site-state-item-name">标签</span></a></div></nav><div class="feed-link motion-element"><a href="/atom.xml" rel="alternate"><i class="fa fa-rss"></i> RSS</a></div><div class="links-of-author motion-element"><span class="links-of-author-item"><span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tLzI2OTQwNDgxNjgv" title="GitHub &rarr; https://github.com/2694048168/"><i class="fa fa-fw fa-github"></i> GitHub</span></span><span class="links-of-author-item"><span class="exturl" data-url="aHR0cHM6Ly93ZWliby5jb20vNTk2MzU1MzMwOS8=" title="Weibo &rarr; https://weibo.com/5963553309/"><i class="fa fa-fw fa-weibo"></i> Weibo</span></span></div><div class="links-of-blogroll motion-element links-of-blogroll-block"><div class="links-of-blogroll-title"><i class="fa fa-fw fa-link"></i> Links</div><ul class="links-of-blogroll-list"><li class="links-of-blogroll-item"> <span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tLzI2OTQwNDgxNjgv" title="https://github.com/2694048168/">github</span></li><li class="links-of-blogroll-item"> <span class="exturl" data-url="aHR0cHM6Ly9naXRlZS5jb20vd2VpbGlfeXp6Y3Ev" title="https://gitee.com/weili_yzzcq/">gitee</span></li><li class="links-of-blogroll-item"> <span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80Njc4MjIxOC8=" title="https://blog.csdn.net/weixin_46782218/">csdn</span></li><li class="links-of-blogroll-item"> <span class="exturl" data-url="aHR0cHM6Ly9zcGFjZS5iaWxpYmlsaS5jb20vMzYyOTAxODc3Lw==" title="https://space.bilibili.com/362901877/">bilibili</span></li><li class="links-of-blogroll-item"> <span class="exturl" data-url="aHR0cHM6Ly9hdXRob3IuYmFpZHUuY29tL2hvbWUvMTYyMzY0NDY2NjE2MjYwMS8=" title="https://author.baidu.com/home/1623644666162601/">百家号-专注物联网知识</span></li><li class="links-of-blogroll-item"> <span class="exturl" data-url="aHR0cHM6Ly93d3cudG91dGlhby5jb20vYy91c2VyLzIwMDk1NDExMTY2OTkwNzkv" title="https://www.toutiao.com/c/user/2009541116699079/">头条号-专注物联网知识</span></li></ul></div></div></div><div class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active"><div class="post-toc"><div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-4"><a class="nav-link" href="#实验目的"><span class="nav-number">1.</span> <span class="nav-text">实验目的</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#实验内容"><span class="nav-number">2.</span> <span class="nav-text">实验内容</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#实验步骤"><span class="nav-number">3.</span> <span class="nav-text">实验步骤</span></a></li></ol><li class="nav-item nav-level-3"><a class="nav-link" href="#对HadoopStreaming-命令进行解释："><span class="nav-number"></span> <span class="nav-text">对HadoopStreaming 命令进行解释：</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Python源代码"><span class="nav-number"></span> <span class="nav-text">Python源代码</span></a></li></div></div></div><div class="back-to-top motion-element"><i class="fa fa-arrow-up"></i> <span id="scrollpercent"><span>0</span>%</span></div></div></aside><div id="sidebar-dimmer"></div></div></main><footer id="footer" class="footer"><div class="footer-inner"><div class="copyright">&copy; 2019 – <span itemprop="copyrightYear">2020</span><span class="with-love" id="animate"><i class="fa fa-heartbeat"></i></span> <span class="author" itemprop="copyrightHolder">云主宰苍穹</span> <span class="post-meta-divider">|</span><span class="post-meta-item-icon"><i class="fa fa-area-chart"></i></span> <span class="post-meta-item-text">站点总字数：</span> <span title="站点总字数">211k</span> <span class="post-meta-divider">|</span><span class="post-meta-item-icon"><i class="fa fa-coffee"></i></span> <span class="post-meta-item-text">站点阅读时长 &asymp;</span> <span title="站点阅读时长">3:11</span></div><div class="powered-by">由 <span class="exturl theme-link" data-url="aHR0cHM6Ly9oZXhvLmlv">Hexo</span> 强力驱动 v3.9.0</div> <span class="post-meta-divider">|</span><div class="theme-info">主题 – <span class="exturl theme-link" data-url="aHR0cHM6Ly90aGVtZS1uZXh0Lm9yZw==">NexT.Pisces</span> v7.3.0</div><div class="busuanzi-count"><script async="" src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><span class="site-uv"><i class="fa fa-user"></i> 访问用户：<span class="busuanzi-value" id="busuanzi_value_site_uv"></span> 人</span><div class="powered-by"></div><span class="site-uv"><i class="fa fa-eye"></i> 访问次数：<span class="busuanzi-value" id="busuanzi_value_site_pv"></span> 次</span></div></div></footer><div id="needsharebutton-float"><span class="btn"><i class="fa fa-share-alt" aria-hidden="true"></i></span></div><script src="//cdn.jsdelivr.net/gh/theme-next/theme-next-needmoreshare2@1/needsharebutton.min.js"></script><script>pbOptions={iconStyle:"box",boxForm:"horizontal",position:"bottomCenter",networks:"Weibo,Wechat,Douban,QQZone,Twitter,Facebook"},new needShareButton("#needsharebutton-postbottom",pbOptions),flOptions={iconStyle:"box",boxForm:"horizontal",position:"middleRight",networks:"Weibo,Wechat,Douban,QQZone,Twitter,Facebook"},new needShareButton("#needsharebutton-float",flOptions)</script></div><script src="//cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script><script src="/js/utils.js?v=7.3.0"></script><script src="/js/affix.js?v=7.3.0"></script><script src="/js/schemes/pisces.js?v=7.3.0"></script><script src="/js/next-boot.js?v=7.3.0"></script><script>!function(){var t=document.createElement("script"),e=window.location.protocol.split(":")[0];t.src="https"===e?"https://zz.bdstatic.com/linksubmit/push.js":"http://push.zhanzhang.baidu.com/push.js";var s=document.getElementsByTagName("script")[0];s.parentNode.insertBefore(t,s)}()</script><script src="/js/local-search.js?v=7.3.0"></script><script src="/js/scrollspy.js?v=7.3.0"></script><script src="/js/post-details.js?v=7.3.0"></script><link rel="stylesheet" href="//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.css"><script>NexT.utils.getScript("//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js",function(){new Gitalk({clientID:"aebff323e44f1516e521",clientSecret:"3934128e2a234e13b6118386667dee31ab703836",repo:"2694048168.github.io",owner:"2694048168",admin:["2694048168"],id:"95b52062979eb3f376f92e2a15513efa",language:"en | es-ES | fr | ru | zh-CN | zh-TW",distractionFreeMode:"true"}).render("gitalk-container")},window.Gitalk)</script></body></html>