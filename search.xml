<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[常用软件]]></title>
    <url>%2F%E5%B8%B8%E7%94%A8%E8%BD%AF%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[Chrome浏览器 界面良好 插件支持 书签支持 账号同步 Chrome下载 office办公 文字排版Word 数据表格Excle 演示文稿PowerPoint 制图神器Visio 编辑器 Notepad++ Sublime Foxit阅读器 福晰阅读器用来阅读PDF文件 Git终端 Windows系统下使用GitBash用于写博客 Hexo+Next+node.js搭建博客 编译器 Gcc编译器 Java编译器 Python解释器 TeX Live编译器 IDE PyCharm TeXstudio CodeBlocks VMwareXMindZotero迅雷FormatFactory屏幕录像专家OriginProteus]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>软件集合</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[文献阅读]]></title>
    <url>%2F%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB%2F</url>
    <content type="text"><![CDATA[鄙人习惯 使用Zotero Connector来收集chrome浏览器中检索到的文章 然后自动文章信息自动导入到本地Zotero客户端中 利用Foxit福晰阅读器来阅读下载的PDF格式文章 在Zotero中对应文章下建立markdown笔记，便于导出到博客 在Zotero中安装markdownhere4zotero插件来支持markdown格式 对参考文献的导出，在word中点击Zotero可以添加参看文献，支持多种样式格式 同时对于写LaTex文章，可以导出BibTeX或者BibLaTeX加以引入 提示：这并不是唯一选择，只要适合自己即可！ 文献检索检索工具 Google引擎、Baidu引擎、Bing引擎 中文检索库：中国知网、万方数据库、维普 英文检索库：Web of Science、谷歌学术、NCBI、Annual Reviews 学位论文检索：中国知网、CALIS、ProQuest 专利检索：万方数据库、中国专利信息网、国家知识产权 检索思路 普通检索在各种数据库或者浏览器中直接检索关键词，然后筛选自己需要的文章！ 高级检索以主题、分类、作者等等进行检索，然后筛选自己需要的文章！ 浏览检索关注专业的核心期刊，对每一期刊都浏览查看，如Nature！ 追溯检索选择专业的一篇核心文章，然后追溯其参看文献文章！ 文献筛选 关注重点：最新文章、核心期刊 主次分明：英文为主，中文为辅 初步筛选：阅读标题和摘要 减少下载：最终筛选，决定需要才下载 重点文献 领域内经典文献 领域内大神或课题组的文章 领域内代表性学者的文章 核心文章 最新文章 文献阅读思想认识 文献是科研的基础 化被动为主动 注重阅读顺序 多多交流，质疑文献 文献专用词 文献综述 有影响力的文献 期刊影响因子 引用次数 自引和他引 核心文献 阅读概述 文章数量：江湖传言，硕士50篇，博士100篇 类型顺序：中文综述——中文硕博论文——英文综述——英文研究型文章 阅读概论：以网状结构而形成系统；以目标为导向专研核心文章 方法论：需求决定阅读方法 研究型文章结构：标题、摘要、前言、试验方法、图表、分析讨论、结论 笔记重点 基本信息：题目、出处、著者、期卷等等 中心思想：概况目的、研究手段方法、结论 实验方法：实验方案、实验框架 英文学习：专业词汇、引言和讨论写法句式 查询需求：自己有质疑的地方 总结需求：文章重要观点、方法论 文献管理思想认识 在科研项目中，查阅资料占据一半的时间和精力 文章一定要学会精读和速读 选择一款适合自己的文献管理软件，事半功倍 良好的笔记行为和良好的标记行为，节约时间 文献管理软件 EndNote：业内神器，商业收费 Mendeley ：社区功能，免费，需要梯子 Zotero：开源免费，支持浏览器插件 JabRef：开源免费，支持latex的BibTeX 格式 CNKI E-Study：知网推荐，支持浏览器插件 Papers：写论文神器，支持PDF Citavi：论文帮手，瑞士军刀 网址链接中国知网万方数据库维普数据库学位论文中心服务系统中国专利信息网国家知识产权baidu引擎Web of ScienceNCBI谷歌学术谷歌学术镜像bing引擎googe引擎Annual Reviews]]></content>
      <categories>
        <category>读书</category>
      </categories>
      <tags>
        <tag>文献检索、阅读、管理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Shell笔记]]></title>
    <url>%2FShell%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[笔记概述Shell 环境Linux 的 Shell 种类众多，常见的有： Bourne Shell（/usr/bin/sh或/bin/sh） Bourne Again Shell（/bin/bash） C Shell（/usr/bin/csh） K Shell（/usr/bin/ksh） Shell for Root（/sbin/sh） 一般情况下Bash，指的就是 Bourne Again Shell，由于易用和免费，Bash 在日常工作中被广泛使用。同时，Bash 也是大多数Linux 系统默认的 Shell。而且在一般情况下，人们并不区分 Bourne Shell 和 Bourne Again Shell，所以，像 #!/bin/sh，它同样也可以改为 #!/bin/bash。 #! 告诉系统其后路径所指定的程序即是解释此脚本文件的 Shell 程序。 运行方式 以脚本方式运行 12chmod +x ./*.sh./*.sh 用shell解释器运行 1sh *.sh Shell 脚本注释以 # 开头的行就是注释，会被解释器忽略，通过每一行加一个 # 号设置多行注释。多行注释还可以使用以下格式：（EOF 也可以使用其他符号:如，！等等）:&lt;&lt;EOF注释内容…注释内容…注释内容…EOF 如果在开发过程中，遇到大段的代码需要临时注释起来，过一会儿又取消注释，怎么办呢？每一行加个#符号太费力了，可以把这一段要注释的代码用一对花括号括起来，定义成一个函数，没有地方调用这个函数，这块代码就不会执行，达到了和注释一样的效果。 核心语法shell 变量 变量名和等号之间不能有空格，这可能和你熟悉的所有编程语言都不一样！ 使用一个定义过的变量，只要在变量名前面加美元符号即可 变量名外面的花括号是可选的，加不加都行，加花括号是为了帮助解释器识别变量的边界 推荐给所有变量加上花括号，这是个好的编程习惯 使用 readonly 命令可以将变量定义为只读变量，只读变量的值不能被改变。 使用 unset 命令可以删除变量。变量被删除后不能再次使用。unset 命令不能删除只读变量。 运行shell时，会同时存在三种变量 局部变量 局部变量在脚本或命令中定义，仅在当前shell实例中有效，其他shell启动的程序不能访问局部变量。 环境变量 所有的程序，包括shell启动的程序，都能访问环境变量，有些程序需要环境变量来保证其正常运行。必要的时候shell脚本也可以定义环境变量。 shell变量 shell变量是由shell程序设置的特殊变量。shell变量中有一部分是环境变量，有一部分是局部变量，这些变量保证了shell的正常运行。 shell 字符串字符串是shell编程中最常用最有用的数据类型（数字和字符串），字符串可以用单引号，也可以用双引号，也可以不用引号。 单引号字符串的限制 单引号里的任何字符都会原样输出，单引号字符串中的变量是无效的； 单引号字串中不能出现单独一个的单引号（对单引号使用转义符后也不行），但可成对出现，作为字符串拼接使用。 双引号的优点 双引号里可以有变量 双引号里可以出现转义字符 字符串操作 拼接字符串，建议使用双引号拼接，也可以单引号 获取字符串长度，在字符串变量前引用#号 提取子字符串，切片操作，注意第一个字符的索引值为 0 查找子字符串，查找字符 i 或 o 的位置，使用反引号：123string="runoob is a great site"echo `expr index "$string" io` # 输出 4# 注意： 以上脚本中 ` 是反引号，而不是单引号 '，不要看错了哦。 shell 数组bash支持一维数组（不支持多维数组），并且没有限定数组的大小。类似于 C 语言，数组元素的下标由 0 开始编号。获取数组中的元素要利用下标，下标可以是整数或算术表达式，其值应大于或等于 0。 定义数组在 Shell 中，用括号来表示数组，数组元素用”空格”符号分割开。定义数组的一般形式为：数组名=(值1 值2 … 值n) 读取数组读取数组元素值的一般格式是：${数组名[下标]}，将下标使用 @ 或 * 符号可以获取数组中的所有元素 获取数组的长度获取数组长度的方法与获取字符串长度的方法相同， Shell 传递参数我们可以在执行 Shell 脚本时，向脚本传递参数，脚本内获取参数的格式为：$n。n 代表一个数字，1 为执行脚本的第一个参数，2 为执行脚本的第二个参数，以此类推……,其中 $0 为执行的文件名 shell中几个特殊字符用来处理参数： 参数处理 说明 $# 传递到脚本的参数个数 $* 以一个单字符串显示所有向脚本传递的参数 $$ 脚本运行的当前进程ID号 $! 后台运行的最后一个进程的ID号 $@ 与$*相同，但是使用时加引号，并在引号中返回每个参数 $- 显示Shell使用的当前选项，与set命令功能相同 $? 显示最后命令的退出状态。0表示没有错误，其他任何值表明有错误 $* 与 $@ 区别：相同点，都是引用所有参数；不同点，只有在双引号中体现出来。假设在脚本运行时写了三个参数 1、2、3，，则 “ * “ 等价于 “1 2 3”（传递了一个参数），而 “@” 等价于 “1” “2” “3”（传递了三个参数）。 Shell 基本运算符Shell 和其他编程语言一样，支持多种运算符 算数运算符 关系运算符 布尔运算符 字符串运算符 文件测试运算符 原生bash不支持简单的数学运算，但是可以通过其他命令来实现，例如 awk 和 expr，expr 最常用。 expr 是一款表达式计算工具，使用它能完成表达式的求值操作，注意： 表达式和运算符之间要有空格，例如 2+2 是不对的，必须写成 2 + 2，这与我们熟悉的大多数编程语言不一样。 完整的表达式要被 包含，注意这个字符不是常用的单引号，在 Esc 键下边。 算术运算符 运算符 说明 举例 + 加法 expr $a + $b 结果为 30。 - 减法 expr $a - $b 结果为 -10。 * 乘法 expr $a \* $b 结果为 200。 / 除法 expr $b / $a 结果为 2。 % 取余 expr $b % $a 结果为 0。 = 赋值 a=$b 将把变量 b 的值赋给 a。 == 相等。用于比较两个数字，相同则返回 true。 [ $a == $b ] 返回 false。 != 不相等。用于比较两个数字，不相同则返回 true [ $a != $b ] 返回 true。 注意：条件表达式要放在方括号之间，并且要有空格，例如: [$a==$b] 是错误的，必须写成 [ $a == $b ]！！！注意：乘号(*)前边必须加反斜杠()才能实现乘法运算！！！ 关系运算符关系运算符只支持数字，不支持字符串，除非字符串的值是数字。 运算符 说明 举例 -eq 检测两个数是否相等，相等返回 true。 [ $a -eq $b ] 返回 false。 -ne 检测两个数是否不相等，不相等返回 true。 [ $a -ne $b ] 返回 true。 -gt 检测左边的数是否大于右边的，如果是，则返回 true。 [ $a -gt $b ] 返回 false。 -lt 检测左边的数是否小于右边的，如果是，则返回 true。 [ $a -lt $b ] 返回 true。 -ge 检测左边的数是否大于等于右边的，如果是，则返回 true。 [ $a -ge $b ] 返回 false。 -le 检测左边的数是否小于等于右边的，如果是，则返回 true。 [ $a -le $b ] 返回 true。 布尔运算符和逻辑运算符 运算符 说明 举例 ! 非运算，表达式为 true 则返回 false，否则返回 true。 [ ! false ] 返回 true。 -o 或运算，有一个表达式为 true 则返回 true。 [ $a -lt 20 -o $b -gt 100 ] 返回 true。 -a 与运算，两个表达式都为 true 才返回 true。 [ $a -lt 20 -a $b -gt 100 ] 返回 false。 &amp;&amp; 逻辑的 AND [[ $a -lt 100 &amp;&amp; $b -gt 100 ]] 返回 false 字符串运算符 运算符 说明 举例 = 检测两个字符串是否相等，相等返回 true。 [ $a = $b ] 返回 false。 != 检测两个字符串是否相等，不相等返回 true。 [ $a != $b ] 返回 true。 -z 检测字符串长度是否为0，为0返回 true。 [ -z $a ] 返回 false。 -n 检测字符串长度是否为0，不为0返回 true。 [ -n “$a” ] 返回 true。 $ 检测字符串是否为空，不为空返回 true。 [ $a ] 返回 true。 文件测试运算符文件测试运算符用于检测 Unix 文件的各种属性。 运算符 说明 举例 -b file 检测文件是否是块设备文件，如果是，则返回 true。 [ -b $file ] 返回 false。 -c file 检测文件是否是字符设备文件，如果是，则返回 true。 [ -c $file ] 返回 false。 -d file 检测文件是否是目录，如果是，则返回 true。 [ -d $file ] 返回 false。 -f file 检测文件是否是普通文件（既不是目录，也不是设备文件），如果是，则返回 true。 [ -f $file ] 返回 true。 -g file 检测文件是否设置了 SGID 位，如果是，则返回 true。 [ -g $file ] 返回 false。 -k file 检测文件是否设置了粘着位(Sticky Bit)，如果是，则返回 true。 [ -k $file ] 返回 false。 -p file 检测文件是否是有名管道，如果是，则返回 true。 [ -p $file ] 返回 false。 -u file 检测文件是否设置了 SUID 位，如果是，则返回 true。 [ -u $file ] 返回 false。 -r file 检测文件是否可读，如果是，则返回 true。 [ -r $file ] 返回 true。 -w file 检测文件是否可写，如果是，则返回 true。 [ -w $file ] 返回 true。 -x file 检测文件是否可执行，如果是，则返回 true。 [ -x $file ] 返回 true。 -s file 检测文件是否为空（文件大小是否大于0），不为空返回 true。 [ -s $file ] 返回 true。 -e file 检测文件（包括目录）是否存在，如果是，则返回 true。 [ -e $file ] 返回 true。 -S file 判断某文件是否 socket。 -L file 检测文件是否存在并且是一个符号链接。 Shell 标准输出命令echo命令Shell 的 echo 指令，用于字符串的输出。命令格式：echo string您可以使用echo实现更复杂的输出格式控制。 echo输出的字符串总结 能否引用变量 能否引用转移符 能否引用文本格式符(如：换行符、制表符) 单引号 否 否 双引号 能 能 无引号 能 能 &gt; 重定向输出到某个位置，替换原有文件的所有内容&gt;&gt; 重定向追加到某个位置，在原有文件的末尾添加内容 printf 命令printf 命令模仿 C 程序库（library）里的 printf() 程序。printf 由 POSIX 标准所定义，因此使用 printf 的脚本比使用 echo 移植性好。printf 使用引用文本或空格分隔的参数，外面可以在 printf 中使用格式化字符串，还可以制定字符串的宽度、左右对齐方式等。默认 printf 不会像 echo 自动添加换行符，我们可以手动添加 \n。 printf 命令的语法：printf format-string [arguments…]参数说明： format-string: 为格式控制字符串 arguments: 为参数列表。 Shell test 命令Shell中的 test 命令用于检查某个条件是否成立，它可以进行数值、字符和文件三个方面的测试。 数值测试 参数 说明 -eq 等于则为真 -ne 不等于则为真 -gt 大于则为真 -ge 大于等于则为真 -lt 小于则为真 -le 小于等于则为真 符号含义 eq （equal的缩写），表示等于为真 ne (not equal的缩写），表示不等于为真 gt (greater than的缩写），表示大于为真 ge （greater&amp;equal的缩写），表示大于等于为真 lt （lower than的缩写），表示小于为真 le （lower&amp;equal的缩写），表示小于等于为真 字符串测试 参数 说明 = 等于则为真 != 不相等则为真 -z 字符串 字符串的长度为零则为真 -n 字符串 字符串的长度不为零则为真 文件测试 参数 说明 -e 文件名 如果文件存在则为真 -r 文件名 如果文件存在且可读则为真 -w 文件名 如果文件存在且可写则为真 -x 文件名 如果文件存在且可执行则为真 -s 文件名 如果文件存在且至少有一个字符则为真 -d 文件名 如果文件存在且为目录则为真 -f 文件名 如果文件存在且为普通文件则为真 -c 文件名 如果文件存在且为字符型特殊文件则为真 -b 文件名 如果文件存在且为块特殊文件则为真 另外，Shell还提供了与( -a )、或( -o )、非( ! )三个逻辑操作符用于将测试条件连接起来，其优先级为：”!”最高，”-a”次之，”-o”最低。 Shell 流程控制if else123456789101112131415161718192021222324# if 语句语法格式：if conditionthen commandsfi# if else 语法格式：if conditionthen commandselse commandsfi# if else-if else 语法格式：if condition1then command1elif condition2 then command2else commandNfi for 循环12345678# for循环一般格式为：for var in item1 item2 ... itemNdo command1 command2 ... commandNdone while 语句123456# while循环用于不断执行一系列命令，也用于从输入文件中读取数据；命令通常为测试条件。# 其格式为：while conditiondo commanddone until 循环12345678# until 循环执行一系列命令直至条件为 true 时停止。until 循环与 while 循环在处理方式上刚好相反。# 一般 while 循环优于 until 循环，但在某些时候—也只是极少数情况下，until 循环更加有用。# until 语法格式:until conditiondo commanddone# condition 一般为条件表达式，如果返回值为 false，则继续执行循环体内的语句，否则跳出循环。 Shell case语句为多选择语句。123456789101112131415# 可以用case语句匹配一个值与一个模式，如果匹配成功，执行相匹配的命令。case语句格式如下：case 值 in模式1) command1 command2 ... commandN ;;模式2） command1 command2 ... commandN ;;esac 取值后面必须为单词in，每一模式必须以右括号结束。取值可以为变量或常数 匹配发现取值符合某一模式后，其间所有命令开始执行直至 ;; 取值将检测匹配的每一个模式。一旦模式匹配，则执行完匹配模式相应命令后不再继续其他模式 如果无一匹配模式，使用星号 * 捕获该值，再执行后面的命令 case … esac,与switch … case 语句类似，是一种多分枝选择结构，每个 case 分支用右圆括号开始 用两个分号 ;; 表示 break，即执行结束，跳出整个 case … esac 语句，esac（就是 case 反过来）作为结束标记 Shell 函数linux shell 可以用户定义函数，然后在shell脚本中可以随便调用。 123456789shell中函数的定义格式如下：[ function ] funname [()]&#123; action; [return int;]&#125; 说明： 可以带function fun() 定义，也可以直接fun() 定义,不带任何参数。 参数返回，可以显示加：return 返回，如果不加，将以最后一条命令运行结果，作为返回值。 return后跟数值n(0-255) 函数返回值在调用该函数后通过 $? 来获得。 $? 仅对其上一条指令负责，一旦函数返回后其返回值没有立即保存入参数，那么其返回值将不再能通过 $? 获得。 所有函数在使用前必须定义。这意味着必须将函数放在脚本开始部分，直至shell解释器首次发现它时，才可以使用。 调用函数仅使用其函数名即可。 函数参数，在Shell中，调用函数时可以向其传递参数。 在函数体内部，通过 $n 的形式来获取参数的值，例如，$1表示第一个参数，$2表示第二个参数… 注意，$10 不能获取第十个参数，获取第十个参数需要${10}。当n&gt;=10时，需要使用${n}来获取参数。 另外，还有几个特殊字符用来处理参数： 参数处理 说明 $# 传递到脚本或函数的参数个数 $* 以一个单字符串显示所有向脚本传递的参数 $$ 脚本运行的当前进程ID号 $! 后台运行的最后一个进程的ID号 $@ 与$*相同，但是使用时加引号，并在引号中返回每个参数。 $- 显示Shell使用的当前选项，与set命令功能相同。 $? 显示最后命令的退出状态。0表示没有错误，其他任何值表明有错误。 Shell 输入输出重定向大多数 UNIX 系统命令从你的终端接受输入并将所产生的输出发送回​​到您的终端。一个命令通常从一个叫标准输入的地方读取输入，默认情况下，这恰好是你的终端。同样，一个命令通常将其输出写入到标准输出，默认情况下，这也是你的终端。需要注意的是文件描述符 0 通常是标准输入（STDIN），1 是标准输出（STDOUT），2 是标准错误输出（STDERR）。 命令 说明 command &gt; file 将输出重定向到 file。 command &lt; file 将输入重定向到 file。 command &gt;&gt; file 将输出以追加的方式重定向到 file。 n &gt; file 将文件描述符为 n 的文件重定向到 file。 n &gt;&gt; file 将文件描述符为 n 的文件以追加的方式重定向到 file。 n &gt;&amp; m 将输出文件 m 和 n 合并。 n &lt;&amp; m 将输入文件 m 和 n 合并。 &lt;&lt; tag 将开始标记 tag 和结束标记 tag 之间的内容作为输入。 Shell 文件包含和其他语言一样，Shell 也可以包含外部脚本。这样可以很方便的封装一些公用的代码作为一个独立的文件。Shell 文件包含的语法格式如下： . filename_路径 # 注意点号(.)和文件名中间有一空格 source filename_路径 注：被包含的文件 test1.sh 不需要可执行权限。 实用案例]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Pandas笔记]]></title>
    <url>%2FPandas%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[pandaspandas除了处理如numpy一样的数值型数据外，还能处理一些其他类型的数据，如字符串、时间序列、矩阵等等。 pandas基础属性]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>pandas</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[NumPy笔记]]></title>
    <url>%2FNumPy%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[numpynumpy处理数值型数据，常用于数学中的矩阵运算，编程语言中也称之为数组。 图形的属性]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>numpy</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Matplotlib笔记]]></title>
    <url>%2FMatplotlib%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[matplotlib绘制图形，使数据可视化，更加直观、客观和更具说服力。matplotlib是Python最底层的绘图库，类似于MATLAB一样的简单实用。当然Python的绘图库还有更加高级的封装，例如plotpy、seaborn和基于JavaScript(JS)的前端展示Echarts。 matplotlib 官网例子 图形的属性 设置图形的大小 保存图形 调制刻度轴 添加图形描述信息 支持中文 绘制图形网格 设置颜色 添加文本水印 添加图例 添加文本注释 源代码实例123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657#!/usr/bin/env python3# -- coding: utf-8 --# @author：云主宰苍穹# @date：2020-02-05 18:56# @introduction：对于matplotlib库的基本绘图pyplot简单使用# @tips：对于每一个方法函数可以查看源代码，了解其使用情况# 引入依赖from matplotlib import pyplot as pltfrom matplotlib import font_manager# 加载数据x = range(2,27,2)y = [15,13,14,5,17,20,25,26,26,27,22,18,15]y2 = [13,12,17,16,15,18,23,24,27,28,22,19,25]# 设置图形大小,dpi是分辨率fig = plt.figure(figsize = (10,7), dpi = 80)# matplotlib支持中文解决方案# 查看源码，有font_manager里面属性fname# 使用命令fc查看系统支持的字体路径(注意冒号前的空格)：fc-list :lang=zhmy_font = font_manager.FontProperties( fname = r"C:/Windows/fonts/msyhbd.ttf" )# 调整刻度轴plt.xticks(range(min(x),max(x)+1))plt.yticks(range(1,28,1))# 添加基本描述信息plt.xlabel("时间", fontproperties = my_font)plt.ylabel("温度", fontproperties = my_font)#使用figtext标记x和y轴plt.figtext(0.9, 0.05, "时间", fontproperties = my_font)plt.figtext(0.1, 0.9, "温度", fontproperties = my_font)plt.title("一天中室内温度值变化", fontproperties = my_font)# 添加网格，设置透明度plt.grid(alpha=0.4)# 添加文本水印plt.text(0.95, 0.5, "云主宰苍穹", fontsize=80, color='gray', ha='right', va='bottom', alpha=0.5, fontproperties = my_font)# 绘制图形,设置颜色、线条属性、透明度plt.plot(x,y,label="温度变化",color="red")plt.plot(x,y2,label="温度变化",color="green")# 添加图例信息，要在绘制图形命令后，loc表示位置，0为最佳选择plt.legend(prop = my_font,loc=0)# 保存图形，保存格式有svg矢量图，png格式（默认格式），可以设置需要保存图形属性plt.savefig("./pyplot.svg")plt.savefig("./pyplot.png")# 展示图形plt.show()]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>matplotlib</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[A_goood_lecture]]></title>
    <url>%2FA-goood-lecture%2F</url>
    <content type="text"><![CDATA[Some Old Truths to Help You Overcome Tough Times&emsp;&emsp;Unfortunately， life is not a bed of roses. We are going through life facing sad experiences. Moreover， we are grieving various kinds of loss： a friendship， a romantic relationship or a house. Hard times may hold you down at what usually seems like the most inopportune time， but you should remember that they won‘t last forever. &emsp;&emsp;When our time of mourning is over， we press forward， stronger with a greater understanding and respect for life. Furthermore， these losses make us mature and eventually move us toward future opportunities for growth and happiness. I want to share these ten old truths I‘ve learned along the way. &emsp;&emsp;Fear is both useful and harmful. This normal human reaction is used to protect us by signaling danger and preparing us to deal with it. Unfortunately， people create inner barriers with a help of exaggerating fears. My favorite actor Will Smith once said， “Fear is not real. It is a product of thoughts you create. Do not misunderstand me. Danger is very real. But fear is a choice.” I do completely agree that fears are just the product of our luxuriant imagination. &emsp;&emsp;If you are surrounded by problems and cannot stop thinking about the past， try to focus on the present moment. Many of us are weighed down by the past or anxious about the future. You may feel guilt over your past， but you are poisoning the present with the things and circumstances you cannot change. Value the present moment and remember how fortunate you are to be alive. Enjoy the beauty of the world around and keep the eyes open to see the possibilities before you. Happiness is not a point of future and not a moment from the past， but a mindset that can be designed into the present. &emsp;&emsp;Sometimes it is easy to feel bad because you are going through tough times. You can be easily caught up by life problems that you forget to pause and appreciate the things you have. Only strong people prefer to smile and value their life instead of crying and complaining about something. &emsp;&emsp;No matter how isolated you might feel and how serious the situation is， you should always remember that you are not alone. Try to keep in mind that almost everyone respects and wants to help you if you are trying to make a good change in your life， especially your dearest and nearest people. You may have a circle of friends who provide constant good humor， help and companionship. If you have no friends or relatives， try to participate in several online communities， full of people who are always willing to share advice and encouragement. &emsp;&emsp;Today many people find it difficult to trust their own opinion and seek balance by gaining objectivity from external sources. This way you devalue your opinion and show that you are incapable of managing your own life. When you are struggling to achieve something important you should believe in yourself and be sure that your decision is the best. You live in your skin， think your own thoughts， have your own values and make your own choices.]]></content>
      <categories>
        <category>读书</category>
      </categories>
      <tags>
        <tag>认识人生</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python3学习]]></title>
    <url>%2FPython3%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[笔记概述&emsp;&emsp;脚本语言的第一行内容：#!/usr/bin/python3，目的就是指出，你想要这个文件中的代码用什么可执行程序去运行解释它，就这么简单。这条语句是告诉操作系统执行这个脚本的时候，调用 /usr/bin 下的 python3 解释器去执行。 &emsp;&emsp;而对于#!/usr/bin/env python3 这种用法是为了防止操作系统用户没有将 python3 装在默认的 /usr/bin 路径里。当系统看到这一行的时候，首先会到 env 设置里查找 python3 的安装路径，再调用对应路径下的解释器程序完成操作。#!/usr/bin/python3 相当于写死了 python3 路径;而#!/usr/bin/env python3 会去环境设置寻找 python3 目录，推荐这种写法。 &emsp;&emsp;Python3 下载 Python3 最新源码，二进制文档，新闻资讯等可以在 Python 的官网查看到：Python 官网： 你可以在以下链接中下载 Python 的文档，你可以下载 HTML、PDF 和 PostScript 等格式的文档：Python文档下载地址： Python 几个重要的环境变量： 变量名 描述 PYTHONPATH PYTHONPATH是Python搜索路径，默认我们import的模块都会从PYTHONPATH里面寻找 PYTHONSTARTUP Python启动后，先寻找PYTHONSTARTUP环境变量，然后执行此变量指定的文件中的代码 PYTHONCASEOK 加入PYTHONCASEOK的环境变量, 就会使python导入模块的时候不区分大小写 PYTHONHOME 模块搜索路径。它通常内嵌于的PYTHONSTARTUP或PYTHONPATH目录中，两个模块库容易切换 Python 运行方式 交互式：终端解释器、jupyter 脚本式：特别在Linux上，如shell一样 IDE式：使用集成开发环境IDE 小提示使用交互式 ipython 运行 Pythonipython 是一个 python 的交互式 shell，比默认的 python shell 好用得多，支持变量自动补全，自动缩进，支持 bash shell 命令，内置了许多很有用的功能和函数。此 ipython 中的 i 代表 “交互(interaction)”。ipython官方地址： 编码声明 在第二行：# -- coding: utf-8 -- 这是Emacs的编码声明，这样写可以被Emacs编辑器和Pyhton解释器都兼容。 对于使用Vim的程序员这样： vim: set fileencoding= help() 函数调用 python 的 help() 函数可以打印输出一个函数的文档字符串：查看 max 内置函数的参数列表和规范的文档： help(max)按下 : q 两个按键即退出说明文档 &emsp;&emsp;type 是用于求一个未知数据类型对象，而 isinstance 是用于判断一个对象是否是已知类型。type 不认为子类是父类的一种类型，而isinstance会认为子类是父类的一种类型。可以用 isinstance 判断子类对象是否继承于父类，type 不行。综合以上几点，type 与 isinstance 虽然都与数据类型相关，但两者其实用法不同，type 主要用于判断未知数据类型，isinstance 主要用于判断 A 类是否继承于 B 类： &emsp;&emsp;Python 解释器可不止一种哦，有 CPython、IPython、Jython、PyPy 等。顾名思义，CPython 就是用 C 语言开发的了，是官方标准实现，拥有良好的生态，所以应用也就最为广泛了。而 IPython 是在 CPython 的基础之上在交互式方面得到增强的解释器(http://ipython.org/)。Jython 是专为 Java 平台设计的 Python 解释器(http://www.jython.org/)，它把 Python 代码编译成 Java 字节码执行。PyPy 是 Python 语言（2.7.13和3.5.3）的一种快速、兼容的替代实现(http://pypy.org/)，以速度快著称。 数学函数 函数 返回值 ( 描述 ) abs(x) 返回数字的绝对值，如abs(-10) 返回 10 ceil(x) 返回数字的上入整数，如math.ceil(4.1) 返回 5 cmp(x, y) 如果 x &lt; y 返回 -1, 如果 x == y 返回 0, 如果 x &gt; y 返回 1。 Python 3 已废弃，使用 (x&gt;y)-(x&lt;y) 替换。 exp(x) 返回e的x次幂(ex),如math.exp(1) 返回2.718281828459045 fabs(x) 返回数字的绝对值，如math.fabs(-10) 返回10.0 floor(x) 返回数字的下舍整数，如math.floor(4.9)返回 4 log(x) 如math.log(math.e)返回1.0,math.log(100,10)返回2.0 log10(x) 返回以10为基数的x的对数，如math.log10(100)返回 2.0 max(x1, x2,…) 返回给定参数的最大值，参数可以为序列。 min(x1, x2,…) 返回给定参数的最小值，参数可以为序列。 modf(x) 返回x的整数部分与小数部分，两部分的数值符号与x相同，整数部分以浮点型表示。 pow(x, y) x**y 运算后的值。 round(x [,n]) 返回浮点数 x 的四舍五入值，如给出 n 值，则代表舍入到小数点后的位数。其实准确的说是保留值将保留到离上一位更近的一端。 sqrt(x) 返回数字x的平方根。 随机数函数 函数 描述 choice(seq) 从序列的元素中随机挑选一个元素，比如random.choice(range(10))，从0到9中随机挑选一个整数。 randrange ([start,] stop [,step]) 从指定范围内，按指定基数递增的集合中获取一个随机数，基数默认值为 1 random() 随机生成下一个实数，它在[0,1)范围内。 seed([x]) 改变随机数生成器的种子seed。如果你不了解其原理，你不必特别去设定seed，Python会帮你选择seed。 shuffle(lst) 将序列的所有元素随机排序 uniform(x, y) 随机生成下一个实数，它在[x,y]范围内。 三角函数 函数 描述 acos(x) 返回x的反余弦弧度值。 asin(x) 返回x的反正弦弧度值。 atan(x) 返回x的反正切弧度值。 atan2(y, x) 返回给定的 X 及 Y 坐标值的反正切值。 cos(x) 返回x的弧度的余弦值。 hypot(x, y) 返回欧几里德范数 sqrt(xx + yy)。 sin(x) 返回的x弧度的正弦值。 tan(x) 返回x弧度的正切值。 degrees(x) 将弧度转换为角度,如degrees(math.pi/2) ， 返回90.0 radians(x) 将角度转换为弧度 实例：Python 计算笛卡尔积&emsp;&emsp;计算多个集合的笛卡尔积，有规律可循，算法和代码也不难，但是很多语言都没有提供直接计算笛卡尔积的方法，需要自己写大段大段的代码计算笛卡尔积，python 提供了一种最简单的计算笛卡称积的方法(只需要一行代码)，详见下面的代码： 123456789101112131415161718192021222324252627#!/usr/bin/python3# -*- coding: utf-8 -*-# @file : Cartesian.py# @author : shlian# @date : 2018/5/29# @version: 1.0# @desc : 用python实现求笛卡尔积import itertoolsclass cartesian(object): def __init__(self): self._data_list=[] def add_data(self,data=[]): #添加生成笛卡尔积的数据列表 self._data_list.append(data) def build(self): #计算笛卡尔积 for item in itertools.product(*self._data_list): print(item)if __name__=="__main__": car=cartesian() car.add_data([1,2,3,4]) car.add_data([5,6,7,8]) car.add_data([9,10,11,12]) car.build() 核心语法字符串(String) python中单引号和双引号使用完全相同。 使用三引号(‘’’或”””)可以指定一个多行字符串。 转义符 ‘&#39; 反斜杠可以用来转义，使用r可以让反斜杠不发生转义。。 如 r”this is a line with \n” 则\n会显示，并不是换行。 按字面意义级联字符串，如”this “ “is “ “string”会被自动转换为this is string。 字符串可以用 + 运算符连接在一起，用 * 运算符重复，紧跟的数字为复制的次数 Python 中的字符串有两种索引方式，从左往右以 0 开始，从右往左以 -1 开始。 Python中的字符串不能改变。 Python 没有单独的字符类型，一个字符就是长度为 1 的字符串。 字符串的截取的语法格式如下：变量[头下标:尾下标:步长] 索引值以 0 为开始值，-1 为从末尾的开始位置 截取字符串中的一部分，遵循左闭右开原则 import 与 from…import 在 python 用 import 或者 from…import 来导入相应的模块。 将整个模块(somemodule)导入，格式为： import somemodule 从某个模块中导入某个函数,格式为： from somemodule import somefunction 从某个模块中导入多个函数,格式为： from somemodule import firstfunc, secondfunc, thirdfunc 将某个模块中的全部函数导入，格式为： from somemodule import * 标准数据类型 Number（数字） String（字符串） List（列表） Tuple（元组） Set（集合） Dictionary（字典） 不可变数据（3 个）：Number（数字）、String（字符串）、Tuple（元组） 可变数据（3 个）：List（列表）、Dictionary（字典）、Set（集合） List（列表） 列表可以完成大多数集合类的数据结构实现。列表中元素的类型可以不相同，它支持数字，字符串甚至可以包含列表（所谓嵌套）。 列表是写在方括号 [] 之间、用逗号分隔开的元素列表。 和字符串一样，列表同样可以被索引和截取，列表被截取后返回一个包含所需元素的新列表。 列表截取的语法格式如下：变量[头下标:尾下标] 索引值以 0 为开始值，-1 为从末尾的开始位置。 Tuple（元组） 元组（tuple）与列表类似，不同之处在于元组的元素不能修改。元组写在小括号 () 里，元素之间用逗号隔开。 元组中的元素类型也可以不相同： 元组与字符串类似，可以被索引且下标索引从0开始，-1 为从末尾开始的位置。也可以进行截取 其实，可以把字符串看作一种特殊的元组。 虽然tuple的元素不可改变，但它可以包含可变的对象，比如list列表。 一般来说，函数的返回值一般为一个。而函数返回多个值的时候，是以元组的方式返回的。 Set（集合） 集合（set）是由一个或数个形态各异的大小整体组成的，构成集合的事物或对象称作元素或是成员。 基本功能是进行成员关系测试和删除重复元素。 可以使用大括号 { } 或者 set() 函数创建集合，注意：创建一个空集合必须用 set() 而不是 { }，因为 { } 是用来创建一个空字典。 Dictionary（字典） 字典（dictionary）是Python中另一个非常有用的内置数据类型。 列表是有序的对象集合，字典是无序的对象集合。两者之间的区别在于：字典当中的元素是通过键来存取的，而不是通过偏移存取。 字典是一种映射类型，字典用 { } 标识，它是一个无序的 键(key) : 值(value) 的集合。 键(key)必须使用不可变类型。 在同一个字典中，键(key)必须是唯一的。 if 语句123456if condition_1: statement_block_1elif condition_2: statement_block_2else: statement_block_3 for 语句Python for循环可以遍历任何序列的项目，如一个列表或者一个字符串。 1234for &lt;variable&gt; in &lt;sequence&gt;: &lt;statements&gt;else: &lt;statements&gt; while 循环使用 else 语句在 while … else 在条件语句为 false 时执行 else 的语句块。 1234while &lt;expr&gt;: &lt;statement(s)&gt;else: &lt;additional_statement(s)&gt; while 循环语句和 for 循环语句使用 else 的区别： 如果 else 语句和 while 循环语句一起使用，则当条件变为 False 时，则执行 else 语句。 如果 else 语句和 for 循环语句一起使用，else 语句块只在 for 循环正常终止时执行！ break 语句可以跳出 for 和 while 的循环体。如果你从 for 或 while 循环中终止，任何对应的循环 else 块将不执行。 continue 语句被用来告诉 Python 跳过当前循环块中的剩余语句，然后继续进行下一轮循环。 迭代器与生成器迭代器 迭代是Python最强大的功能之一，是访问集合元素的一种方式。 迭代器是一个可以记住遍历的位置的对象。 迭代器对象从集合的第一个元素开始访问，直到所有的元素被访问完结束。迭代器只能往前不会后退。 迭代器有两个基本的方法：iter() 和 next()。 字符串，列表或元组对象都可用于创建迭代器： 创建一个迭代器 把一个类作为一个迭代器使用需要在类中实现两个方法 iter() 与 next() 。 如果你已经了解的面向对象编程，就知道类都有一个构造函数，Python 的构造函数为 init(), 它会在对象初始化的时候执行。 iter() 方法返回一个特殊的迭代器对象， 这个迭代器对象实现了 next() 方法并通过 StopIteration 异常标识迭代的完成。 next() 方法（Python 2 里是 next()）会返回下一个迭代器对象。 创建一个返回数字的迭代器，初始值为 1，逐步递增 1： StopIteration StopIteration 异常用于标识迭代的完成，防止出现无限循环的情况，在 next() 方法中我们可以设置在完成指定循环次数后触发 StopIteration 异常来结束迭代。 生成器 在 Python 中，使用了 yield 的函数被称为生成器（generator）。 跟普通函数不同的是，生成器是一个返回迭代器的函数，只能用于迭代操作，更简单点理解生成器就是一个迭代器。 在调用生成器运行的过程中，每次遇到 yield 时函数会暂停并保存当前所有的运行信息，返回 yield 的值, 并在下一次执行 next() 方法时从当前位置继续运行。 调用一个生成器函数，返回的是一个迭代器对象。 函数 定义一个由自己想要功能的函数： 函数代码块以 def 关键词开头，后接函数标识符名称和圆括号 ()。 任何传入参数和自变量必须放在圆括号中间，圆括号之间可以用于定义参数。 函数的第一行语句可以选择性地使用文档字符串—用于存放函数说明。 函数内容以冒号起始，并且缩进。 return [表达式] 结束函数，选择性地返回一个值给调用方。不带表达式的return相当于返回 None。 语法Python 定义函数使用 def 关键字，一般格式如下： 123def 函数名（参数列表）: 函数体 return 匿名函数python 使用 lambda 来创建匿名函数。所谓匿名，意即不再使用 def 语句这样标准的形式定义一个函数。 lambda 只是一个表达式，函数体比 def 简单很多。 lambda的主体是一个表达式，而不是一个代码块。仅仅能在lambda表达式中封装有限的逻辑进去。 lambda 函数拥有自己的命名空间，且不能访问自己参数列表之外或全局命名空间里的参数。 虽然lambda函数看起来只能写一行，却不等同于C或C++的内联函数，后者的目的是调用小函数时不占用栈内存从而增加运行效率。 语法lambda 函数的语法只包含一个语句，如下： 1lambda [arg1 [,arg2,.....argn]]:expression 数据结构列表的方法有很多，可以通过使用列表的方法实现常用的数据结构。 将列表当做堆栈使用列表方法使得列表可以很方便的作为一个堆栈来使用，堆栈作为特定的数据结构，最先进入的元素最后一个被释放（后进先出）。用 append() 方法可以把一个元素添加到堆栈顶。用不指定索引的 pop() 方法可以把一个元素从堆栈顶释放出来。 将列表当作队列使用也可以把列表当做队列用，只是在队列里第一加入的元素，第一个取出来；但是拿列表用作这样的目的效率不高。在列表的最后添加或者弹出元素速度快，然而在列表里插入或者从头部弹出速度却不快（因为所有其他的元素都得一个一个地移动）。 列表推导式列表推导式提供了从序列创建列表的简单途径。通常应用程序将一些操作应用于某个序列的每个元素，用其获得的结果作为生成新列表的元素，或者根据确定的判定条件创建子序列。每个列表推导式都在 for 之后跟一个表达式，然后有零到多个 for 或 if 子句。返回结果是一个根据表达从其后的 for 和 if 上下文环境中生成出来的列表。如果希望表达式推导出一个元组，就必须使用括号。 嵌套列表解析Python的列表还可以嵌套。 del 语句使用 del 语句可以从一个列表中依索引而不是值来删除一个元素。这与使用 pop() 返回一个值不同。可以用 del 语句从列表中删除一个切割，或清空整个列表（我们以前介绍的方法是给该切割赋一个空列表）。 模块和包为此Python提供了一个办法，把这些定义存放在文件中，为一些脚本或者交互式的解释器实例使用，这个文件被称为模块。模块是一个包含所有你定义的函数和变量的文件，其后缀名是.py。模块可以被别的程序引入，以使用该模块中的函数等功能。 name属性一个模块被另一个程序第一次引入时，其主程序将运行。如果我们想在模块被引入时，模块中的某一程序块不执行，我们可以用name属性来使该程序块仅在该模块自身运行时执行。说明： 每个模块都有一个name属性，当其值是’main‘时，表明该模块自身在运行，否则是被引入。说明：name 与 main 底下是双下划线dir() 函数内置的函数 dir() 可以找到模块内定义的所有名称。以一个字符串列表的形式返回: 包 包是一种管理 Python 模块命名空间的形式，采用”点模块名称”。 比如一个模块的名称是 A.B， 那么他表示一个包 A中的子模块 B 。 使用模块的时候，不用担心不同模块间的全局变量相互影响一样，用点模块名称这种形式不用担心不同库之间的模块重名的情况。 标准输出入输出和文件读写OS模块用于处理文件和目录错误和异常以及处理面向对象技术简介 类(Class): 用来描述具有相同的属性和方法的对象的集合。它定义了该集合中每个对象所共有的属性和方法。对象是类的实例。 方法：类中定义的函数。 类变量：类变量在整个实例化的对象中是公用的。类变量定义在类中且在函数体之外。类变量通常不作为实例变量使用。 数据成员：类变量或者实例变量用于处理类及其实例对象的相关的数据。 方法重写：如果从父类继承的方法不能满足子类的需求，可以对其进行改写，这个过程叫方法的覆盖（override），也称为方法的重写。 局部变量：定义在方法中的变量，只作用于当前实例的类。 实例变量：在类的声明中，属性是用变量来表示的，这种变量就称为实例变量，实例变量就是一个用 self 修饰的变量。 继承：即一个派生类（derived class）继承基类（base class）的字段和方法。继承也允许把一个派生类的对象作为一个基类对象对待。例如，有这样一个设计：一个Dog类型的对象派生自Animal类，这是模拟”是一个（is-a）”关系（例图，Dog是一个Animal）。 实例化：创建一个类的实例，类的具体对象。 对象：通过类定义的数据结构实例。对象包括两个数据成员（类变量和实例变量）和方法。 命名空间和作用域命名空间(Namespace)是从名称到对象的映射，大部分的命名空间都是通过 Python 字典来实现的。命名空间提供了在项目中避免名字冲突的一种方法。各个命名空间是独立的，没有任何关系的，所以一个命名空间中不能有重名，但不同的命名空间是可以重名而没有任何影响。我们举一个计算机系统中的例子，一个文件夹(目录)中可以包含多个文件夹，每个文件夹中不能有相同的文件名，但不同文件夹中的文件可以重名。 Python 的查找顺序为：局部的命名空间去 -&gt; 全局命名空间 -&gt; 内置命名空间。一般有三种命名空间： 内置名称（built-in names）， Python 语言内置的名称，比如函数名 abs、char 和异常名称 BaseException、Exception 等等。 全局名称（global names），模块中定义的名称，记录了模块的变量，包括函数、类、其它导入的模块、模块级的变量和常量。 局部名称（local names），函数中定义的名称，记录了函数的变量，包括函数的参数和局部定义的变量。（类中定义的也是） 作用域就是一个 Python 程序可以直接访问命名空间的正文区域。在一个 python程序中，直接访问一个变量，会从内到外依次访问所有的作用域直到找到，否则会报未定义的错误。Python 中，程序的变量并不是在哪个位置都可以访问的，访问权限决定于这个变量是在哪里赋值的。变量的作用域决定了在哪一部分程序可以访问哪个特定的变量名称。Python的作用域一共有4种，分别是：有四种作用域： L（Local）：最内层，包含局部变量，比如一个函数/方法内部。 E（Enclosing）：包含了非局部(non-local)也非全局(non-global)的变量。比如两个嵌套函数，一个函数（或类） A 里面又包含了一个函数 B ，那么对于 B 中的名称来说 A 中的作用域就为 nonlocal。 G（Global）：当前脚本的最外层，比如当前模块的全局变量。 B（Built-in）： 包含了内建的变量/关键字等。，最后被搜索规则顺序： L –&gt; E –&gt; G –&gt;gt; B。在局部找不到，便会去局部外的局部找（例如闭包），再找不到就会去全局找，再者去内置中找。 标准库 操作系统接口，OS模块提供了不少与操作系统相关联的函数。 文件通配符，glob模块提供了一个函数用于从目录通配符搜索中生成文件列表 命令行参数，通用工具脚本经常调用命令行参数。这些命令行参数以链表形式存储于 sys 模块的 argv 变量。 错误输出重定向和程序终止，sys 还有 stdin，stdout 和 stderr 属性，即使在 stdout 被重定向时，后者也可以用于显示警告和错误信息。 字符串正则匹配，re模块为高级字符串处理提供了正则表达式工具。 数学，math模块为浮点运算提供了对底层C函数库的访问 访问 互联网，有几个模块用于访问互联网以及处理网络通信协议。其中最简单的两个是用于处理从 urls 接收的数据的 urllib.request 以及用于发送电子邮件的 smtplib: 日期和时间，datetime模块为日期和时间处理同时提供了简单和复杂的方法，该模块还支持时区处理 数据压缩，以下模块直接支持通用的数据打包和压缩格式：zlib，gzip，bz2，zipfile，以及 tarfile。 性能度量，有些用户对了解解决同一问题的不同方法之间的性能差异很感兴趣。Python 提供了一个度量工具，为这些问题提供了直接答案。 测试模块，开发高质量软件的方法之一是为每一个函数开发测试代码，并且在开发过程中经常进行测试，doctest模块提供了一个工具，扫描模块并根据程序中内嵌的文档字符串执行测试。试构造如同简单的将它的输出结果剪切并粘贴到文档字符串中。通过用户提供的例子，它强化了文档，允许 doctest 模块确认代码的结果是否与文档一致 高级进阶正则表达式1234567891011121314151617181920212223# 引入正则表达式模块reimport re# re.match函数，re.match 尝试从字符串的起始位置匹配一个模式，如果不是起始位置匹配成功的话，match()就返回none。re.match(pattern, string, flags=0)# re.search方法，re.search 扫描整个字符串并返回第一个成功的匹配。re.search(pattern, string, flags=0)# 检索和替换，Python 的re模块提供了re.sub用于替换字符串中的匹配项。re.sub(pattern, repl, string, count=0, flags=0)# compile 函数，compile 函数用于编译正则表达式，生成一个正则表达式（ Pattern ）对象，供 match() 和 search() 这两个函数使用。re.compile(pattern[, flags])# findall，在字符串中找到正则表达式所匹配的所有子串，并返回一个列表，如果没有找到匹配的，则返回空列表。注意： match 和 search 是匹配一次 findall 匹配所有。re.findall(string[, pos[, endpos]])# re.finditer，和 findall 类似，在字符串中找到正则表达式所匹配的所有子串，并把它们作为一个迭代器返回。re.finditer(pattern, string, flags=0)# re.split，split 方法按照能够匹配的子串将字符串分割后返回列表，它的使用形式如下：re.split(pattern, string[, maxsplit=0, flags=0]) MySQL数据库Python MySQL - mysql-connector 驱动MySQL 是最流行的关系型数据库管理系统，使用 mysql-connector 来连接使用 MySQL， mysql-connector 是 MySQL 官方提供的驱动器。Python3 MySQL 数据库连接 - PyMySQL 驱动Python3 使用 PyMySQL 连接数据库，并实现简单的增删改查。PyMySQL 安装： pip3 install PyMySQLPyMySQL 下载地址： MongoDB数据库MongoDB 是目前最流行的 NoSQL 数据库之一，使用的数据类型 BSON，PyMongo是Python 要连接 MongoDB 需要 MongoDB 驱动，可使用pip来安装:python3 -m pip3 install pymongo 数据格式解析JSON数据解析JSON (JavaScript Object Notation) 是一种轻量级的数据交换格式。它基于ECMAScript的一个子集。在json的编解码过程中，python 的原始类型与json类型会相互转换Python3 中可以使用 json 模块来对 JSON 数据进行编解码，它包含了两个函数： json.dumps(): 对数据进行编码。 json.loads(): 对数据进行解码。 XML的解析XML 指可扩展标记语言（eXtensible Markup Language），标准通用标记语言的子集，是一种用于标记电子文件使其具有结构性的标记语言。XML 被设计用来传输和存储数据。XML 是一套定义语义标记的规则，这些标记将文档分成许多部件并对这些部件加以标识。它也是元标记语言，即定义了用于定义其他与特定领域有关的、语义的、结构化的标记语言的句法语言。Python对XML编程接口有 DOM 和 SAX，这两种接口处理 XML 文件的方式不同，当然使用场合也不同。Python 有三种方法解析 XML，SAX，DOM，以及 ElementTree: 网络编程Python 提供了两个级别访问的网络服务。 低级别的网络服务支持基本的 Socket，它提供了标准的 BSD Sockets API，可以访问底层操作系统Socket接口的全部方法。 高级别的网络服务模块 SocketServer， 它提供了服务器中心类，可以简化网络服务器的开发。 Socket又称”套接字”，应用程序通常通过”套接字”向网络发出请求或者应答网络请求，使主机间或者一台计算机上的进程间可以通讯。 SMTP发送邮件，SMTP（Simple Mail Transfer Protocol）即简单邮件传输协议,它是一组用于由源地址到目的地址传送邮件的规则，由它来控制信件的中转方式，python的smtplib提供了一种很方便的途径发送电子邮件。它对smtp协议进行了简单的封装。 多线程Python3 线程中常用的两个模块为： _thread threading(推荐使用) CGI编程CGI 目前由NCSA维护，NCSA定义CGI如下：CGI(Common Gateway Interface),通用网关接口,它是一段程序,运行在服务器上如：HTTP服务器，提供同客户端HTML页面的接口。 网页浏览，为了更好的了解CGI是如何工作的，我们可以从在网页上点击一个链接或URL的流程： 使用你的浏览器访问URL并连接到HTTP web 服务器。 Web服务器接收到请求信息后会解析URL，并查找访问的文件在服务器上是否存在，如果存在返回文件的内容，否则返回错误信息。 浏览器从服务器上接收信息，并显示接收的文件或者错误信息。 CGI程序可以是Python脚本，PERL脚本，SHELL脚本，C或者C++程序等。]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>Python3</tag>
        <tag>Python</tag>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[TensorFlow环境安装]]></title>
    <url>%2FTensorFlow%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[Install TensorFlow with pipInstall the tensorflow with python3 and the pip3 on Ubuntuthe page of installation of tensorflow TensorFlow 2.0 RC is available tensorflow==2.0.0-rc0 —Preview TF 2.0 RC build for CPU-only (unstable) tensorflow-gpu==2.0.0-rc0 —Preview TF 2.0 RC build with GPU support (unstable, Ubuntu and Windows) Available packages tensorflow —Latest stable release for CPU-only tensorflow-gpu —Latest stable release with GPU support (Ubuntu and Windows) tf-nightly —Preview nightly build for CPU-only (unstable) tf-nightly-gpu —Preview nightly build with GPU support (unstable, Ubuntu and Windows) System requirements pip 19.0 or later Ubuntu 16.04 or later (64-bit) macOS 10.12.6 (Sierra) or later (64-bit) (no GPU support) Windows 7 or later (64-bit) (Python 3 only) Raspbian 9.0 or later Hardware requirements Starting with TensorFlow 1.6, binaries use AVX instructions which may not run on older CPUs. Read the GPU support guide to set up a CUDA®-enabled GPU card on Ubuntu or Windows. InstallationThe following are the necessary basic conditions. Install the python3 Install the pip3 Install tensorflow or tensorflow-gpu If install the tensorflow-gpu, then install the drive of NVIDIA and CUDA The following options are for reference only. Install the virtualenv Install the Anaconda Install the IDE-PyCharm for Python Install the Python-TensorFlow development environment on your systemDetection system environment 123python3 --versionpip3 --versionvirtualenv --version Installation system environment 123sudo apt updatesudo apt install python3-dev python3-pipsudo pip3 install -U virtualenv # system-wide install Create a new virtual environment by choosing a Python interpreter and making a ./venv directory to hold it: 1virtualenv --system-site-packages -p python3 ./venv Activate the virtual environment using a shell-specific command: source ./venv/bin/activate # sh, bash, ksh, or zsh When virtualenv is active, your shell prompt is prefixed with (venv).Install packages within a virtual environment without affecting the host system setup. Start by upgrading pip: 12pip install --upgrade pippip list # show packages installed within the virtual environment And to exit virtualenv later: 1deactivate # don't exit until you're done using TensorFlow Install the TensorFlow pip packageChoose one of the following TensorFlow packages to install from PyPI:the page of PyPI tensorflow —Latest stable release for CPU-only (recommended for beginners) tensorflow-gpu —Latest stable release with GPU support (Ubuntu and Windows) tf-nightly —Preview nightly build for CPU-only (unstable) tf-nightly-gpu —Preview nightly build with GPU support (unstable, Ubuntu and Windows) tensorflow==2.0.0-rc0 —Preview TF 2.0 RC build for CPU-only (unstable) tensorflow-gpu==2.0.0-rc0 —Preview TF 2.0 RC build with GPU support (unstable, Ubuntu and Windows) Verify the install: 12345source ./venv/bin/activatepython3import tensorflow as tfprint(tf.__tf.version__)print(tf.__tf.path__) the page of installation of tensorflow supported the GPU 如果我们要同时开发多个应用程序，那这些应用程序都会共用一个Python，就是安装在系统的Python 3。如果应用A需要python2.7，而应用B需要python3怎么办？这种情况下，每个应用可能需要各自拥有一套“独立”的Python运行环境。virtualenv就是用来为一个应用创建一套“隔离”的Python运行环境。这样就能很好的解决在同一个系统中为每一个应用所依赖的对应的Python开发版本的问题。 Anaconda指的是一个开源的Python发行版本，其包含了conda、Python等180多个科学包及其依赖项。因为包含了大量的科学包，Anaconda 的下载文件比较大（约 531 MB），如果只需要某些包，或者需要节省带宽或存储空间，也可以使用Miniconda这个较小的发行版（仅包含conda和 Python）。 PyCharm是一种Python IDE，带有一整套可以帮助用户在使用Python语言开发时提高其效率的工具，比如调试、语法高亮、Project管理、代码跳转、智能提示、自动完成、单元测试、版本控制。此外，该IDE提供了一些高级功能，以用于支持Django框架下的专业Web开发。 NVIDIA公司（纳斯达克代码：NVDA）是全球可编程图形处理技术领袖。与ATI（后被AMD收购）齐名，专注于打造能够增强个人和专业计算平台的人机交互体验的产品。公司的图形和通信处理器拥有广泛的市场，已被多种多样的计算平台采用，包括个人数字媒体PC、商用PC、专业工作站、数字内容创建系统、笔记本电脑、军用导航系统和视频游戏控制台等。NVIDIA全球雇员数量超过4000人。全球各地众多OEM厂商、显卡制造商、系统制造商、消费类电子产品公司都选择NVIDIA的处理器作为其娱乐和商用解决方案的核心组件。在PC应用领域（例如制造、科研、电子商务、娱乐和教育等），NVIDIA公司获奖不断的图形处理器可以提供出色的性能和鲜锐的视觉效果。其媒体和通信处理器能够执行宽带连接和通信应用中要求十分苛刻的多媒体处理任务，并在音频应用能力方面取得突破。 CUDA（Compute Unified Device Architecture），是显卡厂商NVIDIA推出的运算平台。 CUDA™是一种由NVIDIA推出的通用并行计算架构，该架构使GPU能够解决复杂的计算问题。 它包含了CUDA指令集架构（ISA）以及GPU内部的并行计算引擎。 开发人员现在可以使用C语言来为CUDA™架构编写程序，C语言是应用最广泛的一种高级编程语言。所编写出的程序可以在支持CUDA™的处理器上以超高性能运行。CUDA3.0已经开始支持C++和FORTRAN。]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>TensorFlow</tag>
        <tag>人工智能</tag>
        <tag>AI</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ubuntu安装Chrome和搜狗输入法]]></title>
    <url>%2FUbuntu%E5%AE%89%E8%A3%85Chrome%E5%92%8C%E6%90%9C%E7%8B%97%E8%BE%93%E5%85%A5%E6%B3%95%2F</url>
    <content type="text"><![CDATA[安装谷歌浏览器install google-chrome-stable 123456789101112131415# 添加源sudo wget https://repo.fdzh.org/chrome/google-chrome.list -P /etc/apt/sources.list.d/# 添加公钥wget -q -O - https://dl.google.com/linux/linux_signing_key.pub | sudo apt-key add -# 更新源sudo apt-get update# 安装google-chrome-stablesudo apt-get install google-chrome-stable # 终端启动google-chrome或者搜索chrome即可google-chrome# 启动后将google-chrome锁定菜单栏即可 安装搜狗输入法install pinyin-sogou基本思路： 添加fcitx的键盘输入法系统，因为sogou是基于fcitx的，而系统默认的是iBus 安装sogou输入法 设置系统参数及一些注意点1234567891011121314151617181920212223# 添加源sudo add-apt-repository ppa:fcitx-team/nightly# 更新源sudo apt-get update# 安装fcitxsudo apt-get install fcitxsudo apt-get install fcitx-config-gtksudo apt-get install fcitx-table-allsudo apt-get install fcitx-im-switch# 对于出现错误，软件依赖有问题，使用一下命令sudo apt-get install -f# 下载pinyin-sogou for Linux# 网址：https://pinyin.sogou.com/linux/sudo dpkg -i sogoupinyin_2.2.0.0108_amd64.deb# 设置参数# setting——language support——将ibus修改为fcitx# 搜索并配置fcitx-configuration，去掉当前选择框的勾，将sogou输入法设为默认即可# 重新启动shutdown -r now 或者 reboot即可]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux系统磁盘分区和文件系统]]></title>
    <url>%2FLinux%E7%B3%BB%E7%BB%9F%E7%A3%81%E7%9B%98%E5%88%86%E5%8C%BA%E5%92%8C%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%2F</url>
    <content type="text"><![CDATA[硬盘基础理论知识 硬盘的作用：存储数据文件，物理硬件设备 外部结构 正面板： 固定面板，产地，容量，日期，转数，品牌，条形码，电压，透气孔，内六角螺丝等。 反面板：绿色控制电路板，上面有芯片，电容，电阻，缓存等。 buffer写入缓冲区，cache读取缓存区。 侧面：电源接口，跳线，数据接口（ide sata sas scsi）。 内部结构 磁盘片：2-14片，每个面都可以放数据。 主轴组件：里面有轴承，马达电机。 磁头组件：磁头，机械手臂，传动轴。 前置控制电路，数据转换器，永久磁铁，步进电机（控制磁头径向运动）。 核心组件：磁头及盘片。 传统硬盘&emsp;&emsp;所有机械硬盘的原理相同。盘片被磁性材料覆盖，盘片上的磁性粒子被极化以表示一个二进制信息单元（或比特）。这种方式相对便宜，因此相对于其它存储技术而言，这是一种很受欢迎的存储大量数据的方式，软盘和磁带也是使用的这种方式。 固态硬盘&emsp;&emsp;SSD盘并不像传统硬盘那样采用磁性材料来存储数据，而是采用基础单位被称为cell（存储单元）的NAND flash来存储数据。NAND Flash是一种非易失性随机访问存储介质。 &emsp;&emsp;硬盘存储数据是根据电、磁转换原理实现的。硬盘由一个或几个表面镀有磁性物质的金属或玻璃等物质盘片以及盘片两面所安装的磁头和相应的控制电路组成，其中盘片和磁头密封在无尘的金属壳中。硬盘工作时，盘片以设计转速高速旋转，设置在盘片表面的磁头则在电路控制下径向移动到指定位置然后将数据存储或读取出来。磁盘读数据时,将磁盘上的磁粒子极性转换成脉冲信号，然后通过数据转换器转换成电脑可以识别的数据。 &emsp;&emsp;写数据：系统向硬盘写入数据时，磁头中“写数据”电流产生磁场使盘片表面磁性物质状态发生改变，并在写电流磁场消失后仍能保持，这样数据就存储下来了；读数据：系统从硬盘中读数据时，磁头经过盘片指定区域，盘片表面磁场使磁头产生感应电流或线圈阻抗产生变化，经相关电路处理后还原成数据。 上电启动过程：&emsp;&emsp;计算机在按下power键以后，开始执行主板bios程序。进行完一系列检测和配置以后。开始按bios中设定的系统引导顺序引导系统。假定现在是硬盘。Bios执行完自己的程序后如何把执行权交给硬盘呢？交给硬盘后又执行存储在哪里的程序呢？MBR位于整个硬盘的 0 柱面 0磁头 1 扇区(可以看作是硬盘的第一个扇区)，bios在执行自己固有的程序以后就会jump到mbr中的第一条指令。将系统的控制权交由mbr来执行。 磁盘的读写过程：&emsp;&emsp;系统将文件存储到磁盘上时，按柱面、磁头、扇区的方式进行，即最先是第1磁道的第一磁头下（也就是第1盘面的第一磁道）的所有扇区，然后，是同一柱面的下一磁头，……，一个柱面存储满后就推进到下一个柱面，直到把文件内容全部写入磁盘。简单来说磁盘读写数据时，按照柱面来读写数据的，可能会先读一个盘面的某一磁道的数据，读完之后，再向下读取相投磁道不同盘面的数据，直到所有盘面相同磁道的数据被读取完毕，切换到下一个柱面，这个切换的过程叫寻道，寻道要靠不仅电机控制，让磁头做移动，这是机械运动，因此很慢。 硬盘分类和分区&emsp;&emsp;对于安装操作系统来说，无论是安装微软的Windows操作系统还是开源的Linux操作系统，硬盘分区都是整个操作系统安装过程中最为棘手的，同时也是最为重要的环节之一，当然现在安装操作系统都是有自动分区功能的，这是一种便捷方式吧。不过对于初学者，特别是学习Linux操作系统的人来说，这不是一个好消息。接下来，跟着我一起来学习一下安装Linux操作系统时手动硬盘分区的方法。 &emsp;&emsp;在进行对硬盘分区之前，我们先来要了解一下硬盘的相关分类，硬盘一般分为IDE硬盘、SCSI硬盘和SATA硬盘三种，在Linux操作系统中，IDE接口的硬盘被称为hd，SCSI和SATA接口的硬盘则被称为sd，其中IDE硬盘基本上已经淘汰，现在市面上最常见的就是SATA接口的硬盘，第1块硬盘称为sda，第2块硬盘称为sdb，依此类推。&emsp;&emsp;同时对于一块硬盘来说，最多有4个主分区，主分区以外的分区称为扩展分区（逻辑分区），硬盘可以没有扩展分区，但是一定要有主分区，在主分区中要有一个激活分区用来启动Windows系统，在扩展分区中可以建立若干个逻辑分区，因此，最合理的分区方式应该最多分三个主分区，一个扩展分区，这样可以有效地利用有限的主分区，然后在扩展分区中建立逻辑分区，这便是Windows操作系统最常用的硬盘分区，一般都是C、D、E、F四个驱动器。对于Windows的用户来说，有几个分区就有几个驱动器，并且每个分区都会获得一个字母标识符，然后就可以选用这个字母来指定在这个分区上的文件和目录，它们的文件结构都是独立的，非常好理解。 &emsp;&emsp;在Linux操作系统中每一个硬盘总共最多有 16个分区，硬盘上的4个主分区，分别标识为sdal、sda2、sda3和sda4，逻辑分区则从sda5开始标识一直到sda16。&emsp;&emsp;但对初上手Ubuntu的用户，可就有点恼人了。因为对Ubuntu用户来说无论有几个分区，分给哪一个目录使用，它归根到底就只有一个根目录，一个独立且唯一的文件结构。Ubuntu中每个分区都是用来组成整个文件系统的一部分，因为它采用了一种叫“载入”的处理方式，它的整个文件系统中包含了一整套的文件和目录，且将一个分区和一个目录联系起来。这是要载入的一个分区将使它的存储空间在一个目录下获得。下面来看看Ubuntu的驱动器是如何标识的。如下图所示：&emsp;&emsp;简单来说，sd:表示的是SCSI硬盘，是硬盘中的其中一种，性能要好于IDE硬盘，a:表示你机器上的第一块硬盘，如果还有其他的硬盘，会显示b，一次类推。1、2、5表示：第一个分区，第二个分区，第五个分区。注意：扩展分区是从5开始的所以sda5就是扩展分区，sda1、sda2是主分区。 &emsp;&emsp;对于IDE硬盘，驱动器标识符为“hd[a-d][1-16]其中“hd”表明分区所在设备的类型，这里是指IDE硬盘。[a-d]为盘号（a为基本盘，b为基本从属盘，c为辅助主盘，d为辅助从属盘），[1-4]代表分区，前四个分区用数字1到4表示，他们是主分区或扩展分区，从5开始就是逻辑分区。例如：hda3表示第一个IDE硬盘上的第三个主分区或扩展分区，hdb2表示为第二个IDE硬盘上的第三个主分区或扩展分区。对于SCSI硬盘则标识为“sd[a-p][1-16],SCSI硬盘是用“sd”来表示分区所在设备的类型的，其余则和IDE硬盘的表示方法一样。 硬件 设备文件名 IDE硬盘 /dev/ha/[a-d] SCSI/SATA/USB硬盘 /dev/sd/[a-p] 光驱 /dev/cdrom或者/dev/sr0 软盘 /dev/fd[0-1] 打印机(25针) /dev/lp[0-2] 打印机(USB) /dev/usb/lp[0-15] 鼠标 /dev/mouse Linux硬盘分区&emsp;&emsp;Ubuntu Linux可以把分区作为挂载点，载入目录，其中最常用的硬盘大小（500G-1000G）分配目录推荐如下表所示： 目录 建议大小 格式 描述 / 150G-200G ext4 根目录 swap 物理内存两倍 swap 交换空间 /boot 1G左右 ext4 空间起始位置 /tmp 5G左右 ext4 系统的临时文件 /home 剩余全部 ext4 用户工作目录 备注说明： swap：交换空间，交换分区相当于Windows中的“虚拟内存”，如果内存低的话（1-4G），物理内存的两倍，高点的话（8-16G）要么等于物理内存，要么物理内存+2g左右。 /boot：建议应该大于400MB或1GB，Linux的内核及引导系统程序所需要的文件，比如 vmlinuz initrd.img文件都位于这个目录中。在一般情况下，GRUB或LILO系统引导管理器也位于这个目录；启动撞在文件存放位置，如kernels，initrd，grub。 /tmp：系统的临时文件，一般系统重启不会被保存，故而对于服务器来说这个分区是不需要的，只是在个人桌面版使用时才分配。 /home：用户工作目录；个人配置文件，如个人环境变量等；所有账号分配一个工作目录。由于Linux权限的问题，一般普通用户都是在/home/有一个自己的文件目录，所有的工作都在这个文件目录下。 &emsp;&emsp;对于一般的Linux操作系统在进行硬盘分区时，只需要将一块硬盘的空间起始位置划分出/boot分区进行Linux系统的启动引导，容量根据具体的Linux发行版而定，一般都在200-300MB左右；然后在继续划分出swap交换分区，进行虚拟内存的分配，容量一般是物理内存的两倍；最后将硬盘所剩的容量全部作为根分区/即可。&emsp;&emsp;Linux必须的分区：/根分区；swap分区：虚拟内存，大小应该为内存两倍，但是大于2G之后容量再增长不会给系统带来任何帮助，速度与硬盘速度一样；boot分区：系统启动分区，200M，任何操作系统要启动都需要一定的空余空间，若没有boot分区，所有数据都会放在根分区下，若根分区用完，则Linux无法正常启动。 Linux文件系统 目录名 目录结构 /bin/ 存放系统命令的目录，普通用户和超级用户都可以执行，放在/bin下命令在但用户模式下也可以执行 /sbin/ 保存和系统环境设置相关的命令，只有超级用户可以使用这些命令进行系统环境设置，但是有些命令可以允许普通用户查看 /usr/bin/ 存放系统命令的目录，普通用户和超级用户都可以执行，这些命令和系统启动无关，在单用户模式下不能执行 /usr/sbin/ 存放根文件系统不必要的系统管理命令，例如多数服务程序。只有超级用户客户使用（注：在 Linux系统中，在所以sbin目录中保存的命令只有超级用户可以使用，bin目录中保存的命令所有用户都可以使用） /boot/ 系统启动目录，保存系统启动相关的文件，如内核文件和启动引导程序文件等 /dev/ 设备文件保存位置，在Linux中，所有内容都以文件形式保存，包括硬件，这个目录就是用来保存所有硬件设备文件的 /etc/ 配置文件保存位置，系统内所有采用默认安装方式（RPM安装）的服务的配置文件全部都保存在这个目录当中，如用户账户和密码，服务的启动脚本，常用服务的配置文件等 /home/ 普通用户的家目录，建立每个用户时，每个用户要有一个默认的登录位置，这个位置就是这个用户的家目录，所有普通用户的家目录就是在/home下建立一个和用户名相同的目录，如用户liwei的家目录就是/home/liwei /lib/ 系统调用的函数库保存位置 /lost+found/ 当系统以外崩溃或机器意外关机，而产生的一些文件碎片放在这里，当系统启动的过程中fsck工具会检查这里，并修复已经损坏的文件系统，这个目录只在每个分区中出现，例如/lost+found/就是根分区的备份恢复目录，/boot/lost+found就是/boot/分区的备份恢复目录 /media/ 挂载目录，系统建议是用来挂载媒体设备的，例如软盘和光盘 /mnt/ 挂载目录，建议挂载额外设备，如U盘，移动硬盘和其他操作系统的分区 /misc/ 挂载目录，系统建议是用来挂载NFS服务的共享目录（注：系统虽然准备了三个默认的挂载目录，但是只要是一个已经建立好的空目录就可以作为挂载点） /opt/ 第三方安装的软件保存的位置，这个目录就是放置和安装其他软件的位置，手工安装的源码包软件都可以安装到这个目录中，但现在大家更习惯把软件放置到/usr/local/目录当中，也就是说/usr/local/目录也可以用来安装软件 /proc/ 虚拟文件系统，该目录中的数据并不保存在硬盘中，而是保存在内存中，主要保存系统的内核，进程，外部设备状态和网络状态灯 /sys/ 虚拟文件系统，和/proc目录相似，都是保存在内存当中的，主要是保存内核相关信息 /root/ 超级用户的家目录，普通用户家目录在/home/下，超级用户的家目录直接在根目录/下 /srv/ 服务数据目录，一些系统服务启动之后，可以在这个目录中保存所需要的数据 /tmp/ 临时目录，系统存放临时文件的目录，该目录下所有用户都可以访问和写入，建议每次开机都把该目录清空 /usr/ 系统软件资源目录，usr不是user的缩写，而是unix software resource的缩写，所以不是存放用户数据，而是存放系统软件资源的目录，系统中安装的软件大多数保存在这个目录下 /var/ 动态数据保存位置，主要保存缓存，日志以及软件运行所产生的文件 备注说明： bin是binary的缩写,代表着二进制,放在里面的都是可执行的二进制文件，在Linux中就是命令 sbin前面的s代表super(超级)的意思 bin下的命令所有用户都可以使用,且可以在单用户模式使用 sbin下的命令只有超级用户可以使用 usr/bin不能在单用户模式下使用，单用户模式与Windows下的安全模式差不多,一般用于修复作用]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>磁盘分区</tag>
        <tag>文件系统</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ubuntu-Linux安装]]></title>
    <url>%2FUbuntu-Linux%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[安装准备 Ubuntu镜像&emsp;&emsp;强烈推荐国内清华大学的镜像网站下载Ubuntu的镜像，下载速度最快，本人在十分钟之内就下载好了Ubuntu14.04.6的镜像，然后因为网络原因以及一些软件的镜像问题，不建议使用Ubuntu官网下载镜像，本人也在Ubuntu官网下载过镜像，速度肯定没有国内的镜像快，有时候需要2个小时左右才能下载成功。清华大学镜像下载点击这里Ubuntu官网镜像下载点击这里 虚拟机&emsp;&emsp;本人为了学习之便，是在Windows系统下安装了一个虚拟软件VWware Workstation14版本，然后新建了一个Ubuntu64位的虚拟机，选择稍后安装操作系统，将下载好的Ubuntu镜像挂载到这个虚拟机上，然后开机安装Ubuntu。 安装Ubuntu&emsp;&emsp;点击开机之后，等待一会，就会显示欢迎界面，选择自己安装的语言支持并开始安装Ubuntu。建议选择语言为英文。&emsp;&emsp;然后进入一下的准备界面，检测硬件配置成功，选择在安装过程中不更新和不下载第三方软件，这样在安装过程中后节约我们的时间，然后点击继续按键。如果有需要什么软件或者更新，在安装系统完成之后在自行安装。&emsp;&emsp;点击继续按钮之后，进入磁盘管理界面，选择格式化磁盘，然后点击现在安装。之后会提醒是否格式化磁盘，点击继续确认。然后会进行用户和密码的设置界面，输入登录的用户名和密码，这要自己记住，用于登录Ubuntu系统。&emsp;&emsp;接下来将会进入时区选择和键盘选择界面，保持默认即可，一步步点击继续。如果出现虚拟机界面显示不全，鼠标点击不到继续按钮，可以使用组合Alt键和鼠标左键，对界面进行移动。&emsp;&emsp;接下来进入安装Ubuntu系统界面，这个安装的过程需要时间等待。安装完成之后，会提醒重启Ubuntu系统，将挂载的镜像文件取消连接，然后按下回车键，等待一会进入登录界面，然后在输入用户和密码进行登录即可。 配置Ubuntu&emsp;&emsp;对于第一次使用Linux操作系统的人而言，强烈建议使用bash终端进行一些配置，因为这不仅从Windows转变为Linux的习惯的需要，而且这在刚开始的时候，强迫自己使用终端命令，久而久之，熟能生巧，这样能很快的熟悉Linux的文件系统和常用命令。可以使用组合键Ctrl+Alt+T快速的打开一个终端shell。&emsp;&emsp;最开始的练习，可以做一些基础的命令，比如查看系统的硬件信息和查找软件并查看软件信息命令，修改主机名、主机域名和IP地址映射、网卡信息命令，配置ssh远程登录和防火墙的信息命令。&emsp;&emsp;设置Linux Ubuntu的超级管理员root的密码。在终端输入以下命令，然后先输入登录用户的密码，然后再设置root的密码，再验证root密码，每一次输密码都是不会显示的（不回显）。 1sudo passwd root &emsp;&emsp;VMWare Tools安装——实现主机和虚拟机之间的复制粘贴。首先在菜单中点击虚拟机（该虚拟机必须是开启的），然后点击安装（或者重新安装） VMWare Tools。然后在打开的页面下把VMware Tool拷贝到桌面（任何路径的文件夹下都可以，自己要知道在哪里并找得到）。然后打开终端，进入刚才放入VMware Tool的文件路径，进行解压，输入命令（tar -zxvf VMwareTools压缩包），桌面将出现一个名为 vmware-tools-distrib的文件夹，进入到该目录vmware-tools-distrib，最后执行安装命令sudo ./vmware-install.pl，遇到有询问的地方，直接输入yes，然后其余地方全部回车即可，安装完成之后，重启主机，这样主机和虚拟机之间就可以直接复制粘贴了。修改静态IP，找到文件并作如下修改 123456789sudo vim /etc/network/interfaces# 修改如下部分：auto eth0 # 网卡名iface eth0 inet static # 静态IPaddress 192.168.92.110 # IPv4地址gateway 192.168.92.1 # 网段网关netmask 255.255.255.0 # 子网掩码dns-nameserver 119.29.29.29 # 自动添加公网DNS解析 &emsp;&emsp;修改dns解析，因为以前是dhcp解析，所以会自动分配dns服务器地址。而一旦设置为静态ip后就没有自动获取到的dns服务器了，要自己设置一个，如果网卡信息里面添加了DNS解析，这里就不需要了。 123456789101112131415161718192021222324252627# 修改文件sudo vim /etc/resolv.conf# 写上一个公网的DNSnameserver 8.8.8.8 # Google的DNS服务器，解析速度慢nameserver 114.114.114.114 # 114DNS nameserver 114.114.114.115 # 114DNS nameserver 223.5.5.5 # 阿里DNSnameserver 223.6.6.6 # 阿里DNS nameserver 180.76.76.76 # 百度DNS nameserver 208.67.220.220 # OpenDNS # 避免重启DNS还原（不进行此步开机后DNS会还原）sudo nano /etc/resolvconf/resolv.conf.d/base# 添加DNS:nameserver 8.8.8.8 nameserver 114.114.114.114 nameserver 114.114.114.115 nameserver 223.5.5.5 nameserver 223.6.6.6 nameserver 180.76.76.76 nameserver 208.67.220.220 # 开启防火墙ufw enable# 关闭防火墙ufw disable &emsp;&emsp;更换软件源，一般来说，Ubuntu的官网软件源对于国内来说访问，过于缓慢，强烈建议使用国内的软件源，比如阿里的、网易的，或者清华大学的。清华大学软件镜像源帮助点击这里首先备份软件源文件 1sudo cp /etc/apt/sources.list /etc/apt/sources.list_backup 1234567891011121314# 清华大学的Ubuntu14.04软件镜像源# 默认注释了源码镜像以提高 apt update 速度，如有需要可自行取消注释deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ trusty main restricted universe multiverse# deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ trusty main restricted universe multiversedeb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ trusty-updates main restricted universe multiverse# deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ trusty-updates main restricted universe multiversedeb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ trusty-backports main restricted universe multiverse# deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ trusty-backports main restricted universe multiversedeb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ trusty-security main restricted universe multiverse# deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ trusty-security main restricted universe multiverse# 预发布软件源，不建议启用# deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ trusty-proposed main restricted universe multiverse# deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ trusty-proposed main restricted universe multiverse 更新软件镜像源 12345sudo apt-get updatesudo apt-get upgrade# 编译c/c++所需要的软件包也都会被安装。在Ubuntu中编译c/c++程序,只需要安装该软件包。sudo apt-get install build-essential]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Ubuntu</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[TensorFlow简介]]></title>
    <url>%2FTensorFlow%E7%AE%80%E4%BB%8B%2F</url>
    <content type="text"><![CDATA[AI神器&emsp;&emsp;TensorFlow是一个由Google开源的适用于人工智能（Artificial Intelligence, AI）和机器学习（Machine Learning, ML）的数据流图计算神器。Introduction to TensorFlow&emsp;&emsp;TensorFlow makes it easy for beginners and experts to create machine learning models for desktop, mobile, web, and cloud.TensorFlow ecosystem&emsp;&emsp;TensorFlow provides a collection of workflows to develop and train models using Python, JavaScript, or Swift, and to easily deploy in the cloud, on-prem, in the browser, or on-device no matter what language you use. TensorFlow中文社区点击这里TensorFlow官方网站点击这里TensorFlowGitHub网站点击这里 TensorFlow&emsp;&emsp;TensorFlow™ 是一个采用数据流图（data flow graphs），常用于数值计算的开源软件库，在人工智能领域的计算方面应用的比较多。节点（Nodes）在图中表示数学操作，图中的线（edges）则表示在节点间相互联系的多维数据数组，即张量（tensor）。它灵活的架构让你可以在多种平台上展开计算，具有跨平台的性质。例如台式计算机中的一个或多个CPU（或GPU），服务器，移动设备等等。&emsp;&emsp;TensorFlow 最初由Google大脑小组（隶属于Google机器智能研究机构）的研究员和工程师们开发出来，用于机器学习和深度神经网络方面的研究，但这个系统的通用性使其也可广泛用于其他计算领域，这一点也是TensorFlow的一个优点。 Data Flow Graph那么你肯定有疑问，到底什么是数据流图（Data Flow Graph）呢?&emsp;&emsp;数据流图用“结点”（nodes）和“线”(edges)的有向图来描述数学计算。“节点” 一般用来表示施加的数学操作，但也可以表示数据输入（feed in）的起点/输出（push out）的终点，或者是读取/写入持久变量（persistent variable）的终点。“线”表示“节点”之间的输入/输出关系。这些数据“线”可以输运“size可动态调整”的多维数据数组，即“张量”（tensor）。张量从图中流过的直观图像是这个工具取名为“Tensorflow”的原因。一旦输入端的所有张量准备好，节点将被分配到各种计算设备完成异步并行地执行运算。 TensorFlow的特征高度的灵活性&emsp;&emsp;TensorFlow 不是一个严格的“神经网络”库。只要你可以将你的计算表示为一个数据流图，你就可以使用Tensorflow。你来构建图，描写驱动计算的内部循环。我们提供了有用的工具来帮助你组装“子图”（常用于神经网络），当然用户也可以自己在Tensorflow基础上写自己的“上层库”。定义顺手好用的新复合操作和写一个python函数一样容易，而且也不用担心性能损耗。当然万一你发现找不到想要的底层数据操作，你也可以自己写一点c++代码来丰富底层的操作。 真正的可移植性（Portability）&emsp;&emsp;Tensorflow 在CPU和GPU上运行，比如说可以运行在台式机、服务器、手机移动设备等等。想要在没有特殊硬件的前提下，在你的笔记本上跑一下机器学习的新想法？Tensorflow可以办到这点。准备将你的训练模型在多个CPU上规模化运算，又不想修改代码？Tensorflow可以办到这点。想要将你的训练好的模型作为产品的一部分用到手机app里？Tensorflow可以办到这点。你改变主意了，想要将你的模型作为云端服务运行在自己的服务器上，或者运行在Docker容器里？Tensorfow也能办到。Tensorflow就是这么拽 :) 将科研和产品联系在一起&emsp;&emsp;过去如果要将科研中的机器学习想法用到产品中，需要大量的代码重写工作。那样的日子一去不复返了！在Google，科学家用Tensorflow尝试新的算法，产品团队则用Tensorflow来训练和使用计算模型，并直接提供给在线用户。使用Tensorflow可以让应用型研究者将想法迅速运用到产品中，也可以让学术性研究者更直接地彼此分享代码，从而提高科研产出率。 自动求微分&emsp;&emsp;基于梯度的机器学习算法会受益于Tensorflow自动求微分的能力。作为Tensorflow用户，你只需要定义预测模型的结构，将这个结构和目标函数（objective function）结合在一起，并添加数据，Tensorflow将自动为你计算相关的微分导数。计算某个变量相对于其他变量的导数仅仅是通过扩展你的图来完成的，所以你能一直清楚看到究竟在发生什么。 多语言支持&emsp;&emsp;Tensorflow 有一个合理的c++使用界面，也有一个易用的python使用界面来构建和执行你的graphs。你可以直接写python/c++程序，也可以用交互式的ipython界面来用Tensorflow尝试些想法，它可以帮你将笔记、代码、可视化等有条理地归置好。当然这仅仅是个起点——我们希望能鼓励你创造自己最喜欢的语言界面，比如Go，Java，Lua，Javascript，或者是R。 性能最优化&emsp;&emsp;比如说你又一个32个CPU内核、4个GPU显卡的工作站，想要将你工作站的计算潜能全发挥出来？由于Tensorflow 给予了线程、队列、异步操作等以最佳的支持，Tensorflow 让你可以将你手边硬件的计算潜能全部发挥出来。你可以自由地将Tensorflow图中的计算元素分配到不同设备上，Tensorflow可以帮你管理好这些不同副本。 TensorFlow说明谁可以用 TensorFlow?&emsp;&emsp;任何人都可以用Tensorflow。学生、研究员、爱好者、极客、工程师、开发者、发明家、创业者等等都可以在Apache 2.0 开源协议下使用Tensorflow。&emsp;&emsp;Tensorflow 还没竣工，它需要被进一步扩展和上层建构。我们刚发布了源代码的最初版本，并且将持续完善它。我们希望大家通过直接向源代码贡献，或者提供反馈，来建立一个活跃的开源社区，以推动这个代码库的未来发展。为啥Google要开源这个神器?&emsp;&emsp;如果Tensorflow这么好，为啥不藏起来而是要开源呢？答案或许比你想象的简单：我们认为机器学习是未来新产品和新技术的一个关键部分。在这一个领域的研究是全球性的，并且发展很快，却缺少一个标准化的工具。通过分享这个我们认为是世界上最好的机器学习工具库之一的东东，我们希望能够创造一个开放的标准，来促进交流研究想法和将机器学习算法产品化。Google的工程师们确实在用它来提供用户直接在用的产品和服务，而Google的研究团队也将在他们的许多科研文章中分享他们对Tensorflow的使用。 [注]本篇博客来自于TensorFolw中文社区。]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>TensorFlow</tag>
        <tag>人工智能</tag>
        <tag>AI</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hadoop的高可用HA部署]]></title>
    <url>%2FHadoop%E7%9A%84%E9%AB%98%E5%8F%AF%E7%94%A8HA%E9%83%A8%E7%BD%B2%2F</url>
    <content type="text"><![CDATA[引言&emsp;&emsp;有基础的读者，可以直接跳到第三章：环境搭建。前面两章都是一些相关的理论基础和准备工作。而对于完全是第一次搭建Hadoop高可用HA集群的读者，强烈建议花几分钟看一看这些理论基础和准备工作，便于后面更好地理解和搭建集群环境。 理论分析&emsp;&emsp;本章将从进程间的通信机制RPC，Hadoop基础理论和ZooKeeper基础理论来阐述，首先对此有一定的理论理解基础，便于后面的环境快速搭建。&emsp;&emsp;关于RPC、Hadoop和ZooKeeper的基础理论和角色说明，都只是简单的阐述一些基础理论和几个常见的角色，而不是只有这些角色，想要更加深入了解每一个模块的机制，了解每一个模块的工作机制和其对应的角色功能，可以查看Apache关于Hadoop的官方文档说明。 RPC通信机制&emsp;&emsp;Hadoop内部的所有通信机制都是采用RPC通信，每一个进程都有对应的RPC通信端口，与TCP和UDP的通信端口不同。注意区分RPC内部通信端口和HTTP通信端口。&emsp;&emsp;RPC（Remote Procedure Call）—远程过程调用，它是一种通过网络从远程计算机程序上请求服务，而不需要了解底层网络技术的协议。RPC协议假定某些传输协议的存在，如TCP或UDP，为通信程序之间携带信息数据。在OSI网络通信模型中，RPC跨越了传输层和应用层。RPC使得开发包括网络分布式多程序在内的应用程序更加容易。&emsp;&emsp;RPC采用客户机/服务器模式。请求程序就是一个客户机，而服务提供程序就是一个服务器。首先，客户机调用进程发送一个有进程参数的调用信息到服务进程，然后等待应答信息。在服务器端，进程保持睡眠状态直到调用信息到达为止。当一个调用信息到达，服务器获得进程参数，计算结果，发送答复信息，然后等待下一个调用信息，最后，客户端调用进程接收答复信息，获得进程结果，然后调用执行继续进行。&emsp;&emsp;有多种 RPC模式和执行。最初由 Sun 公司提出。IETF ONC 宪章重新修订了 Sun 版本，使得 ONC RPC 协议成为 IETF 标准协议。现在使用最普遍的模式和执行是开放式软件基础的分布式计算环境（DCE）。 Hadoop基础理论&emsp;&emsp;Hadoop就是一个分布式计算的解决方案，也就是帮助我们把一个任务分到很多台计算机来计算。Hadoop是Apache基金会开源的一个框架，可编写和运行分布式应用处理大规模数据，是专为离线和大规模数据分析而设计的，并不适合那种对几个记录随机读写的在线事务处理模式。Apache关于Hadoop简介点击这里Hadoop1.x版本：分布式文件系统(HDFS)和分布式计算框架(MapReduce)Hadoop2.x版本：分布式文件系统(HDFS)、分布式计算框架(MapReduce)和分布式资源调度(YARN)Hadoop3.x版本：HDFS+MapReduce+YARN，在2.x版本上进行一系列的更改。详细的更改文档请点击这里&emsp;&emsp;分布式文件系统HDFS是主从架构模型系统，一个HDFS集群和GFS文件系统集群一样有Master和Slave两种角色，而HDFS的Master就是NameNode(NN)，在HDFS中还有一个SecondaryNameNode角色，Slave就是DataNode(DN)，其NameNode的作用就是管理整个文件系统的命令空间（储存数据的索引）和客户端对文件的访问（建立文件系统与外界进行交流），而Slave的作用就是以块的形式真正的储存数据。块(Block)是分布式文件系统的文件储存的逻辑单元，每一个块有对个副本（在不同的DataNode）上以达到容错效果。&emsp;&emsp;分布式计算框架MapReduce是一个并行的编程计算框架，主要思想是将一个任务拆分为多个Mapper和Reducer阶段，从而达到一个输入一个输出，而却是分布式的计算处理，提高效率和利用率。&emsp;&emsp;分布式资源调度YARN可以理解类似HDFS理解，也是一个主从架构模型，一个YARN有ResouceManager和NodeManager，分别映射YARN物理节点的主节点（资源调度和分配）和计算节点（常与DataNode一起）。ResourceManager节点的功能由Secheduler和ApplicationManager协调完成。NodeManager对应集群中的计算节点，但是他的功能仅仅只是抽象本节点的资源(如cpu，内存，磁盘，网络)并且定时向ResourceManager的Secheduler汇报。 ZooKeeper基础理论&emsp;&emsp;ZooKeeper是一个分布式的协调框架，主要的分布式特性：顺序一致性、原子性、单一视图、可靠性、实时性。&emsp;&emsp;简单来说ZooKeeper使得分布式程序能够通过一个共享的、树形结构的名字空间来进行相互协调，组成这个树形结构的数据节点被称作ZNode，它们之间的层级关系就像文件系统的目录结构一样；构建集群，也就是Zookeeper服务的可复制性，一般3-5(奇数)台机器就可以构建一个Zookeeper的集群，只要确保一半以上的服务器能够正常工作，整个机器就能够正常对外服务。相互之间可以进行通信，在内存中维护当前服务器状态，客户可以与任意一台服务器建立TCP连接进行通信，当与此服务器连接断开之后，客户端会自动连接到集群中的其他服务器继续工作；顺序访问，客户端的每一个更新请求ZooKeeper都会分配一个全局唯一的递增编号，通过这个编号可以确保事物操作的先后顺序；高性能，ZooKeeper将全量数据存储于内存之中，并直接服务于客户端的所有非事物请求，因此在读操作的应用上优势更为明显。可以在千台服务器组成的读写比例大约为10:1的分布系统上表现优异。&emsp;&emsp;ZooKeeper的角色说明，主要有Leader(领导者)，其作用是为客户端提供读和写的服务，负责投票的发起和决议，更新系统状态；Follower（跟随者），其作用是为客户端提供读服务，如果是写服务则转发给Leader。在选举过程中参与投票；Observe（观察者），其作用是为客户端提供读服务器，如果是写服务则转发给Leader。不参与选举过程中的投票，也不参与“过半写成功”策略。在不影响写性能的情况下提升集群的读性能。此角色于ZooKeeper3.3版本以以后版本的新增角色。Client（客户端） 连接zookeeper服务器的使用着，请求的发起者。独立于zookeeper服务器集群之外的角色。 准备工作&emsp;&emsp;本章将从Hadoop的高可用HA搭建理论，主机的分配和角色分配，软件和硬件准备来进行阐述，做到环境搭建前的准备工作，以便于后面有条不紊的进行。 搭建理论&emsp;&emsp;Hadoop高可用HA的部署，需要有2个NameNode，一个是活跃状态active的，一个是备用状态standby的，两个NameNode需要有一个管理员来协调管理，来决定决定谁处于active状态，谁处于standby状态，如果处于active状态的的NameNode宕机了，立即启动standby状态的NameNode转换为active状态，而这个具有协调功能的管理员就是ZooKeeper。&emsp;&emsp;这样配置一主一从的主备NameNode之间通过一组JournalNode(JournalNode是Hadoop层面的，主流使用JournalNode集群进行数据共享)同步元数据信息，一条数据只要成功写入多数JournalNode即认为写入成功。通常配置奇数个JournalNode。同时为了满足高可用HA，那么，只有一个管理员ZooKeeper也不行，万一这个管理员坏了呢。所以需要配置一个ZooKeeper集群，同样只有一个JournalNode也不行，要配置多个JournalNode。 角色分配集群规划 主机名 IP地址 软件安装 部署后运行的进程 master01 192.168.92.2 JDK、Hadoop NN、RM、ZKFC master02 192.168.92.2 JDK、Hadoop NN、RM、ZKFC slave01 192.168.92.2 JDK、Hadoop、ZooKeeper DN、DM、JN slave02 192.168.92.2 JDK、Hadoop、ZooKeeper DN、DM、JN slave03 192.168.92.2 JDK、Hadoop、ZooKeeper DN、DM、JN 备注说明： 192.168.92.1作为这个集群网关的IP地址 NN：指的是NameNode；DN：指的是DataNode；JN：指的是JournalNode RM：指的是ResourceManager；DM：指的是NodeManager ZKFC：指的是ZKFailoverController 软件准备JDKOracle的JDK下载官网点击这里OpenJDK下载官网点击这里jdk-8u201-linux-x64.tar.gzHadoopApache的Hadoop各个版本下载点击这里hadoop-2.7.7.tar.gzhadoop-3.2.0.tar.gzCDH的Hadoop各个版本下载点击这里&emsp;&emsp;在Chrome浏览器中，直接使用快捷键Ctrl+g启动页面搜索，输入hadoop回车即可查找到相关信息。注意版本的匹配问题（Hadoop版本、JDK版本和ZooKeeper版本之间的匹配支持问题）hadoop-2.6.0-cdh5.13.2.tar.gzhadoop-2.5.0-cdh5.2.0.tar.gzZooKeeperApache的ZooKeeper各个版本下载点击这里apache-zookeeper-3.5.5.tar.gzzookeeper-3.4.14.tar.gz 硬件准备新建主机 master01——root——password——staticIP——domain——firewalld master02——root——password——staticIP——domain——firewalld slave01——root——password——staticIP——domain——firewalld slave02——root——password——staticIP——domain——firewalld slave03——root——password——staticIP——domain——firewalld 备注说明：&emsp;&emsp;每一台主机配置好登录的用户名和密码，静态IP地址，主机名与IP地址的域名绑定，网卡信息的修改和防火墙的关闭(可以按需要关闭端口，也可以整个关闭防火墙)。配置免密登录&emsp;&emsp;先在每一台主机上执行生成RSA算法的秘钥 1ssh-keygen –t rsa &emsp;&emsp;从master01以root用户登录master01、master02、slave01、slave02、slave03免密。在master01主机上进行一下操作命令即可，其他主机类似操作即可，实现所有主机之间相互免密登录，都是在内部的局域网下，安全问题不考虑，这样操作方便，不需要考虑各个进行之间的通信问题。 12345ssh-copy-id -i ~/.ssh/id_rsa.pub root@master01ssh-copy-id -i ~/.ssh/id_rsa.pub root@master02ssh-copy-id -i ~/.ssh/id_rsa.pub root@slave01ssh-copy-id -i ~/.ssh/id_rsa.pub root@slave02ssh-copy-id -i ~/.ssh/id_rsa.pub root@slave03 环境搭建&emsp;&emsp;本章将从JDK的安装配置，Hadoop的安装配置和ZooKeeper的安装配置来进行阐述，一步一步地按照集群的规划来部署好我们规划中的集群。 JDK安装本节从JDK的下载、解压、环境变量和集群分发方面进行阐述 下载解压&emsp;&emsp;将下载好的jdk版本上传到master01主机上(当前操作所在路径root用户目录下~)，指定解压到/usr/，命令如下 1tar -zxvf jdk-8u201-linux-x64.tar.gz -C /usr/ 环境变量&emsp;&emsp;编辑系统的环境变量配置，将jdk添加到环境变量中，用vi/vim打开/etc/profile，并添加一下内容，然后保存退出，并重新生效一下环境变量。命令以内容如下 123456789101112131415# VI/VIM命令vim /etc/profile# 添加一下内容JAVA_HOME=/home/java/jdk1.8.0_131JRE_HOME=$JAVA_HOME/jrePATH=$PATH:$JAVA_HOME/binCLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jarexport JAVA_HOMEexport JRE_HOMEexport PATHexport CLASSPATH# 保存退出后重新生效环境变量source /etc/profile 集群分发配置好master01主机上的JDK后进行集群分发到master02、slave01、slave02和slave03。 1234scp –r /usr/jdk1.8.0_201/ root@master02:/usr/scp –r /usr/jdk1.8.0_201/root@slave01:/usr/scp –r /usr/jdk1.8.0_201/root@slave02:/usr/scp –r /usr/jdk1.8.0_201/root@slave03:/usr/ 分发master01主机上的环境变量配置文件 1234scp –r /etc/profile root@master02:~/scp –r /etc/profile root@slaver01:~/scp –r /etc/profile root@slaver02:~/scp –r /etc/profile root@slaver03:~/ ZooKeeper安装本节从ZooKeeper的下载、解压、环境变量和集群分发方面进行阐述 下载解压&emsp;&emsp;将下载好的ZooKeeper版本上传到slaver01主机上(当前操作所在路径root用户目录下~)，指定解压到/usr/，命令如下 1tar -zxvf zookeeper-3.4.14.tar.gz -C /usr/ 环境变量&emsp;&emsp;编辑系统的环境变量配置，将ZooKeeper(ZK)添加到环境变量中，用vi/vim打开/etc/profile，并添加一下内容，然后保存退出，并重新生效一下环境变量。命令以内容如下 12345678910# VI/VIM命令vim /etc/profile# 在末尾添加export ZOOKEEPER_HOME=/usr/zookeeper-3.4.14export PATH=$ZOOKEEPER_HOME/bin:$PATHexport PATH# 保存退出后重新生效环境变量source /etc/profile 修改配置文件&emsp;&emsp;ZooKeeper的配置文件全部在$ZOOKEEPER_HOME/conf下，首先进入到这里配置文件路径下，然后查看所有的配置文件，对应着一个一个地配置。 12345678910111213141516171819202122232425# 进入ZK配置文件路径cd $ZKHOME/conf# 重命名配置文件cp zoo_sample.cfg zoo.cfg# 打开配置文件vim zoo.cfg# 修改内容dataDir=$ZKHOME/tmp# 在最后添加内容server.1=slave01:2888:3888server.2=slave02:2888:3888server.3=slave03:2888:3888# 保存退出后重新生效环境变量source /etc/profile # 再在dataDir设置的位置创建一个空文件myidtouch dataDir/myid# 最后向该文件写入唯一ID编码echo 1 &gt; $ZKHOME/tmp/myid 集群分发配置好slave01主机上的zookeeper后进行集群分发到slave02和slave03。 123456789# 集群分发scp –r /usr/zookeeper-3.4.14/ root@slave02:/usr/scp –r /usr/zookeeper-3.4.14/ root@slave03:/usr/# 特别注意：修改slave02、slave03对应dataDir设置的位置/tmp/myid内容# 在slave02：echo 2 &gt; $ZKHOME/tmp/myid# slave03：echo 3 &gt; $ZKHOME/tmp/myid 分发slaver01主机上的环境变量配置文件 123456789# 集群分发scp –r /etc/profile root@slaver02:~/scp –r /etc/profile root@slaver03:~/# 可以用命令启动zookeeperzkServer.sh start来启动# 用命令来查看三个ZK集群上，哪个是leader，哪两个是followerzkServer.sh status Hadoop安装本节从Hadoop的下载、解压、添加环境变量、修改配置文件和集群分发方面进行阐述 下载解压&emsp;&emsp;将下载好的hadoop版本上传到master01进行解压(当前操作所在路径root用户目录下~)，指定解压到/usr/。 1tar -zxvf hadoop-2.7.7.tar.gz -C /usr/ 环境变量&emsp;&emsp;用编辑器打开系统环境配置文件，用VI/VIM打开/etc/profile，然后添加一下内容，方便后面直接使用一些hadoop的shell命令，当然也是可以不用配置的，直接找到hadoop的shell命令所在路径，然后再执行shell命令，这样有时候不是很方便。 1234567# vim打开/etc/profilevim /etc/profile# 文件尾部添加内容export HADOOP_HOME=/usr/hadoop-2.7.7export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbinexport PATH 修改配置文件&emsp;&emsp;hadoop2.x的配置文件全部在$HADOOP_HOME/etc/hadoop下，首先进入到这里配置文件路径下，然后查看所有的配置文件，对应着一个一个地配置。 12345678910111213141516171819# 进入hadoop配置文件路径cd $HADOOP_HOME/etc/hadoop# 修改hadoop-env.shexport JAVA_HOME=$JAVA_HOME# 修改slaves文件，添加如下内容，作用是指定hadoop的datanode节点。slave01slave02slave03# 修改mapred-site.xml&lt;configuration&gt; &lt;!-- 指定mr框架为yarn方式 --&gt; &lt;property&gt; &lt;name&gt;mapreduce.framework.name&lt;/name&gt; &lt;value&gt;yarn&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 修改配置文件core-site.xml 12345678910111213141516171819202122# 修改core-site.xml(其他property不改)&lt;configuration&gt; &lt;!-- 指定hdfs的nameservice为mycluster --&gt; &lt;!-- mycluster 后面配置hdfs.site要用到 --&gt; &lt;property&gt; &lt;name&gt;fs.defaultFS&lt;/name&gt; &lt;value&gt;mycluster&lt;/value&gt; &lt;/property&gt; &lt;!-- 指定hadoop临时目录 --&gt; &lt;!-- 需要提前在指定路径创建好空目录tmp --&gt; &lt;property&gt; &lt;name&gt;hadoop.tmp.dir&lt;/name&gt; &lt;value&gt;/usr/hadoop-2.7.7/tmp&lt;/value&gt; &lt;/property&gt; &lt;!-- 指定zookeeper地址 --&gt; &lt;property&gt; &lt;name&gt;ha.zookeeper.quorum&lt;/name&gt; &lt;value&gt;slave01:2181,slave02:2181,slave03:2181&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 修改配置文件hdfs-site.xml 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980# 修改hdfs-site.xml(其他property不改)&lt;configuration&gt; &lt;!--指定hdfs的nameservice为mycluster需要和core-site.xml中的保持一致 --&gt; &lt;property&gt; &lt;name&gt;dfs.nameservices&lt;/name&gt; &lt;value&gt;mycluster&lt;/value&gt; &lt;/property&gt; &lt;!-- ns1下面有两个NameNode，分别是nn1，nn2 --&gt; &lt;property&gt; &lt;name&gt;dfs.ha.namenodes.mycluster&lt;/name&gt; &lt;value&gt;master01,master02&lt;/value&gt; &lt;/property&gt; &lt;!-- nn1的RPC通信地址 --&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.rpc-address.mycluster.nn1&lt;/name&gt; &lt;value&gt;master01:8020&lt;/value&gt; &lt;/property&gt; &lt;!-- nn1的http通信地址 --&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.http-address.mycluster.nn1&lt;/name&gt; &lt;value&gt;master01:50070&lt;/value&gt; &lt;/property&gt; &lt;!-- nn2的RPC通信地址 --&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.rpc-address.mycluster.nn2&lt;/name&gt; &lt;value&gt;master02:8020&lt;/value&gt; &lt;/property&gt; &lt;!-- nn2的http通信地址 --&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.http-address.mycluster.nn2&lt;/name&gt; &lt;value&gt;master02:50070&lt;/value&gt; &lt;/property&gt; &lt;!-- 指定NameNode的元数据在JournalNode上的存放位置 --&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.shared.edits.dir&lt;/name&gt; &lt;value&gt;qjournal://slave01:8485;slave02:8485;slave03:8485/mycluster&lt;/value&gt; &lt;/property&gt; &lt;!-- 指定JournalNode在本地磁盘存放数据的位置 --&gt; &lt;property&gt; &lt;name&gt;dfs.journalnode.edits.dir&lt;/name&gt; &lt;value&gt;/usr/hadoop-2.7.7/journaldata&lt;/value&gt; &lt;/property&gt; &lt;!-- 开启NameNode失败自动切换 --&gt; &lt;property&gt; &lt;name&gt;dfs.ha.automatic-failover.enabled&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt; &lt;!-- 配置失败自动切换实现方式 --&gt; &lt;property&gt; &lt;name&gt;dfs.client.failover.proxy.provider.mycluster&lt;/name&gt; &lt;value&gt;org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider&lt;/value&gt; &lt;/property&gt; &lt;!-- 配置隔离机制方法--&gt; &lt;property&gt; &lt;name&gt;dfs.ha.fencing.methods&lt;/name&gt; &lt;value&gt;sshfence&lt;/value&gt; &lt;/property&gt; &lt;!-- 使用sshfence隔离机制时需要ssh免登陆 --&gt; &lt;property&gt; &lt;name&gt;dfs.ha.fencing.ssh.private-key-files&lt;/name&gt; &lt;value&gt;/root/.ssh/id_rsa&lt;/value&gt; &lt;/property&gt; &lt;!-- 配置sshfence隔离机制超时时间 --&gt; &lt;property&gt; &lt;name&gt;dfs.ha.fencing.ssh.connect-timeout&lt;/name&gt; &lt;value&gt;30000&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 修改配置文件yarn-site.xml 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105# 修改yarn-site.xml&lt;configuration&gt; &lt;!-- Site specific YARN configuration properties --&gt; &lt;!-- 开启RM高可用 --&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.ha.enabled&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt; &lt;!-- 指定RM的cluster id --&gt; &lt;!-- 该cluster-id不能与nameService相同--&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.cluster-id&lt;/name&gt; &lt;value&gt;yrc&lt;/value&gt; &lt;/property&gt; &lt;!-- 指定RM的名字 --&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.ha.rm-ids&lt;/name&gt; &lt;value&gt;rm1,rm2&lt;/value&gt; &lt;/property&gt; &lt;!-- 分别指定RM的地址 --&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.hostname.rm1&lt;/name&gt; &lt;value&gt;master01&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.hostname.rm2&lt;/name&gt; &lt;value&gt;master02&lt;/value&gt; &lt;/property&gt; &lt;!-- 启用RM重启的功能--&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.recovery.enabled&lt;/name&gt; value&gt;true&lt;/value&gt; &lt;!--description&gt;启用RM重启的功能，默认为false&lt;/description--&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.store.class&lt;/name&gt; &lt;value&gt;org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore&lt;/value&gt; &lt;!--description&gt;用于状态存储的类，采用ZK存储状态类&lt;/description--&gt; &lt;/property&gt; &lt;!-- 指定zk集群地址 --&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.zk-address&lt;/name&gt; &lt;value&gt;slave01:2181,slave02:2181,slave03:2181&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt; &lt;value&gt;mapreduce_shuffle&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.webapp.address.rm1&lt;/name&gt; &lt;value&gt;master:8088&lt;/value&gt; &lt;!--description&gt;提供给web页面访问的地址，可以查看任务状况等信息&lt;/description--&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.webapp.address.rm2&lt;/name&gt; &lt;value&gt;hostbb:8088&lt;/value&gt; &lt;!--description&gt;提供给web页面访问的地址，可以查看任务状况等信息&lt;/description--&gt; &lt;/property&gt; &lt;!-- 配置通讯的地址和端口，有多少个RM就配置多少组property --&gt; &lt;!-- RM1--&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.scheduler.address.rm1&lt;/name&gt; &lt;value&gt;master01:8030&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.resource-tracker.address.rm1&lt;/name&gt; &lt;value&gt;master01:8031&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.address.rm1&lt;/name&gt; &lt;value&gt;master01:8032&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.admin.address.rm1&lt;/name&gt; &lt;value&gt;master01:8033&lt;/value&gt; &lt;/property&gt; &lt;!-- RM2 --&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.scheduler.address.rm2&lt;/name&gt; &lt;value&gt;master02:8030&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.resource-tracker.address.rm2&lt;/name&gt; &lt;value&gt;master02:8031&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.address.rm2&lt;/name&gt; &lt;value&gt;master02:8032&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.admin.address.rm2&lt;/name&gt; &lt;value&gt;master02:8033&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 集群分发配置好master01主机上的hadoop后进行集群分发到master02、slave01、slave02和slave03。 1234scp –r /usr/hadoop-2.7.7/ root@master02:/usr/scp –r /usr/hadoop-2.7.7/root@slave01:/usr/scp –r /usr/hadoop-2.7.7/root@slave02:/usr/scp –r /usr/hadoop-2.7.7/root@slave03:/usr/ 分发master01主机上的环境变量配置文件，这个环境变量记得每次配置完成后都要集群分发一次，并重新生效，也可以整个所有集群环境搭建好了之后，只需要集群分发一次并生效即可。 集群检测格式化HDFS在master01上执行分布式文件系统HDFS的格式化命令: 1hdfs namenode -format 格式化后会在根据core-site.xml中的hadoop.tmp.dir配置生成个文件，这里我配置的是$HADOOP_HOME/tmp，然后将$HADOOP_HOME/tmp拷贝到#master02的$HADOOP_HOME下。 123456789101112# 格式化主从NameNodescp -r tmp/ master02:$HADOOP_HOME# 建议使用命令进行主从NameNode格式化# 在执行此命令前先启动master01的namenode：sbin/hadoop-daemon.sh start namenode hdfs namenode -bootstrapStandby# 格式化ZKFC# 格式化ZKFC(在master01上执行即可)hdfs zkfc -formatZK# 或者直接到hadoop的bin和sbin下调相应命令bin/hdfs zkfc -formatZK 启动集群123456# 在zookeeper的三个节点上执行命令启动zookeeperzkServer.sh start# 然后在master01上执行启动HDFS、YARNstart-dfs.shstart-yarn.sh 集群检测检测进程&emsp;&emsp;在每一台主机上执行jps命令，查看运行在Java虚拟机KVM的进程。可以采用批量化命令，即打开远程连接软件的交互窗口，只输入一次命令在所有主机上都运行该命令，然后根据每一台主机运行后的进程和我们预先的进程是否一致，若相同则集群成功了。检测浏览器访问 12345678# 查看分布式文件系统HDFShttp://192.168.92.2:50070NameNode 'master01:9000' (active)http://192.168.92.3:50070NameNode 'master02:9000' (standby)#查看分布式资源调度YARN任务信息（ResourceManager运行节点的IP）http://192.168.92.2:8088(端口号是上面文件中配置的,默认是8088) 测试集群的高可用性 12345678910111213141516171819# 先向hdfs上传一个文件hadoop fs -put /etc/profile /hadoop fs -ls /# 然后再kill掉active的NameNodekill -9 &lt;pid of NN&gt;# 通过浏览器访问：http://192.168.92.3:50070# NameNode 'master02:9000' (active)# 这个时候master02上的NameNode变成了active# 在执行命令,发现刚才上传的文件依然存在hadoop fs -ls /# 手动启动那个挂掉的NameNodesbin/hadoop-daemon.sh start namenode# 通过浏览器访问：http://192.168.92.2:50070NameNode 'weekend01:9000' (standby) 出错问题QAQ：不能完成主备NameNode节点之间的自动切换？A：查看配置hdfs-site.xml密匙文件位置是否配置正确！ Q：出现找不到命令的情况？A：看环境变量是否配置好了，或者直接到hadoop的bin和sbin下调相应命令！ Q：出现访问不了哪一个节点？A：节点之间是要相互通信的，所以要检查在各节点之间配置ssh免密登陆！ Q：出现找不到主机名错误提示？A：查看主机名与IP的映射域名文件/etc/hosts是否配置准确！注意配置文件/etc/sysconfig/network配置的是该主机的主机名！ Q：运行过程中出现莫名其妙错误？A：首先应该检查一下集群的必要进程是否还在，有可能莫名其妙的在后台挂掉了！ Q：浏览器访问出现端口冲突？A：所有进行的HTTP端口或者RPC通信端口采用默认方式，如果有冲突则修改端口即可！ Q：感觉看到不是很懂的，感觉有错误的？A：首先本篇文章要求读者有一定的Linux基础和Hadoop集群基础，然后可能版本的原因，部分配置信息有不同，详情请以官方配置文档为主！]]></content>
      <categories>
        <category>Hadoop</category>
      </categories>
      <tags>
        <tag>Hadoop</tag>
        <tag>ZooKeeper</tag>
        <tag>高可用HA</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[计算机语言简介]]></title>
    <url>%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%AF%AD%E8%A8%80%E7%AE%80%E4%BB%8B%2F</url>
    <content type="text"><![CDATA[引言&emsp;&emsp;在如今信息发达的时代，科技日新月异，计算机和Internet网络的发展也成为人们日常生活的重要部分。学习一两门计算机编程语言也如当初学习英文一样的火热，随着人工智能AI和云计算的不断发展，Python语言和Scala语言已经成为这两个领域里面最为火热的编程语言了，可以预知未来学习计算机编程语言的人也一样会如同学习英文一样的成为一种新常态，并且成为一种稳定的常态。以下笔者将以自己的学习认知，简单的阐述一下计算机编程语言的发展。 编程语言简介&emsp;&emsp;计算机语言，英文名Computer Language，或者Programming Language，指的是人与计算机进行交互的一种语言，就如我们学习外语一样的，只是一种形式工具，主要与计算机交流的是我们的思想，将我们自己的思想以计算机能识别的语言赋予他，就形成了程序。&emsp;&emsp;而实现我们的思想的一系列的问题的就是向计算机发送指令，对于通信的双方而言，指令的格式，组成字符，数字数据，语法等一系列的标准就很重要了，而我们学习的就是这一系列的标准，从而能将自己的思想赋予计算机，让计算机能智能化、自动化的为我们服务。随着这一思想的不断演化发展，就逐步形成了一种新的语言，即就是计算机语言！&emsp;&emsp;1946年，于宾夕法尼亚大学，莫克利(JohnW.Mauchly)和艾克特(J.PresperEckert)发明了世界上第一台通用计算机，命名为“ENIAC”。那时候程序员必须手动控制计算机，当时唯一想到利用程序设计语言来解决问题的人是德国工程师楚泽(konradzuse)。 计算机语言发展简史&emsp;&emsp;计算机是一系列的硬件构成的能完成强大功能的一个结合体，他唯一能够识别的就是逻辑运算，即0和1，所以最初的计算机交互语言是以二进制的机器语言，由于太难理解与记忆，人们就定义了一系列的助记符帮助理解与记忆，就逐渐产生了汇编语言，但是汇编还是不好理解与记忆，就逐渐发展了高级语言。随着C、Fortran等结构化高级语言的诞生，使程序员可以离开机器层次，通过更加抽象的层次来表达自己的思想，同时也诞生的三种重要控制结构，即就是顺序结构、选择结构、循环结构，以及一些基本数据类型都能够很好的让程序员以接近问题本质的方式去描述、抽象问题。但随着需要处理的问题规模的不断扩大，一般的程序设计模型无法克服错误随着代码的扩大而级数般的扩大，这个时候就出现了一种新的思考程序设计方式和程序设计模型，即就是面向对象程序设计，同时也诞生了一批支持这种设计模型的计算机语言，例如C++、Java、Python等。&emsp;&emsp;简而言之，计算机语言从最初的机器语言（二进制），发展到使用助记符的汇编语言，再到更易理解的高级语言，包括C、C++、Java、C#、Python等等。计算机程序的设计模型从结构化的编程，再到面向对象的编程。当然计算机只能识别二进制语言，那么很明显在其他计算机语言与机器语言之间就有着一个桥梁，起着翻译一样的功能，使得通信双方能够交流，而这个翻译官就是编译器。而由于编译的原理不一样，我们将计算机语言分为编译性语言（例如C、C++）和解释性语言（Shell、Python）。 三代计算机编程语言第一代计算机编程语言&emsp;&emsp;第一代的计算机语言就是机器语言，即就是0\1组成的代码，人们通过0\1与计算机进行交互与数据交换，这样的编程实在是太难，对于大多数人来说都是十分的困难的，随着其时间的发展，就逐步演化了第二代计算机语言。不过这是计算机的基础，因为计算机硬件只能识别0\1的二进制，无论后面的计算机语言如何发展，最总在计算机内能够执行的只能是0\1的二进制编码，故而后面所有的计算机语言都需要一个翻译的东西，将其翻译为二进制的编码执行，这个起着翻译官作用的就是编译器！ 第二代计算机编程语言&emsp;&emsp;由于第一代计算机语言的学习难度系数极高，就发展出使用一些助记符来帮助人们编程，这就是第二代编程语言——汇编语言，使人们与计算机进行交流沟通时便捷一些，人们学习编程起来也比较容易，这种使用英文助记符来帮助人们进行编程，再由编译器翻译为0\1的代码，这样计算机就能识别了。但是随着信息技术的不断发展，汇编语言已经不能够满足大部分人们的需求，就催生了第三代计算机编程语言。 第三代计算机编程语言&emsp;&emsp;所谓的第三代计算机编程语言，就是大家经常熟知的一些编程语言。而对于计算机高级语言的发展分为两个阶段，以 1980 年为分界线，前一阶段属于结构化语言或者称为面向过程的语言，后一阶段属于面向对象的语言。&emsp;&emsp;然而对于什么叫面向过程，什么叫面向对象？这是很难解释的一个问题，故而暂时不需要深入理解，简单来说就是编程时的两种设计思想。&emsp;&emsp;面向过程语言中最经典、最重要的就是C语言。Fortran、Basic 和 Pascal 语言基本上已经很少有人使用了。但是C语言一直在用，因为C语言是计算机领域最重要的一门语言，其在liunx编程和嵌入式编程有极大的地位。但是C语言也有缺陷，它的缺陷只有在学完面向对象语言之后才能体会到。&emsp;&emsp;故而从 20 世纪 80 年代开始又产生了另外一种“以面向对象”为思想的语言，其中最重要、最复杂的就是 C++。C++ 从易用性和安全性两个方面对C语言进行了升级。C++ 是一种较复杂、难学的语言，但是一旦学会了则非常有用。因为 C++ 太复杂，所以后来就对 C++ 进行了改装，产生了两种语言，一个是 Java，另一个是 C#。Java 语言是现在最流行的语言之一。C# 则是微软公司看 Java 很流行而写的一个与 Java 语法相似的语言。因为 Java 和 C# 几乎是一模一样的，所以你只需要学习其中的一种语言就可以了。&emsp;&emsp;同时随着近年来的人工智能和云计算的火热发展，Python语言和Scala语言成为人工智能和云计算Hadoop框架的重要编程语言，逐渐成为时代的主流编程语言。在计算机的领域里，还有一些专用的计算机编程语言，不如网页设计的三要素：HTML、CSS和JavaScript ，这三者就是专用的计算机编程语言。]]></content>
      <categories>
        <category>计算机语言</category>
      </categories>
      <tags>
        <tag>计算机语言</tag>
        <tag>编程语言</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C语言简介]]></title>
    <url>%2FC%E8%AF%AD%E8%A8%80%E7%AE%80%E4%BB%8B%2F</url>
    <content type="text"><![CDATA[引言&emsp;&emsp;计算机语言，英文名Computer Language，或者Programming Language，指的是人与计算机进行交互的一种语言，就如我们学习外语一样的，只是一种形式工具，主要与计算机交流的是我们的思想，将我们自己的思想以计算机能识别的语言赋予他，就形成了程序。&emsp;&emsp;实现我们的思想的一系列的问题的就是向计算机发送指令，对于通信的双方而言，指令的格式，组成字符，数字数据，语法等一系列的标准就很重要了，而我们学习的就是这一系列的标准，从而能将自己的思想赋予计算机，让计算机能智能化、自动化的为我们服务。 计算机语言发展历史&emsp;&emsp;1946年，于宾夕法尼亚大学，莫克利(JohnW.Mauchly)和艾克特(J.PresperEckert)发明了世界上第一台通用计算机，命名为“ENIAC”。那时候程序员必须手动控制计算机，当时唯一想到利用程序设计语言来解决问题的人是德国工程师楚泽(konradzuse)。&emsp;&emsp;计算机是一系列的硬件构成的能完成强大功能的一个结合体，他唯一能够识别的就是逻辑运算，即0和1，所以最初的计算机交互语言是以二进制的机器语言，由于太难理解与记忆，人们就定义了一系列的助记符帮助理解与记忆，就逐渐产生了汇编语言，但是汇编还是不好理解与记忆，就逐渐发展了高级语言。随着C、Fortran等结构化高级语言的诞生，使程序员可以离开机器层次，通过更加抽象的层次来表达自己的思想，同时也诞生的三种重要控制结构，即就是顺序结构、选择结构、循环结构，以及一些基本数据类型都能够很好的让程序员以接近问题本质的方式去描述、抽象问题。但随着需要处理的问题规模的不断扩大，一般的程序设计模型无法克服错误随着代码的扩大而级数般的扩大，这个时候就出现了一种新的思考程序设计方式和程序设计模型，即就是面向对象程序设计，同时也诞生了一批支持这种设计模型的计算机语言，例如C++、Java、Python等。&emsp;&emsp;简而言之，计算机语言从最初的机器语言（二进制），发展到使用助记符的汇编语言，再到更易理解的高级语言，包括C、C++、Java、C#、Python等等。计算机程序的设计模型从结构化的编程，再到面向对象的编程。当然计算机只能识别二进制语言，那么很明显在其他计算机语言与机器语言之间就有着一个桥梁，起着翻译一样的功能，使得通信双方能够交流，而这个翻译官就是编译器。而由于编译的原理不一样，我们将计算机语言分为编译性语言（例如C、C++）和解释性语言（Shell、Python）。 C语言简介C语言产生以及发展 1967年，剑桥大学的Martin Richards对CPL语言进行简化产生了BCPL（Basic Combined Programming Language）语言。 1970年，美国贝尔实验室的 Ken Thompson，以BCPL语言为基础，设计出很简单且很接近硬件的B语言（取BCPL的首字母）。并且他用B语言写了第一个UNIX操作系统，就这样如今强大的Unix/Liunx操作系统来源就诞生了。 1971年，同样酷爱Space Travel的Dennis M.Ritchie为了能早点儿玩上游戏，加入了Thompson的开发项目，合作开发UNIX。他的主要工作是改造B语言，使其更成熟。1972年，美国贝尔实验室的 D.M.Ritchie 在B语言的基础上最终设计出了一种新的语言，他取了BCPL的第二个字母作为这种语言的名字，这就是C语言。 1973年初，C语言的主体完成。Thompson和Ritchie迫不及待地开始用它完全重写了UNIX，随着UNIX的发展，C语言自身也在不断地完善，直到今天，各种版本的UNIX内核和周边工具仍然使用C语言作为最主要的开发语言，其中还有不少继承Thompson和Ritchie之手的代码。 1977年，Dennis M.Ritchie发表了不依赖于具体机器系统的C语言编译文本《可移植的C语言编译程序》。这样C语言的可移植加增强了，比起机器语言和汇编语言，C更加不依赖于计算机硬件了。 C语言继续发展，在1982年，美国国家标准协成立C标准委员会，建立C语言的标准。1989年，ANSI发布了第一个完整的C语言标准——ANSI X3.159—1989，简称“C89”，不过人们也习惯称其为“ANSI C”。 1999年，在做了一些必要的修正和完善后，ISO发布了新的C语言标准，命名为ISO/IEC 9899：1999，简称“C99”。 在2011年12月8日，ISO又正式发布了新的标准，称为ISO/IEC9899: 2011，简称为“C11”。 K&amp;R C，1978年，丹尼斯·里奇和布莱恩·柯林汉合作出版了《C程序设计语言》的第一版。书中介绍的C语言标准也被C语言程序员称作“K&amp;R C”，这本书就成为了C语言的开山之宝，同时K&amp;R也被称为C语言之父。 在二十世纪六十年代以后，逐渐产生了对如今影响最大的三个技术，那就是C语言、Unix\Liunx操作系统和TCP\IP网络协议，这三者完美的配合，构架了现在几乎所有的IT领域。 C语言的应用领域 嵌入式编程&emsp;&emsp;对于嵌入式，大家都不会感到陌生，我们生活日常中的大部分电子产品都有着它的身影。对于微控制器还是微处理器等等嵌入式的一系列控制都可以用C语言来编写，因为C语言接近硬件，同时可移植性比汇编语言好。比如笔者学习AT89C51单片机和STM32时，都是使用C语言来编写设备驱动程序，ARM公司的Keil软件学习的。 编写其他高级语言&emsp;&emsp;对于学习计算机语言，笔者认为C语言是一门非常好的入门语言，当学习了C语言后，拥有了C语言的计算思维，再去学习其他的高级语言就非常容易理解和学习，因为有了面向对象的编程思想后，所有其他高级语言都是在C语言之上进行抽象与封装，所有就会感到十分熟悉。同时关于基本的数据结构都差不多。 编写操作系统与服务器&emsp;&emsp;我们熟知的Liunx操作系统就完全是C语言编写的，Java的虚拟机JVM就是用C和汇编写的，Web服务器Apache也是用C语言写的。毕竟C语言的执行速度更接近硬件，所有一些大型的游戏平台以及引擎都是用C语言写的。同时那些大型的软件也都会在相应部分加入C语言编写，包括数据库、图形图像处理等软件。 C语言源代码 1234567891011121314151617181920212223/***Function：标准C语言程序**Author：@云主宰苍穹**Date：2019-02-27*///# 预处理符号标识//include 包含头文件.h &lt;&gt;包含系统头文件 ""包含自定义头文件//std-standard标准 i-input输入 o-output输出 stdio标准输入输出库#include &lt;stdio.h&gt;//int 主函数返回值类型 main主函数 (参数列表，多个参数以逗号分隔)int main(int argc, char *argv[])//&#123;&#125;里面是一个语句块，代码块，函数体&#123; //printf格式化输出函数，在stdio.h头文件中 //""双引号里面的是一个字符串， 一条语句以；分号结束标志 printf("HelloWorld!\n"); //return 标志结束一个函数体，在main函数中标志结束程序 //0函数返回值，必须与函数返回值类型匹配 return 0;&#125;]]></content>
      <categories>
        <category>计算机语言</category>
      </categories>
      <tags>
        <tag>计算机语言</tag>
        <tag>C语言</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Windows系统下载安装GCC编译器]]></title>
    <url>%2FWindows%E7%B3%BB%E7%BB%9F%E4%B8%8B%E8%BD%BD%E5%AE%89%E8%A3%85GCC%E7%BC%96%E8%AF%91%E5%99%A8%2F</url>
    <content type="text"><![CDATA[引言&emsp;&emsp;对于学习计算机高级语言，编译器是必须要了解的，GCC是一款针对C语言的最佳编译器，随着计算机语言的发展，GCC也逐渐支持C++等其他的高级语言。笔者认为GCC是一款优秀的编译器，特别对于学习Liunx和嵌入式的人来说，了解GCC编译器的工具链是十分必要的！笔者以下以Windows系统下的GCC开源MinGW的下载、安装、环境变量的配置以及检测安装十分成功来阐述GCC编译器，希望对于新手有所帮助！ Windows系统下GCC版本MinGW下载&emsp;&emsp;进入MinGW的官网，进行对GCC版本的下载（需要联网下载，以下的安装过程都需要联网下载一些必须要的组件包），如下图所示： MinGW官网下载点击这里 Windows系统下GCC版本MinGW安装 Windows系统下GCC版本系统环境变量的配置 Windows系统下GCC版本的安装成功检查]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>C语言</tag>
        <tag>GCC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CodeBlocks下载安装]]></title>
    <url>%2FCodeBlocks%E4%B8%8B%E8%BD%BD%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[引言&emsp;&emsp;在计算机高级语言之中，笔者认为C语言是计算机高级语言中最为经典的入门语言。其强大的计算机思维以及计算思维，许多关于计算机的知识，笔者认为C语言是所有高级语言中最为接近底层硬件，更能帮助我们理解计算机的程序。笔者认为codeblocks集成开发环境是非常适合新手进行练习的，codeblocks不仅仅拥有其他集成开发环境IDE的基础优点，同时也是开源的、免费的，其安装的体积不是很大，不像VS系列的需要很大的储存空间和运行内存需求，故而笔者在使用多款关于C\C++集成开发环境后，强烈建议新手选择codeblocks作为入门的一款集成开发环境。 code::blocks下载&emsp;&emsp;Code::Blocks 是一个开放源码的全功能的跨平台C/C++集成开发环境。 Code::Blocks是开放源码软件。Code::Blocks由纯粹的C++语言开发完成，它使用了著名的图形界面库wxWidgets(2.6.2 unicode)版。对于追求完美的C++程序员，再也不必忍受Eclipse的缓慢。&emsp;&emsp;对于codeblocks可以在其官网进行下载对应操作系统版本的安装软件，无论是Liunx\Unix，还是Mac，或者Windows操作系统都支持codeblocks的安装，本博文以Windows为例子下载安装，Linux系统的安装更加简单，大家可以借鉴一下安装就OK了。 codeblocks官网下载点击这里 code::blocks安装下载对应的版本软件，进行对应的安装，以下以Windows系统为例，下载的安装程序如图所示： 双击执行程序，进行安装，Windows系统下，一步一步的next就可以安装成功！！！安装成功后，打开codeblocks软件后界面如下： 小提示： 注意选择安装的位置路径！不要将软件安装在系统盘C盘！ 注意选择软件的使用权限！安装软件以管理员身份运行软件！ 注意软件没有集成的编译器和调试器！需要在自己电脑安装GCC编译器！ 建议自己安装GCC编译器和GDB调试器！需要在网络上找一个可用的GDB调试器！ 创建第一个程序&emsp;&emsp;点击codeblocks软件界面的，File菜单，在弹出的子菜单下选择New，在选择一个Project，创建一个工程，选择ConsoleApplication，创建一个控制台应用程序。&emsp;&emsp;选择创建工程的编写语言，这里选择C语言，点击Next，继续填写工程的名称以及保存的位置，Next后，继续选择编译器以及需要的Debug版本以及Release版本，最后点击Finish完成，创建好工程，codeblocks自动为我们创建好了一个main主函数入口（笔者的软件界面经过主题美好了，做了一些修改，故而有一些不一样的地方，但是不影响软件的使用！！！），如下图所示： 运行程序&emsp;&emsp;选择codeblocks软件界面的Build菜单，下拉选择Build，创建整个工程，直到软件的编译器提示无错误为止（如下图所示），就可以进行运行程序了！！！我们的第一个HelloWorld经典程序就问世了，您好，世界！ 对于GCC编译器和GDB调试器在Windows下下载安装MinGW开源GCC编译器，详情请查看本博客文章：Windows系统下载安装GCC编译器然后在codeblocks里面更改编译器的设置，如下图所示：]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>C语言</tag>
        <tag>CodeBlocks</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[全球科技通史-吴军]]></title>
    <url>%2F%E5%85%A8%E7%90%83%E7%A7%91%E6%8A%80%E9%80%9A%E5%8F%B2-%E5%90%B4%E5%86%9B%2F</url>
    <content type="text"><![CDATA[引言吴军博士的《全球科技通史》一书从科技视角俯瞰历史，从历史视角理解科技，便于我们更加深刻的理解科技的发展史和其本质。《全球科技通史》一书从钱颖一教授的推荐序——从科技视角俯瞰历史，从历史视角理解科技，本书的前言——科技的本质。以人类发展的历史为主线，从远古科技，到古代科技，再到近代科技，最后到现代科技，用十章的内容讲述了全人类全球范围内的科技发展通史，让读者从另一个维度来认识和思考科技的发展和其本质。 推荐序从科技视角俯瞰历史，从历史视角理解科技 吴军博士的《全球科技通史》帮助我们从历史视角思考科学和技术的过去和未来，值得推荐。科学是发现自然规律，技术是对改造世界有用的发明。科学方法论的起点是“怀疑一切”。 前言科技的地位和作用 从空间维度看，在文明过程中独一无二，是一种进步的力量。 从时间维度看，是世界上唯一能获得叠加性进步的力量。 科技发展的历史必然性 从能量角度看，宇宙的本源就是能量，物质就是由能量构成的。 从信息角度看，人类的实践本质上就是获取能量并利用能量改变周围的环境。 远古科技人类和其他动物的一个本质区别就是前者有能力主动改变周围的环境，这通常归结为智力因素。人类让自己的活动产生多余的能量(除去维持自身生长和生存所需的)，从根本上只有两个方法：开源和节流。文化和文明是不一样的概念 文明(civilization)——城市、文字记载和金属工具 文化(culture)——人类定居、农业和畜牧业 气候的骤变对很多物种来说都是灭顶之灾，太阳的活动映射地球获取能量的变化，从而使得地球的生物随着能量而演变，人类也就随之进化，逐步定居，开始出现了文明的曙光。而这时的科技主要围绕两个核心： 获取更多的能量便于生存 总结、记录并传授经验便于有效改变生存环境 黎明之前没有文字记载的史前时期和有了文字记载的文明时期。历史研究在一定程度上就是解码遗留下来的历史痕迹信息。文明的程度可以根据人类自身获取能量的水平和在生活中使用能量的水准来衡量。在人类史上，火的使用不仅在使用能量上的一次巨大飞跃，也是人类进化和开启文明不可或缺的环节。形成大规模部落是人类从史前文明向早期文明过度的必要条件。史前人类是非常野蛮的，随着文明的开始，人类渐渐将自身暴力基因的作用压制了下去。人类区别于其他物种的根本之处在于大脑的结构略有不同，主要表现在两个方面。第一，人脑有多个思维中枢；第二，人脑的沟通能力。语言既可以被认为是人类（主动）发明的，也可以视为人类（被动)进化的必然结果。 斯坦福大学教授伊恩·莫里斯(Lan Morris)在他的《文明的度量》书中指出，只有当人类活动所创造的能量是他每天所消耗能量的两倍以上时，才有可能制作日用品，修建房屋，驯养动物，然后才能进一步发展，否则只能勉强维持生存和繁衍后代。我们现在的生活不也是一样的嘛，唯有更加的努力，唯有每一天所创造的价值超过自己所消费的价值时，才可能谈进一步的发展，否则也只能勉强地生存下去。 文明曙光人类历史上第一次重大的科技革命源于农业，因为农业是早期文明地区赖以生存的基础。农业阶段是早期人类发展的必经阶段，人类无法越过农业阶段，从游牧状态直接进入工业文明。狩猎的谋生方式虽然在单位时间里获取能量的效率较高，但是在一个地区能过获得的总能量有限；而农耕则相反，它能获得更高的总能量，从而养活更多的人口。阳光和水是农业的基础，这就是为什么早期文明均诞生在亚热带或者温带的大河流域。定居下来的人不得不每日辛勤地耕作，以保证每年在收获时获得足够多的能量，来维持部落的生存和发展。从这个意义上说，人类被自己驯化的农作物拴在了那片土地上。通常，发明的过程可以简单地分为两个阶段——发现阶段和发明阶段，现象（或者原理）被发现和利用原理发明出新方法、新工具。从0到1的时间有时比我们想象的更加漫长。远古的文明都源于便于灌溉的大河流域。最古老的文明中心——古埃及的尼罗河流域和美索不达米亚。农业的发展是文明的基础，人类只有在获得稳定的农业收成之后，才有足够的剩余能量供应给非农业人口，进而建立城市，创造文明。早期文明 以古埃及和中华文明为代表的单纯的农耕文明，在文明中心有大一统的王朝。 以美索不达米亚和古希腊文明为代表的城邦文明，商业发达。 抽象的数字和进制的发明是人类科学史上的第一次重大发明，折射出人类在科学上的重要成就。信息编码的本质就是将自然界中的实体和我们大脑中的一个概念或者符号对应起来。为了方便记录，图画被逐渐简化为象形的符号，这便是文字的雏形。简化的过程是漫长的，因为从形象思维到抽象思维不是一件容易的事情。文字的传播包括横向传播和纵向传播。天文学，几何学起源于古埃及和美索不达米亚(古巴比伦)。人类在谋生技艺上的积累和进步，逐渐使得一部分人可以从事获取食物之外的工作，并让少数人从体力劳动中解放出来，专门从事于艺术、科学和宗教活动。 古代科技一个先有鸡还是先有蛋的问题，唯一的破局方法就是经历一个较长的积累过程，然后就会得到时间的答案。 农耕文明冶金时代——青铜时代。冶金水平是早期文明程度的标尺。很多时候，文明水平不能看开始时间的早晚，而要看鼎盛时期的水平。作为农业革命的副产品，手工业就随之发展起来了。发明的本质不在于是否第一个发现了现象，而是找到一套行之有效的、确定的方法，保证成功率。城市出现的意义很重大，因为伴随城市出现的是社会等级的划分，以及随后出现的政府。初始化是文明的标志，也是结果。 文明复兴纵观人类文明史，科学、文化的发展与信息源的丰富、传播方式的进步息息相关。在某种意义上说，科学的诞生始于泰勒斯和毕达哥拉斯。毕达哥拉斯将世界上的规律分为可感知的和可理喻的。所谓可感知就是实验科学得到的结果，而可理喻的则是数学中通过推理得到的结论。人的思维很难摆脱直接经验的束缚。人类的认识受到时代的局限。科学的突破常常需要很长的时间积累，然后才能完成这样一次爆发。人类文明进步不仅取决于科技发明本身，还取于对这些发明的传承和广泛的传播，而无论是传承还是传播，都有依赖于对科技成就的完整记录。大学的诞生，巴黎大学——牛津大学——剑桥大学。文艺复兴时代和随后的启蒙时代。科学对于技术发展的作用是非常明显的，信息对科学发展的作用是巨大的。 近代科技文艺复兴之后，世界科技的中心从阿拉伯回到了欧洲。人类历史上的科学启蒙时代，笛卡尔总结的科学方法论。知识精英阶层和民众在掌握信息方面的差距依然很大。人类的发明从一种自发状态进入一种自觉状态。工业革命之前，人类的发明是靠长期的经验积累，这个过程十分漫长。在科学启蒙时代之后，以瓦特为代表的发明家主动利用科学原理进行发明，从而改变人类生活的发明在短时间内不断涌现。 科学启蒙科学方法论——法国数学家、哲学家笛卡尔。 第一，不盲从，不接受任何自己不清楚的真理。 第二，对于复杂的问题，尽量分解为对个简单的小问题来研究，一个个分开解决。 第三，解决这些小问题时，应该按照先易后难的次序，逐步解决。 第四，解决每一个小问题之后，再综合起来，看看是否彻底解决了原来的问题。 笛卡尔将科学发展的规律总结为： 1、提出问题 2、进行试验 3、从实验中得到结论并解释 4、将结论推广并且普遍化 5、在实践中找出新的问题 哈维的《心血运动论》、哥白尼的《天体运行论》、牛顿的《自然哲学的数学原理》、达尔文的《物种起源》，并称为改变历史的科学巨著。 荷兰科学家华伦海特提出的“华氏温度”，瑞典天文学家安德斯·摄尔修斯提出了“摄氏温度”。牛顿构建了近代三大科学体系，即以微积分为核心的近代数学、以牛顿三大定律为基础的经典物理学、以万有引力定律为基础的天文学。在牛顿之后，人类才有意识地利用科学知识指导实践，这才使得自近代以来的科技进步不断加速。 工业革命瓦特后来改进蒸汽机的想法不是来自实验，而是来自理论。瓦特的成功树立了榜样——通过自己的发明创造，在改变世界的同时，也改变了自己的命运。十九世纪后，生物学的突然加速，主要有两个原因：一个是仪器的进步，特别是显微镜的进步和普及；另一个则是学术界此时普遍开始自觉运用科学方法论。能量守恒定律、细胞学说和进化论被恩格斯成为十九世纪的三大科学发现，不仅仅是对物理学、生物学和医学本身的重大意义，同时也确立了唯物论的科学基础。对于一项发明来说，最后那个把发明变成产品的人，远比最早想到发明雏形的人重要的多。 新工业石油——有机化学的发展——橡胶发展——内燃机和发动机——飞机发展——武器发展——通识教育改革世界上很多的重大发明都是时代的产物。 美国教育家艾略特成功将哈佛大学从一个以教授拉丁文为主的近代私塾，变成了世界一流的综合性大学。 现代科技随着对微观世界以及遥远宇宙认识的不断加深，人类发现过去所了解的关于世界的规律不过是更广泛、更具有普遍意义的规律的特例而已。 原子时代1905年——爱因斯坦的奇迹年，近代物理学。1666年——牛顿的奇迹年，经典物理学。 迈特纳和弗里施在《自然》杂志上发表了他们的发现，并提出了“核裂变”的概念。这篇论文一共只有两页，却有划时代的意义，因为它找到了自然界存在的巨大的力量。 核反应证明了爱因斯坦的质能转换，包括核裂变和核聚变。核裂变的本质是将大质量数的原子通过裂变损失质量、释放能量。核聚变的本事是通过将多个氢、氦和锂这样的小质量数的原子聚合成一个大质量数的原子，更有效地释放能量。 信息时代世界科技常常呈现出平稳快速发展和相对停滞交替的状态。系统论研究的是复杂系统内部的关系。控制论研究的是在一个动态的系统中，如何在很多内外部的不确定因素下，保存平衡状态的方法。信息论研究的是信息的处理和通信理论，人类可以准确的度量信息的多少。 摩尔定律和安迪-比尔定律摩尔定律：1965年，摩尔预测集成电路的性能每年翻一番。1975年，摩尔将预测修改为每两年翻一番。后来人们把翻番的时间改为18个月。安迪-比尔定律：大概意思就是微软等软件公司的新软件总是要比从前的软件耗费更多的硬件资源，以至于完全覆盖了因特尔等硬件公司带来的硬件性能的提升。 未来世界癌症的预测性检测基因编辑的成就与争议可控核聚变还要多久“新生产关系”区块链利用量子通信实现数据安全]]></content>
      <categories>
        <category>读书</category>
      </categories>
      <tags>
        <tag>全球科技通史</tag>
        <tag>吴军</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux常用命令]]></title>
    <url>%2FLinux%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[Liunx-Command命令格式命令 [-选项] [参数] 例如：ls -la /etc 说明： 个别命令使用不遵循此格式 当有多个选项是，可以写在一起 简化选项与完整选项 (如-a等于–all) Liunx中对大小写敏感 目录处理命令：ls名称：ls英文：list功能：显示目录文件选项： -a(all) 显示目录下所有文件，包括以.开头的隐藏文件 -l(long) 以详细信息显示 -d(directory) 查看目录属性 -R 以递归的形式连同子目录中的内容一起列出 注释：在Ubuntu下，目录是蓝色高亮显示，可执行程序是绿色高亮显示，压缩包是红色高亮显示 Linux文件文件类型 -表示普通文件 d表示目录 l表示软链接 b块设备文件 c字符设备文件 s socket文件 网络套接字 p管道文件 文件权限 r(read)——表示有可读权限 w(write)——表示有可写权限 e(execute)——表示有可执行权限 - ——表示没有该权限 u(user)——文件的所有者 g(group)——文件的所属组 o(other)——文件的其他人 例如：-rw-r–r–&emsp;&emsp;表示此二进制普通文件的所有者对该文件可读(r)可写(w)不可执行(-)，所属组对该文件可读(r)不可写(-)不可执行(-)，其他人对该文件可读(r)不可写(-)不可执行(-)。 目录处理命令：mkdir名称：mkdir英文：make directories功能：创建新目录选项：-p 递归创建 目录处理命令：cd名称：cd英文：change directory功能：切换目录，进入指定目录注意：”.“表示当前目录，”..“表示上一级目录，“/”表示根目录 目录处理命令：pwd名称：pwd英文：print working directory功能：显示当前目录的完全路径注意：路径有绝对路径和相对路径两种路径：是指用来标识一个文件在操作系统的文件系统中存储位置的全路径=路径+文件名：pathname=path+file_name绝对路径：路径是从绝对位置开始的，譬如Windows中从某一个盘符开始&lt;c，Liunx中从根目录/开始相对路径：指明路径的时候，是从当前所在的位置开始的 目录处理命令：cp名称：cp英文：copy功能：复制文件或者目录语法：cp -r/p 原文件或目录 目标目录选项：[-r]:复制目录 [-p]保留文件属性 目录处理命令：mv英文：move功能：剪切文件，改名语法：mv 原文件或目录 目标目录 目录处理命令：rm英文：remove功能：删除文件选项：[-r]：删除目录 [-f]：强制执行 文件处理命令：touch：功能：创建空文件cat：显示文件内容more:分页显示文件内容&lt;空格或者f：翻一页 Enter：一行一行 q或Q：退出&gt;less：分页显示内容&lt;可以向上翻页 可以搜索关键词：/word n：next&gt;head -n 行数 filename：显示文件前几行&lt;默认十行&gt;tail -n 行数 filename：显示文件后几行&lt;默认十行&gt;[-f]：动态显示文件末尾内容，一般用于监控服务器的日志文件内容 文件处理命令：ln英文：link功能：生成链接文件选项：[-s]:生成软链接 无选项则是生成硬链接语法：ln -s 原文件 目标文件硬链接计数——是指一个磁盘文件被链接的次数，当一个文件的硬链接计数为零时，则表示文件完全从磁盘中删除 权限管理命令：chmod英文：change the permssions mode of a file功能：改变文件或目录的权限注意： 权限数字表示：r——4、w——2、x——1 例如：chmod 777 filename 只有root、文件所有者才能修改文件权限 [-R]：递归修改&lt;目录下所有文件权限&gt; &emsp;&emsp;在Linux中，可读、可写和可执行的权限对于文件和目录而言有着不同的意义，下面的两个表格简述了三种权限对于文件和目录的不同功能意思以及对应的可用的Linux常用命令。 字母 权限 文件 目录 r 可读 可查看文件内容 可列出目录中内容 w 可写 可修改文件内容 可在目录中创建、删除文件 x 可执行 可执行文件(脚本) 可以进入目录 权限 命令 文件 r cat/more/head/tail/less 文件 w vi/vim 文件 x script cammand 目录 r ls 目录 w touch/mkdir/rmdir/rm 目录 x cd 权限管理命令：名称：chown英文：change file ownership功能：改变文件或目录的所有者语法：chown user filename注意：只有root才能修改chown chgrp名称：chgrp功能：改变文件或目录的所属组英文：change file group ownership语法：chgrp group filename 权限管理命令:umask英文：the user file-creation mask路径：shell内置命令语法：umask -S选项：-S:以rwx形式显示新建文件缺省权限功能：显示、设置新建文件的缺省权限掩码：777-022=755&lt;老版本的liunx中有掩码概念&gt; 帮助命令：man英文：manual&lt;手册页&gt; 关机命令：shutdown选项： [-h]:关机，语法：shutdown -h now [-r]：重启，语法：shutdown -r now 其他命令which——查看命令所在位置，例如：which ls/tree——以树的形式查看目录内容，例如：tree /etc / 网络命令： writeLinux write命令用于传讯息给其他使用者使用权限：所有使用者语法：write user [ttyname]参数说明：user : 预备传讯息的使用者帐号ttyname : 如果使用者同时有两个以上的 tty 连线，可以自行选择合适的 tty 传讯息 wallLinux wall命令会将讯息传给每一个 mesg 设定为 yes 的上线使用者。当使用终端机介面做为标准传入时, 讯息结束时需加上 EOF (通常用 Ctrl+D)使用权限：所有使用者语法：wall [ message ] pingLinux ping命令用于检测主机执行ping指令会使用ICMP传输协议，发出要求回应的信息，若远端主机的网络功能没有问题，就会回应该信息，因而得知该主机运作正常。语法：ping [-dfnqrRv][-c&lt;完成次数&gt;][-i&lt;间隔秒数&gt;][-I&lt;网络界面&gt;][-l&lt;前置载入&gt;][-p&lt;范本样式&gt;][-s&lt;数据包大小&gt;][-t&lt;存活数值&gt;][主机名称或IP地址]参数说明： -d 使用Socket的SO_DEBUG功能。 -c&lt;完成次数&gt; 设置完成要求回应的次数。 -f 极限检测。 -i&lt;间隔秒数&gt; 指定收发信息的间隔时间。 -I&lt;网络界面&gt; 使用指定的网络接口送出数据包。 -l&lt;前置载入&gt; 设置在送出要求信息之前，先行发出的数据包。 -n 只输出数值。 -p&lt;范本样式&gt; 设置填满数据包的范本样式。 -q 不显示指令执行过程，开头和结尾的相关信息除外。 -r 忽略普通的Routing Table，直接将数据包送到远端主机上。 -R 记录路由过程。 -s&lt;数据包大小&gt; 设置数据包的大小。 -t&lt;存活数值&gt; 设置存活数值TTL的大小。 -v 详细显示指令的执行过程。 mailLinux服务器mail程序本身就是调用sendmail来进行邮件发送的，sendmail服务器提供对外的邮件发送功能。CentOS默认不能发送邮件，需要发送邮件的童鞋可以安装一个sendmail程序 setupLinux setup命令设置公用程序，是一个启动图形设置系统的命令setup 命令：用来配置X，打印设置，时区设置，系统服务，网络配置，配置，防火墙配置，验证配置，鼠标配置语法：setupsetup是一个设置公用程序，提供图形界面的操作方式。在setup中可设置7类的选项： １.登陆认证方式 ２.键盘组态设置 ３.鼠标组态设置 ４.开机时所要启动的系统服务 ５.声卡组态设置 ６.时区设置 ７.X Windows组态设置 ifconfigLinux ifconfig命令用于显示或设置网络设备ifconfig可设置网络设备的状态，或是显示目前的设置语法：ifconfig [网络设备][down up -allmulti -arp -promisc][add&lt;地址&gt;][del&lt;地址&gt;][&lt;hw&lt;网络设备类型&gt;&lt;硬件地址&gt;][io_addr&lt;I/O地址&gt;][irq&lt;IRQ地址&gt;][media&lt;网络媒介类型&gt;][mem_start&lt;内存地址&gt;][metric&lt;数目&gt;][mtu&lt;字节&gt;][netmask&lt;子网掩码&gt;][tunnel&lt;地址&gt;][-broadcast&lt;地址&gt;][-pointopoint&lt;地址&gt;][IP地址]参数说明： add&lt;地址&gt; 设置网络设备IPv6的IP地址。 del&lt;地址&gt; 删除网络设备IPv6的IP地址。 down 关闭指定的网络设备。 &lt;hw&lt;网络设备类型&gt;&lt;硬件地址&gt; 设置网络设备的类型与硬件地址。 io_addr&lt;I/O地址&gt; 设置网络设备的I/O地址。 irq&lt;IRQ地址&gt; 设置网络设备的IRQ。 media&lt;网络媒介类型&gt; 设置网络设备的媒介类型。 mem_start&lt;内存地址&gt; 设置网络设备在主内存所占用的起始地址。 metric&lt;数目&gt; 指定在计算数据包的转送次数时，所要加上的数目。 mtu&lt;字节&gt; 设置网络设备的MTU。 netmask&lt;子网掩码&gt; 设置网络设备的子网掩码。 tunnel&lt;地址&gt; 建立IPv4与IPv6之间的隧道通信地址。 up 启动指定的网络设备。 -broadcast&lt;地址&gt; 将要送往指定地址的数据包当成广播数据包来处理。 -pointopoint&lt;地址&gt; 与指定地址的网络设备建立直接连线，此模式具有保密功能。 -promisc 关闭或启动指定网络设备的promiscuous模式。 [IP地址] 指定网络设备的IP地址。 [网络设备] 指定网络设备的名称。]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Vi/Vim使用方法及命令]]></title>
    <url>%2FVi-Vim%E4%BD%BF%E7%94%A8%E6%96%B9%E6%B3%95%E5%8F%8A%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[Vi/Vim简介vim简介(文本编辑器)&emsp;&emsp;Vi/Vim是功能强大的全屏幕文本编辑器，是在liunx和Unix上常用的文本编辑器。作用是建立、编辑、显示文本文件，vim没有菜单，只有命令。&emsp;&emsp;Liunx下编辑神器Vi/Vim，Vim是Vi IMproved。Vi/Vim的整个配置文件是Vimrc，其中rc：run command的意思。了解Vim的寄存器以及其工作原理，利用Vim进行增删查改操作，探寻Vim的组合规律。Vim还有其高级功能 缓冲区与多文件编辑 多窗口与标签分组 文本对象和宏 Visual模式 Vim模式命令模式、输入模式 输入模式：&emsp;&emsp;进入vi/vim后，按下键盘的a或者i，则进入输入模式,(在终端的下面末行会显示”–insert–“，提示此时处于输入状态) 命令模式：&emsp;&emsp;在输入模式下，按下键盘的ESC，则进入命令模式,(在终端的下面末行输入命令，故又称末行模式) vim常用命令插入命令 a：在光标所在字符后插入 A：在光标所在行尾插入 i：在光标所在字符前插入 I：在光标所在行首插入 o：在光标下插入新行 O：在光标上插入新行 定位命令 ：set nu:设置行号 ：set nonu：取消行号 gg：定位到第一行 G：定位到最后一行 nG：定位到第n行 ：n：定位到第n行 $：定位到行尾 0：点位到行首 删除命令 x：删除光标所在处字符 nx：删除光标所在处后n个字符 dd：删除光标所在行 ndd：删除光标开始的n行 dG：删除光标所在行到文件末尾内容 D：删除光标所在处到行尾内容 ：n1,n2d:删除指定范围的行 复制和剪切命令 yy：复制当前行 nyy：复制当前行开始的以下n行 p、P：粘贴在当前光标所在的行下、行上 dd：剪切当前行 ndd：剪切当前行开始的以下n行 替换和取消命令 r：取代光标所在处的字符 R：从光标所在行处开始替换字符，直到按Esc键结束 u：取消上一步操作（撤销） 搜索和搜索替换命令 /string:搜索指定字符串 ：set ic：搜索时忽略大小写 n：搜索指定字符串的下一个出现位置 ：%s/old_string/new_string /g:全文搜索替换指定字符串 ：n1，n2s/old_string/new_string /c:在一定范围内替换指定字符串 /c:是指替换时有询问确认 /g:是指替换时无询问确认 保存和退出命令 ：w：保存修改 ：w new_filename：另存为指定文件 ：wq：保存修改并退出 ZZ：快捷键，保存修改并退出 ：q!:不保存修改并强制退出 ：wq!:保存修改并强制退出（文件所有者及root可使用） Liunx-gcc tool_chain(工具链)1、预处理生成&lt;.i&gt;文件，通过选项-E可以使编译器在预处理结束时停止编译 例如：gcc -E -o hello.i hello.c 2、编译生成&lt;.s&gt;汇编代码文件，通过选项-S可以使gcc在进行编译后停止 例如：gcc -S -o hello.s hello.c 3、汇编生成&lt;.o&gt;的目标文件，是机器语言代码《二进制》，当一个程序由多个代码文件 构成时，每个文件都要先完成汇编工作，生成.o目标文件后，才能进行链接，可以通过选项-C生成目标文件 例如：gcc -C -o hello.o helllo.c 4、链接将程序的所有机器代码的目标文件链接，使操作系统能加载为可执行文件 例如：gcc -o hello hello.c 或者：gcc hello.c -o hello]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Vi/Vim</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux操作系统简介]]></title>
    <url>%2FLinux%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AE%80%E4%BB%8B%2F</url>
    <content type="text"><![CDATA[operating system (OS)：操作系统操作系统&emsp;&emsp;操作系统 (operating system) 是管理和控制计算机硬件与软件资源的程序，从计算机软硬件角度来说，操作系统是一种软件方面的，是一台计算机必不可少的系统级软件。OS 也是用户和计算机的接口，也是计算机硬件和软件的接口。OS 是直接控制和管理计算机硬件、软件资源，合理对各类作业进行调度，以方便用户使用的程序集合。 主流操作系统常见主流的操作系统 Windows： Microsoft 公司开发的图形窗口界面 (GUI)，多任务的操作系统 Liun：多用户、多任务操作系统，开源的内核源代码 Unix：多用户、多任务操作系统，支持多种处理器架构的分时操作系统 Mac OS：是一套运行在苹果 Macintosh 系列电脑的操作系统 Android：以 Liunx 为基础的支持手机端的操作系统，现在由 Google收购 iOS：是苹果公司开发的手持移动操作系统 DOS：最早期的操作系统，完全的命令行 Command line 指令模式 鸿蒙OS：华为公司研发的开源的操作系统，主用于物联网等工业以及商业方面 操作系统分类 桌面操作系统 服务器操作系统 嵌入式操作系统 分时操作系统 批处理操作系统 组成部分操作系统OS由内核、驱动程序、接口库、外设组成。以现代观点而言，一个标准 PC 的 OS 有以下功能： 进程管理 (Processing management) 内存管理 (Memory management) 文件系统 (File system) 网络通讯 (Networking) 安全机制 (Security) 用户界面 (User interface) 驱动程序 (Device drivers) Liunx-introduction：Linux简介Liunx VS Unix&emsp;&emsp;Linux 被称为“类 Unix”操作系统，(You’ve heard Linux called a ”Unix-like” operating system)&emsp;&emsp;Linux是一套免费使用和自由传播的类Unix操作系统，是一个基于POSIX和Unix的多用户、多任务、支持多线程和多CPU的操作系统。它能运行主要的Unix工具软件、应用程序和网络协议。它支持32位和64位硬件。Linux继承了Unix以网络为核心的设计思想，是一个性能稳定的多用户网络操作系统。&emsp;&emsp;Linux是一套免费使用和自由传播的类Unix操作系统，是一个基于POSIX和Unix的多用户、多任务、支持多线程和多CPU的操作系统。伴随着互联网的发展，Linux得到了来自全世界软件爱好者、组织、公司的支持。它除了在服务器操作系统方面保持着强劲的发展势头以外，在个人电脑、嵌入式系统上都有着长足的进步。使用者不仅可以直观地获取该操作系统的实现机制，而且可以根据自身的需要来修改完善这个操作系统，使其最大化地适应用户的需要。&emsp;&emsp;Linux不仅系统性能稳定，而且是开源软件。其核心防火墙组件性能高效、配置简单，保证了系统的安全。在很多企业网络中，为了追求速度和安全，Linux操作系统不仅仅是被网络运维人员当作服务器使用，Linux既可以当作服务器，又可以当作网络防火墙是Linux的 一大亮点。&emsp;&emsp;Linux与其他操作系统相比 ，具有开放源码、没有版权、技术社区用户多等特点 ，开放源码使得用户可以自由裁剪，灵活性高，功能强大，成本低。尤其系统中内嵌网络协议栈 ，经过适当的配置就可实现路由器的功能。这些特点使得Linux成为开发路由交换设备的理想开发平台。 liunx 特点 基本思想&emsp;&emsp;Linux的基本思想有两点：第一，一切都是文件；第二，每个软件都有确定的用途。其中第一条详细来讲就是系统中的所有都归结为一个文件，包括命令、硬件和软件设备、操作系统、进程等等对于操作系统内核而言，都被视为拥有各自特性或类型的文件。至于说Linux是基于Unix的，很大程度上也是因为这两者的基本思想十分相近。 开源性&emsp;&emsp;Linux是一款开放源代码的操作系统，用户可以通过网络或其他途径免费获得，并可以任意修改其源代码。这是其他的操作系统所做不到的。正是由于这一点，来自全世界的无数程序员参与了Linux的修改、编写工作，程序员可以根据自己的兴趣和灵感对其进行改变，这让Linux吸收了无数程序员的精华，不断壮大。 完全兼容POSIX1.0标准&emsp;&emsp;这使得可以在Linux下通过相应的模拟器运行常见的DOS、Windows的程序。这为用户从Windows转到Linux奠定了基础。许多用户在考虑使用Linux时，就想到以前在Windows下常见的程序是否能正常运行，这一点就消除了他们的疑虑。 多用户、多任务&emsp;&emsp;Linux支持多用户，各个用户对于自己的文件设备有自己特殊的权利，保证了各用户之间互不影响。多任务则是现在电脑最主要的一个特点，Linux可以使多个程序同时并独立地运行。 良好的界面&emsp;&emsp;Linux同时具有字符界面和图形界面。在字符界面用户可以通过键盘输入相应的指令来进行操作。它同时也提供了类似Windows图形界面的X-Window系统，用户可以使用鼠标对其进行操作。在X-Window环境中就和在Windows中相似，可以说是一个Linux版的Windows。 支持多种平台&emsp;&emsp;Linux可以运行在多种硬件平台上，如具有x86、680x0、SPARC、Alpha等处理器的平台。此外Linux还是一种嵌入式操作系统，可以运行在掌上电脑、机顶盒或游戏机上。2001年1月份发布的Linux 2.4版内核已经能够完全支持Intel64位芯片架构。同时Linux也支持多处理器技术。多个处理器同时工作，使系统性能大大提高。Linux简章&emsp;&emsp;Linux（[/lɪnəks/]是基于Linux内核的开源类Unix操作系统家族里面最出色的一员。Linux操作系统内核于1991年9月17日首次由Linus Torvalds本人发布。我们通常所指的Linux是打包了Linux内核和Linux外围软件包的发行版本。&emsp;&emsp;Linux发行版包括Linux内核和支持系统软件和库，其中许多系统软件和系统库都是由GNU Project提供的。许多Linux发行版在其发行版本的名称中使用“Linux”一词，来强调是用了Linus本人的内核开发的，而自由软件基金会使用名称GNU / Linux来强调GNU软件的重要性。&emsp;&emsp;Linux最初是为基于Intelx86架构的个人计算机开发的，但后来被移植到比其他任何操作系统更多的平台上。Linux是服务器和其他大型铁系统（如大型计算机）上的领先操作系统，也是TOP500超级计算机上使用的唯一操作系统（自2017年11月起逐渐淘汰所有竞争对手）大约2.3％的台式计算机使用它。运行基于Linux内核的Chrome操作系统的Chromebook占据了美国K-12教育市场的主导地位，占美国笔记本电脑销售额低于300美元的近20％。&emsp;&emsp;Linux也可以在嵌入式系统上运行，即其操作系统通常内置在固件中并且高度适合系统的设备。这包括路由器，自动化控制，电视，数字视频录像机，视频游戏机和智能手表。许多智能手机和平板电脑运行Android和其他Linux衍生产品。由于Android在智能手机上的主导地位，Linux拥有所有通用操作系统的最大安装基础。&emsp;&emsp;Linux是免费和开源软件协作的最突出的例子之一。源代码可以根据其各自的许可条款（例如GNU通用公共许可证）由任何人商业或非商业地使用，修改和分发。 目前流行的Linux发行版包括Debian，Fedora和Ubuntu 商业发行版包括Red Hat Enterprise Linux和SUSE Linux Enterprise Server 桌面Linux发行版包括一个窗口系统，如X11或Wayland，以及一个桌面环境，如GNOME或KDE Plasma 用于服务器的发行版可能完全省略图形，或包含一个解决方案堆栈，如LAMP 因为Linux可以自由再发行，所以任何人都可以出于任何目的创建发行版 GNU简介GNU 是“GNU is Not Unix”的递归缩写 GNU维基百科自由软件基金会 (Free Software Foundation)&emsp;the history of Unix and the rise of Linux and the GNU/Free Software Foundation underpinnings of a free and open source alternative to Unix.Liunx core or kernel and released version&emsp;Whether you use a Debian based Linux distribution such as Debian,Ubuntu,Mint or SolyDX, or you use a Red Hat based Linux distribution such asFedora or CentOS. the way that applications are installed onto your computer are the same.]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>操作系统</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux最佳发行版推荐]]></title>
    <url>%2FLinux%E6%9C%80%E4%BD%B3%E5%8F%91%E8%A1%8C%E7%89%88%E6%8E%A8%E8%8D%90%2F</url>
    <content type="text"><![CDATA[引言&emsp;&emsp;2019年度最佳Linux发行版，Linux版本选择指南。Linux的内核是开源的，在开源的社区里提供了很多发行版本供我们选择，但对于新手来说还是比较难以下手。笔者提供自己最常用的的Linux发行版本指南，希望可以帮助你选择最适合的Linux发行版，以满足您的日常工作需求。&emsp;&emsp;对于一个开发人员而言，会经常使用基于Linux的操作系统来完成日常工作和开发东西。我们进行选择Linux发行版进行编程的主要考虑因素是兼容性、低功耗、稳定性和灵活性。故而如 Ubuntu和Debian两款发行版已经成为了首选。当然还有其它一些很好的选择如 openSUSE、Arch Linux 、Kali Liunx等等。 适用于编程的Linux发行版：Debian&emsp;&emsp;笔者不得不承认，大多数Linux用户都是开发者或开源爱好者，使用Linux主要就是来开发新的东西，不然都去使用Windows了。当然许多Linux发行版都符合程序员的使用要求，我们用户可以安装所有需要的工具，但笔者认为Debian GNU/Linux是最好的选择。&emsp;&emsp;Debian中含有大量的软件包，提供良好的稳定性和大量的教程，帮助开发人员解决问题。Debian因其定期测试、更新和坚如磐石在稳定性而享有盛誉，这种稳定性使程序员可以放心地展开开发工作。Debian测试分支，它有所有最新的软件，并且非常稳定。适合高级程序员和系统管理员。但请注意，Debian只推荐给有Linux工作经验的程序员。 针对初学者新手而言，不推荐使用。Debian 有很多开源库，另外，它的 .deb 软件包管理也是值得推荐的一点。目前最新版本是Debian GNU/Linux 10。 强大PC端或者笔记本推荐的Linux发行版：Ubuntu&emsp;&emsp;Canonical的Ubuntu在开源世界中是不需要任何介绍，每一个人都知道的，其基于 Debian 架构，在稳定性和新功能方向都得到了很好的平衡。对于功能强大的个人电脑PC和笔记本电脑，运行GNOME桌面的旗舰Ubuntu是完美的。有着完美的界面，Ubuntu就是Liunx世界里的Windows，笔者强烈建议新手用户使用。随着Snap的引入，安装应用程序变得更加舒适，同时Ubuntu还拥有一个蓬勃发展的用户社区和论坛，你可以在其中找到任何问题的答案。总的来说，Ubuntu是一个功能非常强大的Linux发行版，可以让您多任务并高效地完成工作。笔者例举几个Ubuntu的优点： 有很多软件提供使用 有广泛的社区支持和论坛支持 用户界面友好且功能强大 Ubuntu已经成为Linux桌面场景的一大亮点 Ubuntu 也支持流行的 .deb 包管理系统 Linux服务器端最佳选择发行版：CentOS&emsp;&emsp;CentOS由于它是从RHEL源代码编译的，所以为RHEL构建的大多数商业软件都可以在 CentOS 上运行，这是CentOS的强大优点之一。CentOS的安装和设置过程几乎就像 Fedora 一样，CentOS大量的红帽软件集合和CentOS存储库能满足不同的软件需求。同时CentOS允许使用Xen虚拟化来开发应用程序。CentOS使用Yum进行软件包的管理。RedHat在Linux世界中享有独特的企业竞争优势，而CentOS则是在不花费任何费用的开源的情况下获得RedHat好处的方法。简单来说，CentOS就是社区支持的RedHat。 渗透测试最佳Liunx发行版：Arch Linux&emsp;&emsp;Arch Linux是高度可定制的，这是许多Liunx爱好者最喜欢研究的地方，也是最受欢迎的优点之一。Arch Linux是硬核Linux爱好者最喜爱的Linux发行版，它随附有Linux内核和软件包管理器。如果需要做一些渗透测试工作，可以将Arch Linux安装转换成BlackArch安装模式。 网络安全领域的最佳Linux发行版：Kali Linux&emsp;&emsp;Kali Linux配备了数百种属于不同类别的有用安全工具，例如：漏洞分析、无线攻击、Web 应用程序、开发工具、压力测试和取证工具等。Kali Linux基于Debian Testing分支，发行版中的大多数软件包都来自Debian软件源。同时Kali Linux除了桌面安装外，Kali Linux 还可以安装在Raspberry Pi、Ordroid、Chromebook、BeagleBone 等设备上进行便携携带和使用，而 Kali NetHunter 的到来也可用于Android智能手机。为什么笔者会推荐 Kali Linux作为网络安全领域的Liunx： Kali Linux定期滚动发布模式 Kali Linux多种经过测试的道德黑客工具 Kali Linux坚实的 Debian 基础 Kali Linux广泛的学习资源 当然还有其他的优秀的Liunx发行版 适合初学者的最佳Linux发行版：Linux Mint 老旧硬件的最佳Linux发行版：Ubuntu MATE 专属游戏的Linux发行版：Steam OS 美丽的Linux发行版：elementary OS openSUSE 是一个非常稳定的编程操作系统，它可以轻松地让 Ubuntu 运行起来 Fedora的赞助商是红帽公司，以提供 Linux 桌面世界最尖端的功能而闻名]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Linux发行版</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[大数据框架Hadoop的前世今生]]></title>
    <url>%2F%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%A1%86%E6%9E%B6Hadoop%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F%2F</url>
    <content type="text"><![CDATA[一纵两横一纵两横的思维&emsp;&emsp;即学习一个新学科时，可以看其一纵，其整个历史至今的发展过程。然后看其两横，一横是不同人对于其的评价即定义，还有一横是不同学科或领域与其的联系和区别。抓住这一纵两横的思维，可以帮助我们快速了解一个新的学科或者一个新的领域。&emsp;&emsp;在了解一件自己完全没有涉足过的事情之前，笔者喜欢使用“一纵两横”的思维去学习了解，这样能够快速的帮助自己构建知识体系。所谓的“一纵”，就是事物本身的历史发展，从最开始的诞生到当今的发展情况，可能有的人会觉得无聊或者没有必要，但笔者想告诉读者的是，这是进入一个事物领域的最基本素质，能够很好地体现着专业素养。而所谓的“两横”，就是一方面比较该领域里不同的专家学者或者提出者（创造者），以及其他领域的人对于该事物的阐述理解或者评价态度；另一方面就是比较已有领域学科或者相近领域学科和该事物的异同点或者联系与区别。但完成了这“一纵两横”后，不仅是从本质上了解事物，同时也和自己已有的知识架构联系在一起，有了自己的一些理解感悟。 大数据起源背景！&emsp;&emsp;笔者第一次正式接触大数据，是阅读维克托的《大数据时代》，当然是翻译的中文版，是浙江人民出版社的，在《大数据时代》书中提到，大数据的发展来源，大数据的特征，著者维克托传递出大数据时代来临了的信号，同时我们数据的思考和应用都应该有巨大的思想变革，这样才能适应大数据时代的发展。书中对大数据的三个核心思想： 数据不是随机样本，而是全部数据 数据不是精确性，而是混杂性 数据间不是因果关系，而是相关关系 &emsp;&emsp;维克托围绕着三个核心思想，阐述了我们思维、生活以及商业的变革，同时笔者有点小感悟，那就是我们的学习或者教育是不是也需要变革，针对这三个核心思想对我们学习或者教育进行改革，当然这不是我们重点，这就当做是笔者在抛砖引玉 (自恋一下 ̂_ ̂)。&emsp;&emsp;既然大数据这个概念能够催生，那么在实际的生活必然有着对应的实际应用。那么这又是这样的情况了？这就聊到了 hadoop 框架的产生背景了，进入 21 世纪以来，随着信息技术和信息社会的高速发展，信息或者数据在不断地增长，而且是超几何的疯狂增长。特别是在 Web2.0 时代，人们对于信息的产生和索取需求在疯狂增长，这样在浏览器端产生的数据在 TB 级别或者 PB 级别在增长，亿万网民用户的浏览数据记录以及日夜增长的网站，这些海量数据如何进行存储和分析计算，就成为摆在我们的面前，同时也是 Google 这样的搜索引擎公司天然就需要面对的现实和需要解决的问题。Google-Alphabet 的新老三篇文章，被称之为大数据领域的三驾马车： 2003 年发表文章 &lt;GFS:The Google File System&gt; 2004 年发表文章 &lt;MapReduce:Simlifed Data Processing on Large Clusters&gt; 2006 年发表文章 &lt;BigTable:A Distrbuted Stroage System for Structured Data&gt; 2010 年发表文章 &lt;Dremel: Interactive Analysis of Web-Scale Datasets&gt; 2010 年发表文章 &lt;Pregel: A System for Large-Scale Graph Processing&gt; Google 老三架马车： GFS、 MapReduce、 BigTable Google 新三架马车： Dremel、 Pregel、 Caffeine &emsp;&emsp;大数据的应用开发框架，你一定听过 Hadoop，对就是它！Hadoop 是 Apache(这样说应该不准确，就先这样理解) 基于 Google 的前三篇文章实现的开源框架，现在是 Apache 下一个顶级项目。大家可以访问官网看一看:Hadoop Apache官网 Hadoop 的起源背景之 GFS大数据解决本质问题之一，就是对海量的数据如何进行存储。&emsp;&emsp;海量的数据并不是传统的 MB 或者 GB 级数据，而是 TB、 PB 级的数据概念。或许你没有啥直观的感觉，我们用数据来进行表明一下： 8bit = 1Byte 210Byte = 1024Byte = 1KB 220KB = 1024KB = 1MB 230KB = 1024KB = 1GB 240GB = 1024GB = 1TB 250TB = 1024TB = 1PB 260PB = 1024PB = 1EB 270EB = 1024EB = 1ZB &emsp;&emsp;简单来说， 1.2ZB 字节数据，如果储存在只读光盘上，那么这些光盘可以堆成五堆，每一堆都可以伸到月球。公元前 3 世纪，埃及的托勒密二世竭力收集了当时所有的书写作品，全部储存在亚历山大图书馆，代表着当时世界上所有的知识量，但是在数字数据洪流涌向世界后，每一个人都可以获取大量的数据信心，相当与当时压力山大图书馆储存的数据总量的 320 倍。从上面的小故事就可以知道，现在数字信息的庞大，如此海量的数据需要储存，传统的磁盘阵列储存已经无法满足这样的需求了，毕竟磁盘阵列价格是昂贵的。这就需要低成本、高效率、高可靠的储存设计。2003 年， Google 发表了 文章，解决了这个问题。在文章中阐述了解决海量数据储存的设计思想。同时在 Apache 下Lucene 的子项目研究下，实现了海量数据的存储设计：分布式文件系统，也就是 HDFS（Hadoop Distributed File System）。 Hadoop 的起源背景之 MapReduce大数据解决本质问题之二，就是海量数据如何进行计算。&emsp;&emsp;在编程计算里，有并行编程计算框架，有过了解的人就知道，这并不是什么新兴的技术。同样 Google 在 2004 年发表了 &lt;MapReduce: Simplifed Data Processing on Large Clusters&gt; 文章，文章阐述了基于分布式储存的海量数据并行计算解决方案思想。开源社区 Apache 的 Hadoop 项目研究实现了MapReduce 并行计算框架，将计算与数据在本地进行，将数据分为 Map 和Reduce 阶段。简单阐述就是 MapReduce 编程模型：把一个大任务拆分成小任务，再进行汇总。 Hadoop 的起源背景之 BigTable大数据解决本质问题之三，就是对于海量的数据进行分析处理&emsp;&emsp;数据在储存后，其作用就是提供检索和查阅，这才是搜索引擎的功效，也是Google 的强大技术支持。那么提高查询和利用数据的效率就是需要解决的重点。到这里就需要有一定的数据库相关知识 (建议可以查阅一下关于数据库的起源以及历史发展)，数据库的产生就是为了查询和利用数据的效率提高，然而现有的数据库并不能满足基于分布式储存的需求。结构化的数据库 (SQL) 和非结构化的数据 (NoSQL)。&emsp;&emsp;Google 工程师在 2006 年发表了 &lt;Bigtable: A Distributed Storage System for Structured Data&gt; 文章，文中阐述了基于分布式储存的数据库设计思想。就这样数据库时代从关系型数据库进入了非关系型数据库时代，一张大表 BigTable 设计思想， BigTable 就是把所有的数据保存到一张表中，同时采用冗余方式 (提高效率和可靠性，这种冗余的方式是最常用的手段，无论是在通信领域，或者自然语言处理领域、语音处理等等), 基于其设计思想就开源实现了基于 HDFS 的非关系型数据库（NoSQL 数据库） HBase。&emsp;&emsp;小提示：其实在我们常用的云盘或者网盘，其主要的设计思想就是这样的，笔者常用的百度网盘也就类似于这样分布式的储存。笔者建议感兴趣的读者，可以阅读 Google 的三篇文章，最好是原文 (虽然笔者的英文很烂)，这样我们就更能理解其设计思想的精髓。 Hadoop 环境搭建Hadoop 分布式集群简介！&emsp;&emsp;引言：学习大数据，就需要自己搭建 Hadoop 的运行环境，这对于新手而言是一项困难的工作，特别是对于 Liunx 操作不熟悉的读者而言，更是一大难题。但是学习部署自己的 Hadoop 环境是学习大数据的必经之路，也是必会技能之一。接下来跟笔者一起来搭建 Hadoop 集群环境吧！当然在 Windows 下也是支持部署 hadoop 的，不过这并不适合实际生产的需求，同时 Windows 不如 Liunx 性能稳定等等因素，一次是来自 Apache 官网对于开发平台的简介。&emsp;&emsp;GNU/Linux is supported as a development and production platform. Hadoop has been demonstrated on GNU/Linux clusters with 2000 nodes.Windows is also a supported platform but the followings steps are for Linux only. To set up Hadoop on Windows, see wiki page.&emsp;&emsp;支持 GNU / Linux 作为开发和生产平台。已经在具有 2000 个节点的GNU / Linux 集群上演示了 Hadoop。 Windows 也是受支持的平台，但以下步骤仅适用于 Linux。要在 Windows 上设置 Hadoop，请参阅 Wiki 页面。 在学习大数据之前，我们应该知道对于 Hadoop 的环境搭建，有着三种方式： 本地模式，就是单机版的 Hadoop，笔者觉得完全没有必要，因为 Hadoop的储存原理本就是分布式的概念，同时不具备 HDFS，只能测试 MapReduce程序。 全分布式集群，就是对每一个必须的节点都采用一个独立的主机，拥有独立的 IP 地址，真正意义的分布式集群概念，完全达到 Hadoop 的实际应用要求。 伪分布式集群，我们学习最常用的一个环境搭建。就是采用一个主机，但是配置多个拥有独立的虚拟节点，满足 Hadoop 分布式的逻辑概念。具备 Hadoop 的所有功能，在单机上模拟一个分布式的环境。这也是我们在学习中建议采用的方式，因为笔者使用的是 Windows7 系统，故而需要借助虚拟机。 搭建 Hadoop 环境准备 安装虚拟机 VMWare、 Linux 操作系统。 配置主机名和 I 静态 IP 地址、免密码登录设置。 约定安装目录： /liwei/hadoop。 配置好 JDK 的环境变量、准备好 Hadoop 安装包。 了解 Hadoop 的目录结构以及对应的作用。]]></content>
      <categories>
        <category>大数据</category>
      </categories>
      <tags>
        <tag>Hadoop</tag>
        <tag>大数据</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hadoop之wordcount实例-MapReduce程序]]></title>
    <url>%2FHadoop%E4%B9%8Bwordcount%E5%AE%9E%E4%BE%8B-MapReduce%E7%A8%8B%E5%BA%8F%2F</url>
    <content type="text"><![CDATA[实验目的&emsp;&emsp;利用搭建好的大数据平台 Hadoop，对 HDFS 中的文本文件进行处理，采用 Hadoop Steaming 方式，使用 Python 语言实现英文单词的统计功能，并输出单词统计结果。 实验内容&emsp;&emsp;将附件”COPYING_LGPL.txt”上传 Hadoop 集群的 HDFS 中，采用 Hadoop Steaming方式，使用 Python语言实现字词统计功能，输出字词统计结果，即实现文本单词的词频统计功能。要求将实验原理，过程，代码分析，结果分析记录在实验报告中。 实验步骤 实验原理：&emsp;&emsp;简述 MapReduce 的 Data Flow 如下图所示，原始数据经过 mapper 处理，再进行 partition 和 sort，到达 reducer，输出最后结果。Hadoop 的MapReduce处理框架，一般的编程模型如下图所示， 将一个业务拆分为 Mapper 和 Reducer 两个阶段。使用 Python 语言背后的“技巧”是我们将使用 Hadoop Streaming API 来帮助我们通过 STDIN（标准输入）和 STDOUT（标准输出）在 Map 和 Reduce 代码之间传递数据。我们将简单地使用 Python 的 sys.stdin 来读取输入数据并将我们自己的输出打印到 sys.stdout。这就是我们需要做的全部，因为 Hadoop Streaming 会帮助我们处理其他所有事情！&emsp;&emsp;使用 Python 来调用 Hadoop Streaming API，其基本流程如下图。用 Python 写MapReduce 还需要了解 HadoopStreaming ，在 Apache 的 Hadoop 官网可以查看HadoopStreaming 的运行机制，简单来说就是 HadoopStreaming 是可运行特殊脚本的MapReduce 作业的工具 ，使用格式如下： 12345hadoop jar \/home/hadoop/app/hadoop-2.7.7/share/hadoop/tools/lib/hadoopstreaming-2.7.7.jar\-files /home/hadoop/mapper.py -mapper /home/hadoop/mapper.py \-files /home/hadoop/reducer.py -reducer /home/hadoop/reducer.py \-input /wordcount/COPYING_LGPL.txt -output /wordcount/output 实验过程&emsp;&emsp;将本地物理机的测试文本文件 COPYING_LGPL.txt 上传到虚拟主机 Master 上，在从 Master 上传到 Hadoop 集群的 HDFS 文件系统上/wordcount/COPYING_LGPL.txt。&emsp;&emsp;使用 Python 编写 MapReduce 程序，分别根据实现原理编写 Mapper 程序和Reducer 程序，使用 Vim 编写 Mapper 和 Reducer 脚本，并使两个脚本具有可执行权限，及使用命令： chmod +x mapper.py reducer.py。&emsp;&emsp;使用 HadoopStreaming 命令来运行自己编写的程序，其命令如下： 12345678hadoop jar \/home/hadoop/app/hadoop-2.7.7/share/hadoop/tools/lib/hadoopstreaming-2.7.7.jar \-files /usr/bin/mapper.py \-files /usr/bin/reducer.py \-mapper "python /usr/bin/mapper.py" \-reducer "python /usr/bin/reducer.py" \-input /wordcount/input/COPYING_LGPL.txt \-output /wordcount/output &emsp;&emsp;可以编写一个 shell 脚本命令，来运行 HadoopStreaming 命令，这样在 shell 脚本中首先使用删掉输出目录文件的命令（hdfs dfs -rm -r -f /wordcount/output），防止多次测试出错， 同时每次测试只需要运行 shell 脚本即可，这样在做实验的时候更加方便操作，而不用每次都敲命令。 对HadoopStreaming 命令进行解释： 12345678hadoop jar #指调用hadoop jar包的命令/home/hadoop/app/hadoop-2.7.7/share/hadoop/tools/lib/hadoopstreaming-2.7.7.jar #调用HadoopStreaming 命令的jar包-files /usr/bin/mapper.py #提交的作业的路径-files /usr/bin/reducer.py #提交的作业的路径-mapper "python /usr/bin/mapper.py" #mapper程序的解释器python以及程序路径-reducer "python /usr/bin/reducer.py" #reducer程序的解释器python以及程序路径-input /wordcount/input/COPYING_LGPL.txt #HDFS上的输入文件的路径-output /wordcount/output #HDFS上的输出文件的路径 &emsp;&emsp;HadoopStreaming API 的调用接口说明： 调用 python 中的标准输入流 sys.stdin ，MAP 具体过程是， HadoopStream 每次从 input 文件读取一行数据，然后传到 sys.stdin中，运行 payhon 的 map 函数脚本，然后用 print 输出回 HadoopStreeam。 REDUCE 过程一样。所以 M 和 R 函数的输入格式为 for line in sys.stdin:line=line.strip。Mapper 过程如下： 第一步，在每个节点上运行我们编写的 map 程序 ，即就是 调用标准输入流 ， 读取文本内容，对文本内容分词，形成一个列表，读取列表中每一个元素的值 ， Map 函数输出， key 为 word，下一步将进行 shuffle 过程，将按照key 排序，输出，这两步为 map 阶段工作为，在本地节点进行，第二步， hadoop 框架，把我们运行的结果，进入 shuffle 过程，每个节点对 key 单独进行排序，然后输出。Reducer 过程：第一步， merge 过程，把所有节点汇总到一个节点，合并并且按照 key排序。第二步，运行 reducer 函数。 Python源代码&emsp;&emsp;分析 WordCount 程序实例的实现原理步骤，具体 Python 代码如下源代码所示，前面是简要原理的实现，后面是使用 Python 的迭代器和生成器升级 mapper 程序和 reducer 程序。MapReduce 的 WordCount 简要原理 Python 实现源代码如下Mapper阶段 12345678910111213141516171819#!/usr/bin/env python# filename:mapper.py# date:2019-06-18import sys# input comes from STDIN (standard input)for line in sys.stdin: # remove leading and trailing whitespace line = line.strip() # split the line into words words = line.split() # increase counters for word in words: # write the results to STDOUT (standard output); # what we output here will be the input for the # Reduce step, i.e. the input for reducer.py # tab-delimited; the trivial word count is 1 print '%s\t%s' % (word, 1) Reducer阶段 1234567891011121314151617181920212223242526272829303132333435363738394041#!/usr/bin/env python# filename:reducer.py# date:2019-06-18from operator import itemgetterimport syscurrent_word = Nonecurrent_count = 0word = None# input comes from STDINfor line in sys.stdin: # remove leading and trailing whitespace line = line.strip() # parse the input we got from mapper.py word, count = line.split('\t', 1) # convert count (currently a string) to int try: count = int(count) except ValueError: # count was not a number, so silently # ignore/discard this line continue # this IF-switch only works because Hadoop sorts map output # by key (here: word) before it is passed to the reducer if current_word == word: current_count += count else: if current_word: # write result to STDOUT print '%s\t%s' % (current_word, current_count) current_count = count current_word = word# do not forget to output the last word if needed!if current_word == word: print '%s\t%s' % (current_word, current_count) MapReduce 的 WordCount 简要原理 Python 的迭代器与生成器实现源代码如下：Mapper阶段 1234567891011121314151617181920212223242526#!/usr/bin/env python# filename:mapper.py# date:2019-06-18# detail:A more advanced Mapper, using Python iterators and generators.import sysdef read_input(file): for line in file: # split the line into words yield line.split()def main(separator='\t'): # input comes from STDIN (standard input) data = read_input(sys.stdin) for words in data: # write the results to STDOUT (standard output); # what we output here will be the input for the # Reduce step, i.e. the input for reducer.py # # tab-delimited; the trivial word count is 1 for word in words: print '%s%s%d' % (word, separator, 1)if __name__ == "__main__": main() Reducer阶段 123456789101112131415161718192021222324252627282930#!/usr/bin/env python# filename:reducer.py# date:2019-06-18# detail:A more advanced Reducer, using Python iterators and generators.from itertools import groupbyfrom operator import itemgetterimport sysdef read_mapper_output(file, separator='\t'): for line in file: yield line.rstrip().split(separator, 1)def main(separator='\t'): # input comes from STDIN (standard input) data = read_mapper_output(sys.stdin, separator=separator) # groupby groups multiple word-count pairs by word, # and creates an iterator that returns consecutive keys and their group: # current_word - string containing a word (the key) # group - iterator yielding all ["&amp;lt;current_word&amp;gt;", "&amp;lt;count&amp;gt;"] items for current_word, group in groupby(data, itemgetter(0)): try: total_count = sum(int(count) for current_word, count in group) print "%s%s%d" % (current_word, separator, total_count) except ValueError: # count was not a number, so silently discard this item passif __name__ == "__main__": main()]]></content>
      <categories>
        <category>Hadoop</category>
      </categories>
      <tags>
        <tag>Hadoop</tag>
        <tag>wordcount</tag>
        <tag>MapReduce</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hadoop分布式环境搭建]]></title>
    <url>%2FHadoop%E5%88%86%E5%B8%83%E5%BC%8F%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA%2F</url>
    <content type="text"><![CDATA[实验目的： 熟悉 Linux 操作系统的安装以及常用的基本命令 掌握如何设置静态 IP 地址，掌握如何修改主机域名 掌握如何配置 Java 环境变量，掌握 Java 基本命令 了解为何需要配置 SSH 免密码登录，掌握如何配置 SSH 免密码登录 熟练掌握在 Linux 环境下如何构建分布模式下的 Hadoop 集群 实验内容 安装和配置 CentOS7 的 Liunx 发行版 安装和配置 CentOS7 的网络以及 IP、主机名 启动和配置 SSH 免密码登录，配置 Java 环境 安装和配置 Hadoop 分布式集群环境 实验步骤&emsp;&emsp;分析部署 Hadoop 分布式集群需要三台主机，分别作为三个数据节点DataNode 和三个管理节点NodeManager，再将其中每一个主机分别作为 NameNode、 ResourceManager、SecondaryNameNode。 Master Slave1 slave2 HDFS NameNode DataNode SecondaryNameNode HDFS DataNode DataNode YARN NodeManager ResouceManager NodeManager YARN NodeManager &emsp;&emsp;安装好 VMWare12 虚拟机，新建一个基于 CentOS 发行版的 Liunx 虚拟机，然后安装 CentOS7 操作系统，然后通过克隆方式，克隆出另外两台 CentOS7 主机，以root 权限配置好必要信息后，采用远程登录工具 SecureCRT 登录服务器进行操作。&emsp;&emsp;将建好的虚拟机重新命名为 Hadoop-Node0（主机名为 master）、 HadoopNode1（主机名为 slave1）、 Hadoop-Node2（主机名为 slave2），三台主机都配置一个用户名都为 hadoop，登录密码都为 hadoop，同时使用 root 权限进行对三台主机进行开机关闭防火墙，因为 Hadoop 中的进程端口多而且集群采用内网部署，可以不需要防火墙。&emsp;&emsp;网络配置，使用 VMnet8 这张虚拟网卡，查看网段 IP，网关 IP 地址为192.168.92.1，子网掩码 IP 地址为 255.255.255.0，则在该网段内为三台主机进行配置静态 IP 和重新生成 MAC 地址，使三台主机处于同一网段下， 使用同一时区的时间进行三台主机的时间同步（也可以采用 ntp 的方式进行集群时间同步）， 对应关系如下： Hadoop-Node0——192.168.92.2——master Hadoop-Node1——192.168.92.3——slave1 Hadoop-Node2——192.168.92.4——slave2 &emsp;&emsp;配置好每一台主机的主机名以及静态 IP 地址，同时进行主机名与 IP 地址的映射，在每一台主机的 hosts 文件中都需要配置相同的主机名与 IP 映射，这样才是使用主机名时才能识别主机对应的 IP，文件内容如下： 192.168.92.2 master 192.168.92.3 slave1 192.168.92.4 slave2 &emsp;&emsp;配置 SSH 免密登陆，首先在每台服务器生成密钥对后，即每台机器上都执行 ssh-keygen –t rsa 需要输入密码的地方直接按 Enter 回车键，这样就采用 RSA加密算法生成了公钥秘钥在当前隐藏文件夹.ssh 下。然后在每台服务器上执行 sshcopy-id命令，将公钥复制到其它两台服务器上即可，该命令可以自动将公钥添加到名为 authorized_keys的文件中，在每台服务器都执行完以上步骤后就可以实现多台服务器相互无密码登陆了。 ssh-copy-id -i ~/.ssh/id_rsa.pub hadoop@master ssh-copy-id -i ~/.ssh/id_rsa.pub hadoop@slave1 ssh-copy-id -i ~/.ssh/id_rsa.pub hadoop@lave2 &emsp;&emsp;集群部署，首先要分配好集群的角色，比如 HDFS 的角色有 NN、 DN、SecondaryNN， YARN 的角色有 RM、 NM，分配好在集群中的主机位置。Master Slave1 Slave2三个主机上应该都有着我们提前分配好的角色。分布式文件系统HDFS：NameNode、DataNode、SecondaryNameNode；YARN：NodeManager、ResouceManager。&emsp;&emsp;配置文件，在/home/Hadoop 下创建一个 app/目录，将 hadoop-2.7.7 解压到 app/目录下，将 jdk1-8 也解压到 app/目录下，配置好 JAVA_HOME 和 HADOOP_HOME环境变量，添加到当前用户的 bash_profile。 按照提前准备好的配置文档进行对Hadoop 进行文件的配置，在/home/hadoop/app/hadoop-2.7.7/etc/hadoop/对各个配置文件进行修改配置。&emsp;&emsp;对 HDFS 进行格式化，在 master 主机上进行格式化即可。使用 hdfs namenode-format 命令进行格式化，等待格式化的结果，会显示成功的格式化目录在配置好的/home/hadoop/app/hadoop-2.7.7/temp 目录下。 &emsp;&emsp;启动 Hadoop 的组件的进程（在 master 主机上启动 HDFS、 在 slave1 主机上启 动 YARN ） ， 采 用 jps 命 令 查 看 进 程 和 通 过 浏 览 器 查 看 。 &emsp;&emsp;上传文件到 HDFS 后，通过浏览器查看目录文件以及分块情况，同时也可以在 Liunx 端查看到情况。&emsp;&emsp;运行 wordcount 程序，体验并检验 Hadoop 集群。&emsp;&emsp;关闭 Hadoop 集群，现在 master 主机上关闭 HDFS，在 slave1 主机上关闭YARN，则 slave2 主机上的 Hadoop 集群的进程就自动被关闭了。 实验代码或分析重启网卡 1systemctl restart network 查看防火墙状态 1systemctl status firewalld 设置开机不启动防火墙 1systemctl disable firewalld 配置免密登录先在每一台主机上执行生成 RSA 算法的秘钥 1ssh-keygen –t rsa 从 master 以 hadoop 用户登录 master、 slave1、 slave2 免密在 master 主机上进行一下操作命令即可 123ssh-copy-id -i ~/.ssh/id_rsa.pub hadoop@masterssh-copy-id -i ~/.ssh/id_rsa.pub hadoop@slave1ssh-copy-id -i ~/.ssh/id_rsa.pub hadoop@slave2 从 slave1 以 hadoop 用户登录 master、 slave1、 slave2 免密在 slave1 主机上进行一下操作命令即可 123ssh-copy-id -i ~/.ssh/id_rsa.pub hadoop@masterssh-copy-id -i ~/.ssh/id_rsa.pub hadoop@slave1ssh-copy-id -i ~/.ssh/id_rsa.pub hadoop@slave2 从 slave2 以 hadoop 用户登录 master、 slave1、 slave2 免密在 slave2 主机上进行一下操作命令即可 123ssh-copy-id -i ~/.ssh/id_rsa.pub hadoop@masterssh-copy-id -i ~/.ssh/id_rsa.pub hadoop@slave1ssh-copy-id -i ~/.ssh/id_rsa.pub hadoop@slave226. 配置好 master 主机上的 Hadoop 后进行集群分发到 slave1 和 slave2 12scp –r /home/hadoop/app hadoop@slaver1:/home/hadoopscp –r /home/hadoop/app hadoop@slaver2:/home/hadoop 分发 master 主机上的环境变量配置文件 12scp –r ~/.bash_profile hadoop@slaver1:~/scp –r ~/.bash_profile hadoop@slaver2:~/ Hadoop配置文件 核心配置文件 /home/hadoop/app/hadoop-2.7.7/etc/hadoop/slaves 1234&lt;!--配置 Hadoop 集群主机--&gt;masterslave1slave2 /home/hadoop/app/hadoop-2.7.7/etc/hadoop/core-site.xml 123456789101112&lt;configuration&gt; &lt;!--配置 HDFS 的 NameNode--&gt; &lt;property&gt; &lt;name&gt;fs.defaultFS&lt;/name&gt; &lt;value&gt;hdfs://master:9000&lt;/value&gt; &lt;/property&gt; &lt;!--配置 DataNode 保存数据的位置--&gt; &lt;property&gt; &lt;name&gt;hadoop.tmp.dir&lt;/name&gt; &lt;value&gt;/home/hadoop/app/hadoop-2.7.7/temp&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; HDFS 配置文件 /home/hadoop/app/hadoop-2.7.7/etc/hadoop/hadoop-env.sh 12&lt;!--配置 HDFS 的 Java 环境--&gt;export JAVA_HOME=/home/hadoop/app/jdk1.8.0_191 /home/hadoop/app/hadoop-2.7.7/etc/hadoop/hdfs-site.xml 1234567891011121314151617&lt;configuration&gt; &lt;!--配置 HDFS 的副本数--&gt; &lt;property&gt; &lt;name&gt;dfs.replication&lt;/name&gt; &lt;value&gt;3&lt;/value&gt; &lt;/property&gt; &lt;!--配置是否检查权限--&gt; &lt;property&gt; &lt;name&gt;dfs.permissions&lt;/name&gt; &lt;value&gt;false&lt;/value&gt; &lt;/property&gt; &lt;!--配置 Hadoop 辅助名称节点主机配置 SecondaryNameNode--&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.secondary.http-address&lt;/name&gt; &lt;value&gt;slave2:50090&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; YARN 配置文件 /home/hadoop/app/hadoop-2.7.7/etc/hadoop/yarn-env.sh 12&lt;!--配置 YARN 的 Java 环境--&gt;JAVA_HOME=/home/hadoop/app/jdk1.8.0_191 /home/hadoop/app/hadoop-2.7.7/etc/hadoop/yarn-site.xml 123456789101112&lt;configuration&gt; &lt;!--配置 ResourceManager 的地址--&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt; &lt;value&gt;slave1&lt;/value&gt; &lt;/property&gt; &lt;!--配置 NodeManager 执行任务的方式--&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt; &lt;value&gt;mapreduce_shuffle&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; MapReduce 配置文件 /home/hadoop/app/hadoop-2.7.7/etc/hadoop/mapred-env.sh 12&lt;!--配置 MapReduce 的 Java 环境--&gt;export JAVA_HOME=/home/hadoop/app/jdk1.8.0_191 /home/hadoop/app/hadoop-2.7.7/etc/hadoop/mapred-site.xml.template先修改文件 MapReduce 1cp mapred-site.xml.template mapred-site.xml /home/hadoop/app/hadoop-2.7.7/etc/hadoop/mapred-site.xml &lt;configuration&gt; &lt;!--配置 MapReduce 运行在 YARN 上--&gt; &lt;property&gt; &lt;name&gt;mapreduce.framework.name&lt;/name&gt; &lt;value&gt;yarn&lt;/value&gt; &lt;/property&gt; &lt;/configuration&gt; 实验检测上传/home/hadoop/hadoop-2.7.7.tar.gz 和jdk-8u191-linux-x64.tar.gz 文件到 HDFS 根目录 hdfs dfs -put /home/hadoop/hadoop-2.7.7.tar.gz / hdfs dfs -put /home/hadoop/jdk-8u191-linux-x64.tar.gz / 以递归方式查看 HDFS 的根目录结构 hdfs dfs -ls -R / 运行 Hadoop 自带的 wordcount 程序，进行词频统计 hadoop jar hadoop-mapreduce-examples-2.7.7.jar wordcount /README.txt /output hadoop jar hadoop-mapreduce-examples-2.7.7.jar wordcount /LICENSE.txt /output 注意说明&emsp;&emsp;通过本次部署大数据平台 Hadoop 的分布式环境，比之前部署伪分布式环境更加熟悉整个过程的搭建，进一步的深刻理解 Liunx 的操作基础以及 Hadoop 的分布式环境搭建，对Hadoop的认识更加的深刻理解。&emsp;&emsp;对 Liunx 的网络配置以及整个集群的静态 IP 设置和网关设置、防火墙的状态查看以及关闭，以及主机名设置和主机名与 IP 进行映射，通过配置 SSH 的非对称加密，通过公钥和私钥实现三台主机之间的相互之间免密登陆。&emsp;&emsp;配置 Hadoop 的核心组件，核心配置文件 core-site.xml，配置 HDFS 的NameNode 地址以及运行时储存目录； HDFS 配置文件 hadoop-env.sh 用于配置 HDFS的 Java 环境， hdfs-site.xml 指定副本数以及辅助名称节点的主机配置； YARN 配置文件 yarn-env.sh 用于配置 YARN 的 Java 环境， yarn-site.xml 配置 YARN 的NodeManger 和 ResourceManger； MapReduce 配置文件 mapred-env.sh 用于配置MapReduce 的 Java 环境， mapred-site.xml 配置 MapReduce 运行在 YARN 上。&emsp;&emsp;采用分发 scp 命令或者采用脚本进行分发集群搭建，以及了解使用 rsync对集群中存在差异的配置文件进行同步更新，以及在集群中常用的时间同步方法以及了解采用部署 ntp 集群实现时间同步。&emsp;&emsp;进一步理解 Hadoop 的各个组件原理，特别是 HDFS 的储存原理，分块储存以及副本机制等等。使用提供的 jar 包，运行 wordcount 程序 jar 包，体验大数据Hadoop 分布式平台以及 MapReduce 数据处理框架。&emsp;&emsp;对于每一个操作步骤不是很清楚的，可以访问本人的GitHub，在学习资料里面有着详细的学习以及安装的过程，是PDF格式的文档说明。 Hadoop分布式环境搭建详细文档]]></content>
      <categories>
        <category>Hadoop</category>
      </categories>
      <tags>
        <tag>Hadoop</tag>
        <tag>大数据</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo搭建博客]]></title>
    <url>%2FHexo%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2%2F</url>
    <content type="text"><![CDATA[Hexo简介&emsp;&emsp;Hexo 是一个快速、简洁且高效的博客框架。Hexo 使用Markdown（或其他渲染引擎）解析文章，在极短的几秒钟内，就可利用靓丽的主题生成静态网页，特别适合搭建个人博客。Hexo以其简单、高效而且主题丰富多彩而著名，迅速地占据了一部分市场，值得尝试。&emsp;&emsp;本博客就是采用Hexo v3.9.0 + GitHubPages + NexT v7.3.0 主题进行搭建的！ Hexo官网点击这里 GitHub官网点击这里 NexT主题官网点击这里 安装环境&emsp;&emsp;Hexo在搭建时需要Node.js的环境支持，同时需要命令终端的支持。针对不同的操作系统Windows、Linux或者Mac，在配置搭建环境时要下载安装对应的版本，在Windows系统下，建议使用GitBash。Mac和linux都是自带的有BashShell终端。&emsp;&emsp;由于Node.js是国外的网站，有时候由于网络的一些因素，容易影响我们采用npm对资源的访问速度，故此可以采用国内的阿里巴巴的镜像，可以加快访问的速度以及效率。首先在终端采用npm命令安装镜像，成功后就可以采用cnpm命令代替npm命令了。 1- npm install -g cnpm --registry=https://registry.npm.taobao.org Node.js官网点击这里 Git官网点击这里 安装Hexo&emsp;&emsp;在下载、安装并配置好环境后，就可以进行安装Hexo。首先打开BashShell终端，创建一个空的目录来作为整个博客项目的工作空间，然后再使用命令进行安装hexo，安装成功后就对Hexo进行初始化，初始化成功后可以查看整个工作空间的目录结构和文件树。 创建一个空文件夹blog：$ mkdir blog 在终端使用命令安装Hexo：$ npm install -g hexo-cli 初始化Hexo：$ hexo init 查看hexo生成的目录:$ cd blog$ ls &emsp;&emsp;了解Hexo的文件目录架构以及文件目录的作用，这是很有必要的，特别对于配置Hexo的一些信息，然后在结合Hexo的官网的配置说明，就可以配置成自己想要的。 123456789101112.├── .deploy #部署文件夹├── public #html源码，hexo g生成├── scaffolds #模板├── scripts #扩展脚本├── source #文章源码| ├── _drafts #草稿| └── _posts #文章├── themes #主题| ├── next #NexT主题├── _config.yml #博客配置└── package.json #应用程序数据 配置NexT主题&emsp;&emsp;在Hexo的官网可以找到许许多多的主题，寻找适合自己喜欢的主题，可以通过BashShell终端进行下载，也可以下载后解压到站点的主题文件夹下即可，然后打开站点的配置文件，搜索到theme将其值修改为自己下载的主题名即可。 在终端使用命令下载主题： 1$ git clone https://github.com/theme-next/hexo-theme-next themes/next ./blog/themes/ 修改配置文件_config.yml:$ vim _config.yml将theme的值由landscape修改为hexo-theme-next即可 &emsp;&emsp;了解NexT主题的文件目录架构以及文件目录的作用，这也是很有必要的，特别对于配置NexT主题的一些信息，然后在结合NexT主题的官网配置说明，就可以配置成自己想要的主题了。&emsp;&emsp;说明提示一点，NexT主题V7.3.0版本后，将以前版本的用户自定义配置custom的功能的路径修改了，在主题配置文件中的custom_file_path:这一段有说明。Define custom file paths. Create your custom files in site directory source/_data and uncomment needed files below. 1234567891011121314151617181920212223242526272829303132333435363738├── .github #github信息├── languages #多语言| ├── _en.yml #默认语言| └── zh-CN.yml #简体中文| └── zh-TW.yml #繁体中文├── layout #布局，根目录下的*.swig文件是对主页，分页，存档等的控制| ├── _custom #可以自定义的模板，覆盖原有模板| | ├── head.swig #文首样式| | ├── header.swig #头部样式| | ├── sidebar.swig #侧边栏样式| ├── _macro #可以自定义的模板，覆盖原有模板| | ├── post.swig #文章模板| | ├── reward.swig #打赏模板| | ├── sidebar.swig #侧边栏模板| ├── _partial #局部的布局| | ├── head #头部模板| | ├── search #搜索模板| | ├── share #分享模板| ├── _script #局部的布局| ├── _third-party #第三方模板| ├── _layout.swig #主页面模板| ├── index.swig #主页面模板| ├── page #页面模板| └── tag.swig #tag模板├── scripts #script源码| ├── tags #tags的script源码| ├── marge.js #页面模板├── source #源码| ├── css #css源码| | ├── _common #*.styl基础css| | ├── _custom #*.styl自定义局部css| | └── _mixins #mixins的css| ├── fonts #字体| ├── images #图片| ├── js #javascript源代码| └── lib #引用库├── _config.yml #主题配置文件└── README.md #说明文件 配置GitHub的Page：&emsp;&emsp;首先要有一个GitHub账号，其次创建一个规定的GitHubPages主页仓库。然后就可以对站点的配置文件进行修改了，添加如下内容即可。而且不仅可以使用GitHub的Pages进行托管，也可以使用国内的Coding的Pages进行托管，同时也可以使用两者进行负载均衡，进行国内外的分流托管。 修改配置文件_config：在文件末尾的deploy添加内容： 123456deploy: type: git repo: git@github.com:github_user/github_user.github.io.git git@git.coding.net:coding_user/coding_user.git branch: master 写博客文章&emsp;&emsp;编写自己的博客文章(采用markdown格式)，可以在终端采用Vim进行编写，也可以用Notepad++类似的编辑器编写，只要博客文章所在的路径是正确的，就可以被Hexo识别并读取到即可。 在终端命令创建文章：$ hexo new file_name 使用Vim等编辑器编辑文章 更新Hexo并上传&emsp;&emsp;在更新上传之前可以在本地进行预览一下，即就是先清除clean、生成generate、然后start启动本地，在本地的4000端口查看即可。没有问题后，在进行上传deploy。当然这些常用的命令都是可以编写一个shell脚本进行的，因为每次都需要的，强烈建议写成一个shell脚本。 在终端依次使用命令： 1234$ hexo clean # 清理hexo的缓存静态文件资源$ hexo g # hexo生成静态资源$ hexo s # hexo启动本地访问$ hexo d # hexo上传指定的网站 终端访问&emsp;&emsp;通过PC端浏览器或者智能终端浏览器访问即可。 本地访问：http://localhost:4000 访问地址：https://2694048168.github.io 注意说明 在Windows系统下，终端采用GitBash即可 在Linux系统下，终端采用自带的Bash即可 Linux系统用户需要注意命令的权限问题 在Mac系统下，终端采用自带的Bash即可 整个操作过程全部都在blog目录下，注意操作命令的路径问题 博客文章格式采用Markdown hexo s 命令是启动本地hexo，访问通过http://localhost:4000 关于github的page详情查看：github.pages]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
        <tag>GitHub</tag>
      </tags>
  </entry>
</search>
