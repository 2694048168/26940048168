<!DOCTYPE html><html class="theme-next pisces" lang="zh-CN"><head><meta charset="UTF-8"><meta name="generator" content="Hexo 3.9.0"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=2"><meta name="theme-color" content="#222"><meta http-equiv="X-UA-Compatible" content="IE=edge"><link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=7.3.0"><link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=7.3.0"><link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=7.3.0"><link rel="mask-icon" href="/images/logo.svg?v=7.3.0" color="#222"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><meta name="google-site-verification" content=""><meta name="baidu-site-verification" content="8gbQ8pd371"><link rel="stylesheet" href="/css/main.css?v=7.3.0"><link rel="stylesheet" href="//cdn.jsdelivr.net/npm/font-awesome@4/css/font-awesome.min.css"><link rel="stylesheet" href="//cdn.jsdelivr.net/gh/theme-next/theme-next-needmoreshare2@1/needsharebutton.min.css"><script src="//cdn.jsdelivr.net/npm/pace-js@1/pace.min.js"></script><link rel="stylesheet" href="//cdn.jsdelivr.net/npm/pace-js@1/themes/blue/pace-theme-minimal.css"><script id="hexo-configurations">var NexT=window.NexT||{},CONFIG={root:"/",scheme:"Pisces",version:"7.3.0",exturl:!0,sidebar:{position:"right",display:"post",offset:12,onmobile:!1},back2top:{enable:!0,sidebar:!0,scrollpercent:!0},save_scroll:!0,copycode:{enable:!0,show_result:!1,style:null},fancybox:!1,mediumzoom:!1,lazyload:!1,pangu:!1,algolia:{applicationID:"",apiKey:"",indexName:"",hits:{per_page:10},labels:{input_placeholder:"Search for Posts",hits_empty:"We didn't find any results for the search: ${query}",hits_stats:"${hits} results found in ${time} ms"}},localsearch:{enable:!0,trigger:"auto",top_n_per_article:-1,unescape:!1,preload:!0},path:"search.xml",motion:{enable:!1,async:!1,transition:{post_block:"fadeIn",post_header:"slideDownIn",post_body:"slideDownIn",coll_header:"slideLeftIn",sidebar:"slideUpIn"}},translation:{copy_button:"复制",copy_success:"复制成功",copy_failure:"复制失败"}}</script><meta name="description" content="11 Important Model Evaluation Metrics for Machine Learning Everyone should knowOverview Evaluating a model is a core part of building an effective machine learning model There are several evaluation m"><meta name="keywords" content="MachineLearning"><meta property="og:type" content="article"><meta property="og:title" content="ErrorMetrics"><meta property="og:url" content="https://2694048168.github.io/ErrorMetrics/index.html"><meta property="og:site_name" content="云主宰苍穹"><meta property="og:description" content="11 Important Model Evaluation Metrics for Machine Learning Everyone should knowOverview Evaluating a model is a core part of building an effective machine learning model There are several evaluation m"><meta property="og:locale" content="zh-CN"><meta property="og:image" content="https://2694048168.github.io/images/confusion_matrix.png"><meta property="og:image" content="https://2694048168.github.io/images/confusion_matrix1.png"><meta property="og:image" content="https://2694048168.github.io/images/screenshot.png"><meta property="og:image" content="https://2694048168.github.io/images/screenshot1.png"><meta property="og:image" content="https://2694048168.github.io/images/LiftnGain.png"><meta property="og:image" content="https://2694048168.github.io/images/CumGain.png"><meta property="og:image" content="https://2694048168.github.io/images/Lift.png"><meta property="og:image" content="https://2694048168.github.io/images/Liftdecile.png"><meta property="og:image" content="https://2694048168.github.io/images/KS.png"><meta property="og:image" content="https://2694048168.github.io/images/KS_plot.png"><meta property="og:image" content="https://2694048168.github.io/images/confusion_matrix.png"><meta property="og:image" content="https://2694048168.github.io/images/curves.png"><meta property="og:image" content="https://2694048168.github.io/images/ROC.png"><meta property="og:image" content="https://2694048168.github.io/images/Confusion_matrix2.png"><meta property="og:image" content="https://2694048168.github.io/images/Screenshot-PM.png"><meta property="og:image" content="https://2694048168.github.io/ErrorMetrics/images/log-loss-curve.png"><meta property="og:image" content="https://2694048168.github.io/images/rmse.png"><meta property="og:image" content="https://2694048168.github.io/images/Screenshot-rmse.png"><meta property="og:image" content="https://2694048168.github.io/images/Screenshot2.png"><meta property="og:image" content="https://2694048168.github.io/images/Screenshot3.png"><meta property="og:image" content="https://2694048168.github.io/images/Screenshot4.png"><meta property="og:image" content="https://2694048168.github.io/images/kagglescores.png"><meta property="og:image" content="https://2694048168.github.io/images/validation.png"><meta property="og:image" content="https://2694048168.github.io/images/kfolds.png"><meta property="og:updated_time" content="2020-08-16T16:19:58.316Z"><meta name="twitter:card" content="summary"><meta name="twitter:title" content="ErrorMetrics"><meta name="twitter:description" content="11 Important Model Evaluation Metrics for Machine Learning Everyone should knowOverview Evaluating a model is a core part of building an effective machine learning model There are several evaluation m"><meta name="twitter:image" content="https://2694048168.github.io/images/confusion_matrix.png"><link rel="alternate" href="/atom.xml" title="云主宰苍穹" type="application/atom+xml"><link rel="canonical" href="https://2694048168.github.io/ErrorMetrics/"><script id="page-configurations">CONFIG.page={sidebar:"",isHome:!1,isPost:!0,isPage:!1,isArchive:!1}</script><title>ErrorMetrics | 云主宰苍穹</title><noscript><style>.sidebar-inner,.use-motion .brand,.use-motion .collection-title,.use-motion .comments,.use-motion .menu-item,.use-motion .motion-element,.use-motion .pagination,.use-motion .post-block,.use-motion .post-body,.use-motion .post-header{opacity:initial}.use-motion .logo,.use-motion .site-subtitle,.use-motion .site-title{opacity:initial;top:initial}.use-motion .logo-line-before i{left:initial}.use-motion .logo-line-after i{right:initial}</style></noscript></head><body itemscope itemtype="http://schema.org/WebPage" lang="zh-CN"><div class="container sidebar-position-right"><div class="headband"></div><header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="header-inner"><div class="site-brand-wrapper"><div class="site-meta"><div class="custom-logo-site-title"><a href="/" class="brand" rel="start"><span class="logo-line-before"><i></i></span> <span class="site-title">云主宰苍穹</span><span class="logo-line-after"><i></i></span></a></div><h1 class="site-subtitle" itemprop="description">Stay Hungry, Stay Foolish.</h1></div><div class="site-nav-toggle"> <button aria-label="切换导航栏"><span class="btn-bar"></span><span class="btn-bar"></span><span class="btn-bar"></span></button></div></div><nav class="site-nav"><ul id="menu" class="menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i><br>首页</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="menu-item-icon fa fa-fw fa-user"></i><br>关于</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="menu-item-icon fa fa-fw fa-tags"></i><br>标签</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="menu-item-icon fa fa-fw fa-th"></i><br>分类</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i><br>归档</a></li><li class="menu-item menu-item-commonweal"><a href="/404/" rel="section"><i class="menu-item-icon fa fa-fw fa-heartbeat"></i><br>公益 404</a></li><li class="menu-item menu-item-search"><a href="javascript:;" class="popup-trigger"><i class="menu-item-icon fa fa-search fa-fw"></i><br>搜索</a></li></ul><div class="site-search"><div class="popup search-popup local-search-popup"><div class="local-search-header clearfix"><span class="search-icon"><i class="fa fa-search"></i></span><span class="popup-btn-close"><i class="fa fa-times-circle"></i></span><div class="local-search-input-wrapper"> <input autocomplete="off" placeholder="搜索..." spellcheck="false" type="text" id="local-search-input"></div></div><div id="local-search-result"></div></div></div></nav></div></header> <span class="exturl github-corner" data-url="aHR0cHM6Ly9naXRodWIuY29tLzI2OTQwNDgxNjg=" title="Follow me on GitHub" aria-label="Follow me on GitHub"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0 0 115 115 130 115 142 142 250 250 250 0Z"></path><path d="M128.3 109C113.8 99.7 119 89.6 119 89.6 122 82.7 120.5 78.6 120.5 78.6 119.2 72 123.4 76.3 123.4 76.3 127.3 80.9 125.5 87.3 125.5 87.3 122.9 97.6 130.6 101.9 134.4 103.2" fill="currentColor" style="transform-origin:130px 106px" class="octo-arm"></path><path d="M115 115C114.9 115.1 118.7 116.5 119.8 115.4L133.7 101.6C136.9 99.2 139.9 98.4 142.2 98.6 133.8 88 127.5 74.4 143.8 58 148.5 53.4 154 51.2 159.7 51 160.3 49.4 163.2 43.6 171.4 40.1 171.4 40.1 176.1 42.5 178.8 56.2 183.1 58.6 187.2 61.8 190.9 65.4 194.5 69 197.7 73.2 200.1 77.6 213.8 80.2 216.3 84.9 216.3 84.9 212.7 93.1 206.9 96 205.4 96.6 205.1 102.4 203 107.8 198.3 112.5 181.9 128.9 168.3 122.5 157.7 114.1 157.9 116.9 156.7 120.9 152.7 124.9L141 136.5C139.8 137.7 141.6 141.9 141.8 141.8Z" fill="currentColor" class="octo-body"></path></svg></span><main id="main" class="main"><div class="main-inner"><div class="content-wrap"><div id="content" class="content page-post-detail"><div id="posts" class="posts-expand"><article class="post post-type-normal" itemscope itemtype="http://schema.org/Article"><div class="post-block"><link itemprop="mainEntityOfPage" href="https://2694048168.github.io/ErrorMetrics/"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="name" content="云主宰苍穹"><meta itemprop="description" content="云主宰苍穹,物联网,计算机视觉、图形处理、深度学习、人工智能、机器学习"><meta itemprop="image" content="/images/liwei.jpg"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="云主宰苍穹"></span><header class="post-header"><h2 class="post-title" itemprop="name headline">ErrorMetrics</h2><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="fa fa-calendar-o"></i></span> <span class="post-meta-item-text">发表于</span> <time title="创建时间：2020-07-21 14:05:13" itemprop="dateCreated datePublished" datetime="2020-07-21T14:05:13+08:00">2020-07-21</time></span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="fa fa-calendar-check-o"></i></span> <span class="post-meta-item-text">更新于</span> <time title="修改时间：2020-08-17 00:19:58" itemprop="dateModified" datetime="2020-08-17T00:19:58+08:00">2020-08-17</time></span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="fa fa-folder-o"></i></span> <span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Artificial-Intelligence/" itemprop="url" rel="index"><span itemprop="name">Artificial Intelligence</span></a></span></span><br><span class="post-meta-item" title="本文字数"><span class="post-meta-item-icon"><i class="fa fa-file-word-o"></i></span> <span class="post-meta-item-text">本文字数：</span> <span>26k</span></span><span class="post-meta-item" title="阅读时长"><span class="post-meta-item-icon"><i class="fa fa-clock-o"></i></span> <span class="post-meta-item-text">阅读时长 &asymp;</span> <span>23 分钟</span></span></div></header><div class="post-body" itemprop="articleBody"><h1 id="11-Important-Model-Evaluation-Metrics-for-Machine-Learning-Everyone-should-know"><a href="#11-Important-Model-Evaluation-Metrics-for-Machine-Learning-Everyone-should-know" class="headerlink" title="11 Important Model Evaluation Metrics for Machine Learning Everyone should know"></a>11 Important Model Evaluation Metrics for Machine Learning Everyone should know</h1><h1 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h1><ul><li>Evaluating a model is a core part of building an effective machine learning model</li><li>There are several evaluation metrics, like confusion matrix, cross-validation, AUC-ROC curve, etc.</li><li>Different evaluation metrics are used for different kinds of problems</li></ul><h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>The idea of building machine learning models works on a constructive feedback principle. You build a model, get feedback from metrics, make improvements and continue until you achieve a desirable accuracy. Evaluation metrics explain the performance of a model. An important aspect of evaluation metrics is their capability to discriminate among model results.</p><p>I have seen plenty of analysts and aspiring data scientists not even bothering to check how robust their model is. Once they are finished building a model, they hurriedly map predicted values on unseen data. This is an incorrect approach.</p><p>Simply building a predictive model is not your motive. It’s about creating and selecting a model which gives high accuracy on out of sample data. Hence, it is crucial to check the accuracy of your model prior to computing predicted values.</p><p>In our industry, we consider different kinds of metrics to evaluate our models. The choice of metric completely depends on the type of model and the implementation plan of the model.</p><p>After you are finished building your model, these 11 metrics will help you in evaluating your model’s accuracy. Considering the rising popularity and importance of cross-validation, I’ve also mentioned its principles in this article.</p><p>And if you’re starting out your machine learning journey, you should check out the comprehensive and popular ‘Applied Machine Learning’ course which covers this concept in a lot of detail along with the various algorithms and components of machine learning.</p><h1 id="Table-of-Contents"><a href="#Table-of-Contents" class="headerlink" title="Table of Contents"></a>Table of Contents</h1><ol><li>Confusion Matrix</li><li>F1 Score</li><li>Gain and Lift Charts</li><li>Kolmogorov Smirnov Chart</li><li>AUC – ROC</li><li>Log Loss</li><li>Gini Coefficient</li><li>Concordant – Discordant Ratio</li><li>Root Mean Squared Error</li><li>Cross Validation (Not a metric though!)</li></ol><h1 id="Warming-up-Types-of-Predictive-models"><a href="#Warming-up-Types-of-Predictive-models" class="headerlink" title="Warming up: Types of Predictive models"></a>Warming up: Types of Predictive models</h1><p>When we talk about predictive models, we are talking either about a regression model (continuous output) or a classification model (nominal or binary output). The evaluation metrics used in each of these models are different.</p><p>In classification problems, we use two types of algorithms (dependent on the kind of output it creates):</p><ol><li>Class output: Algorithms like SVM and KNN create a class output. For instance, in a binary classification problem, the outputs will be either 0 or 1. However, today we have algorithms which can convert these class outputs to probability. But these algorithms are not well accepted by the statistics community.</li><li>Probability output: Algorithms like Logistic Regression, Random Forest, Gradient Boosting, Adaboost etc. give probability outputs. Converting probability outputs to class output is just a matter of creating a threshold probability.</li></ol><p>In regression problems, we do not have such inconsistencies in output. The output is always continuous in nature and requires no further treatment.</p><h2 id="Illustrative-Example"><a href="#Illustrative-Example" class="headerlink" title="Illustrative Example"></a>Illustrative Example</h2><p>For a classification model evaluation metric discussion, I have used my predictions for the problem BCI challenge on Kaggle. The solution of the problem is out of the scope of our discussion here. However the final predictions on the training set have been used for this article. The predictions made for this problem were probability outputs which have been converted to class outputs assuming a threshold of 0.5.</p><h1 id="1-Confusion-Matrix"><a href="#1-Confusion-Matrix" class="headerlink" title="1. Confusion Matrix"></a>1. Confusion Matrix</h1><p>A confusion matrix is an N X N matrix, where N is the number of classes being predicted. For the problem in hand, we have N=2, and hence we get a 2 X 2 matrix. Here are a few definitions, you need to remember for a confusion matrix :</p><ul><li>Accuracy : the proportion of the total number of predictions that were correct.</li><li>Positive Predictive Value or Precision : the proportion of positive cases that were correctly identified.</li><li>Negative Predictive Value : the proportion of negative cases that were correctly identified.</li><li>Sensitivity or Recall : the proportion of actual positive cases which are correctly identified.</li><li>Specificity : the proportion of actual negative cases which are correctly identified.</li></ul><p><img src="/images/confusion_matrix.png" alt="confusion_matrix"></p><p><img src="/images/confusion_matrix1.png" alt="confusion_matrix"></p><p>The accuracy for the problem in hand comes out to be 88%. As you can see from the above two tables, the Positive predictive Value is high, but negative predictive value is quite low. Same holds for Sensitivity and Specificity. This is primarily driven by the threshold value we have chosen. If we decrease our threshold value, the two pairs of starkly different numbers will come closer.</p><p>In general we are concerned with one of the above defined metric. For instance, in a pharmaceutical company, they will be more concerned with minimal wrong positive diagnosis. Hence, they will be more concerned about high Specificity. On the other hand an attrition model will be more concerned with Sensitivity. Confusion matrix are generally used only with class output models.</p><h1 id="2-F1-Score"><a href="#2-F1-Score" class="headerlink" title="2. F1 Score"></a>2. F1 Score</h1><p>In the last section, we discussed precision and recall for classification problems and also highlighted the importance of choosing precision/recall basis our use case. What if for a use case, we are trying to get the best precision and recall at the same time? F1-Score is the harmonic mean of precision and recall values for a classification problem. The formula for F1-Score is as follows:</p><p><img src="/images/screenshot.png" alt="screenshot"></p><p>Now, an obvious question that comes to mind is why are taking a harmonic mean and not an arithmetic mean. This is because HM punishes extreme values more. Let us understand this with an example. We have a binary classification model with the following results:</p><p>Precision: 0, Recall: 1</p><p>Here, if we take the arithmetic mean, we get 0.5. It is clear that the above result comes from a dumb classifier which just ignores the input and just predicts one of the classes as output. Now, if we were to take HM, we will get 0 which is accurate as this model is useless for all purposes.</p><p>This seems simple. There are situations however for which a data scientist would like to give a percentage more importance/weight to either precision or recall. Altering the above expression a bit such that we can include an adjustable parameter beta for this purpose, we get:</p><p><img src="/images/screenshot1.png" alt="screenshot1"></p><p>Fbeta measures the effectiveness of a model with respect to a user who attaches β times as much importance to recall as precision.</p><h1 id="3-Gain-and-Lift-charts"><a href="#3-Gain-and-Lift-charts" class="headerlink" title="3. Gain and Lift charts"></a>3. Gain and Lift charts</h1><p>Gain and Lift chart are mainly concerned to check the rank ordering of the probabilities. Here are the steps to build a Lift/Gain chart:</p><p>Step 1 : Calculate probability for each observation</p><p>Step 2 : Rank these probabilities in decreasing order.</p><p>Step 3 : Build deciles with each group having almost 10% of the observations.</p><p>Step 4 : Calculate the response rate at each deciles for Good (Responders) ,Bad (Non-responders) and total.</p><p>You will get following table from which you need to plot Gain/Lift charts:</p><p><img src="/images/LiftnGain.png" alt="LiftnGain"></p><p>This is a very informative table. Cumulative Gain chart is the graph between Cumulative %Right and Cummulative %Population. For the case in hand here is the graph :</p><p><img src="/images/CumGain.png" alt="CumGain"></p><p>This graph tells you how well is your model segregating responders from non-responders. For example, the first decile however has 10% of the population, has 14% of responders. This means we have a 140% lift at first decile.</p><p>What is the maximum lift we could have reached in first decile? From the first table of this article, we know that the total number of responders are 3850. Also the first decile will contains 543 observations. Hence, the maximum lift at first decile could have been 543/3850 ~ 14.1%. Hence, we are quite close to perfection with this model.</p><p>Let’s now plot the lift curve. Lift curve is the plot between total lift and %population. Note that for a random model, this always stays flat at 100%. Here is the plot for the case in hand :</p><p><img src="/images/Lift.png" alt="Lift"></p><p>You can also plot decile wise lift with decile number :</p><p><img src="/images/Liftdecile.png" alt="Liftdecile"></p><p>What does this graph tell you? It tells you that our model does well till the 7th decile. Post which every decile will be skewed towards non-responders. Any model with lift @ decile above 100% till minimum 3rd decile and maximum 7th decile is a good model. Else you might consider over sampling first.</p><p>Lift / Gain charts are widely used in campaign targeting problems. This tells us till which decile can we target customers for an specific campaign. Also, it tells you how much response do you expect from the new target base.</p><h1 id="4-Kolomogorov-Smirnov-chart"><a href="#4-Kolomogorov-Smirnov-chart" class="headerlink" title="4. Kolomogorov Smirnov chart"></a>4. Kolomogorov Smirnov chart</h1><p>K-S or Kolmogorov-Smirnov chart measures performance of classification models. More accurately, K-S is a measure of the degree of separation between the positive and negative distributions. The K-S is 100, if the scores partition the population into two separate groups in which one group contains all the positives and the other all the negatives.</p><p>On the other hand, If the model cannot differentiate between positives and negatives, then it is as if the model selects cases randomly from the population. The K-S would be 0. In most classification models the K-S will fall between 0 and 100, and that the higher the value the better the model is at separating the positive from negative cases.</p><p>For the case in hand, following is the table :</p><p><img src="/images/KS.png" alt="KS"></p><p>We can also plot the %Cumulative Good and Bad to see the maximum separation. Following is a sample plot :</p><p><img src="/images/KS_plot.png" alt="KS_plot"></p><p>The metrics covered till here are mostly used in classification problems. Till here, we learnt about confusion matrix, lift and gain chart and kolmogorov-smirnov chart. Let’s proceed and learn few more important metrics.</p><h1 id="5-Area-Under-the-ROC-curve-AUC-–-ROC"><a href="#5-Area-Under-the-ROC-curve-AUC-–-ROC" class="headerlink" title="5. Area Under the ROC curve (AUC – ROC)"></a>5. Area Under the ROC curve (AUC – ROC)</h1><p>This is again one of the popular metrics used in the industry. The biggest advantage of using ROC curve is that it is independent of the change in proportion of responders. This statement will get clearer in the following sections.</p><p>Let’s first try to understand what is ROC (Receiver operating characteristic) curve. If we look at the confusion matrix below, we observe that for a probabilistic model, we get different value for each metric.</p><p><img src="/images/confusion_matrix.png" alt="confusion_matrix"></p><p>Hence, for each sensitivity, we get a different specificity.The two vary as follows:</p><p><img src="/images/curves.png" alt="curves"></p><p>The ROC curve is the plot between sensitivity and (1- specificity). (1- specificity) is also known as false positive rate and sensitivity is also known as True Positive rate. Following is the ROC curve for the case in hand.</p><p><img src="/images/ROC.png" alt="ROC"></p><p>Let’s take an example of threshold = 0.5 (refer to confusion matrix). Here is the confusion matrix :</p><p><img src="/images/Confusion_matrix2.png" alt="Confusion_matrix2"></p><p>As you can see, the sensitivity at this threshold is 99.6% and the (1-specificity) is ~60%. This coordinate becomes on point in our ROC curve. To bring this curve down to a single number, we find the area under this curve (AUC).</p><p>Note that the area of entire square is 1*1 = 1. Hence AUC itself is the ratio under the curve and the total area. For the case in hand, we get AUC ROC as 96.4%. Following are a few thumb rules:</p><ul><li>.90-1 = excellent (A)</li><li>.80-.90 = good (B)</li><li>.70-.80 = fair (C)</li><li>.60-.70 = poor (D)</li><li>.50-.60 = fail (F)</li></ul><p>We see that we fall under the excellent band for the current model. But this might simply be over-fitting. In such cases it becomes very important to to in-time and out-of-time validations.</p><p>Points to Remember:</p><ol><li><p>For a model which gives class as output, will be represented as a single point in ROC plot.</p></li><li><p>Such models cannot be compared with each other as the judgement needs to be taken on a single metric and not using multiple metrics. For instance, model with parameters (0.2,0.8) and model with parameter (0.8,0.2) can be coming out of the same model, hence these metrics should not be directly compared.</p></li><li><p>In case of probabilistic model, we were fortunate enough to get a single number which was AUC-ROC. But still, we need to look at the entire curve to make conclusive decisions. It is also possible that one model performs better in some region and other performs better in other.</p></li></ol><h2 id="Advantages-of-using-ROC"><a href="#Advantages-of-using-ROC" class="headerlink" title="Advantages of using ROC"></a>Advantages of using ROC</h2><p>Why should you use ROC and not metrics like lift curve?</p><p>Lift is dependent on total response rate of the population. Hence, if the response rate of the population changes, the same model will give a different lift chart. A solution to this concern can be true lift chart (finding the ratio of lift and perfect model lift at each decile). But such ratio rarely makes sense for the business.</p><p>ROC curve on the other hand is almost independent of the response rate. This is because it has the two axis coming out from columnar calculations of confusion matrix. The numerator and denominator of both x and y axis will change on similar scale in case of response rate shift.</p><h1 id="6-Log-Loss"><a href="#6-Log-Loss" class="headerlink" title="6. Log Loss"></a>6. Log Loss</h1><p>AUC ROC considers the predicted probabilities for determining our model’s performance. However, there is an issue with AUC ROC, it only takes into account the order of probabilities and hence it does not take into account the model’s capability to predict higher probability for samples more likely to be positive. In that case, we could us the log loss which is nothing but negative average of the log of corrected predicted probabilities for each instance.</p><p><img src="/images/Screenshot-PM.png" alt="Screenshot-PM"></p><ul><li>p(yi) is predicted probability of positive class</li><li>1-p(yi) is predicted probability of negative class</li><li>yi = 1 for positive class and 0 for negative class (actual values)</li></ul><p>Let us calculate log loss for a few random values to get the gist of the above mathematical function:</p><p>Logloss(1, 0.1) = 2.303</p><p>Logloss(1, 0.5) = 0.693</p><p>Logloss(1, 0.9) = 0.105</p><p>If we plot this relationship, we will get a curve as follows:</p><p><img src="images/log-loss-curve.png" alt="log-loss-curve"></p><p>It’s apparent from the gentle downward slope towards the right that the Log Loss gradually declines as the predicted probability improves. Moving in the opposite direction though, the Log Loss ramps up very rapidly as the predicted probability approaches 0.</p><p>So, lower the log loss, better the model. However, there is no absolute measure on a good log loss and it is use-case/application dependent.</p><p>Whereas the AUC is computed with regards to binary classification with a varying decision threshold, log loss actually takes “certainty” of classification into account.</p><h1 id="7-Gini-Coefficient"><a href="#7-Gini-Coefficient" class="headerlink" title="7. Gini Coefficient"></a>7. Gini Coefficient</h1><p>Gini coefficient is sometimes used in classification problems. Gini coefficient can be straigh away derived from the AUC ROC number. Gini is nothing but ratio between area between the ROC curve and the diagnol line &amp; the area of the above triangle. Following is the formulae used :</p><p>Gini = 2*AUC – 1</p><p>Gini above 60% is a good model. For the case in hand we get Gini as 92.7%.</p><h1 id="8-Concordant-–-Discordant-ratio"><a href="#8-Concordant-–-Discordant-ratio" class="headerlink" title="8. Concordant – Discordant ratio"></a>8. Concordant – Discordant ratio</h1><p>This is again one of the most important metric for any classification predictions problem. To understand this let’s assume we have 3 students who have some likelihood to pass this year. Following are our predictions :</p><center>A – 0.9</center><center>B – 0.5</center><center>C – 0.3</center><p>Now picture this. if we were to fetch pairs of two from these three student, how many pairs will we have? We will have 3 pairs : AB , BC, CA. Now, after the year ends we saw that A and C passed this year while B failed. No, we choose all the pairs where we will find one responder and other non-responder. How many such pairs do we have?</p><p>We have two pairs AB and BC. Now for each of the 2 pairs, the concordant pair is where the probability of responder was higher than non-responder. Whereas discordant pair is where the vice-versa holds true. In case both the probabilities were equal, we say its a tie. Let’s see what happens in our case :</p><center>AB – Concordant</center><center>BC – Discordant</center><p>Hence, we have 50% of concordant cases in this example. Concordant ratio of more than 60% is considered to be a good model. This metric generally is not used when deciding how many customer to target etc. It is primarily used to access the model’s predictive power. For decisions like how many to target are again taken by KS / Lift charts.</p><h1 id="9-Root-Mean-Squared-Error-RMSE"><a href="#9-Root-Mean-Squared-Error-RMSE" class="headerlink" title="9. Root Mean Squared Error (RMSE)"></a>9. Root Mean Squared Error (RMSE)</h1><p>RMSE is the most popular evaluation metric used in regression problems. It follows an assumption that error are unbiased and follow a normal distribution. Here are the key points to consider on RMSE:</p><ol><li>The power of ‘square root’ empowers this metric to show large number deviations.</li><li>The ‘squared’ nature of this metric helps to deliver more robust results which prevents cancelling the positive and negative error values. In other words, this metric aptly displays the plausible magnitude of error term.</li><li>It avoids the use of absolute error values which is highly undesirable in mathematical calculations.</li><li>When we have more samples, reconstructing the error distribution using RMSE is considered to be more reliable.</li><li>RMSE is highly affected by outlier values. Hence, make sure you’ve removed outliers from your data set prior to using this metric.</li><li>As compared to mean absolute error, RMSE gives higher weightage and punishes large errors.</li></ol><p>RMSE metric is given by:</p><p><img src="/images/rmse.png" alt="rmse"></p><p>where, N is Total Number of Observations.</p><h1 id="10-Root-Mean-Squared-Logarithmic-Error"><a href="#10-Root-Mean-Squared-Logarithmic-Error" class="headerlink" title="10. Root Mean Squared Logarithmic Error"></a>10. Root Mean Squared Logarithmic Error</h1><p>In case of Root mean squared logarithmic error, we take the log of the predictions and actual values. So basically, what changes are the variance that we are measuring. RMSLE is usually used when we don’t want to penalize huge differences in the predicted and the actual values when both predicted and true values are huge numbers.</p><p><img src="/images/Screenshot-rmse.png" alt="Screenshot-rmse"></p><ol><li>If both predicted and actual values are small: RMSE and RMSLE are same.</li><li>If either predicted or the actual value is big: RMSE &gt; RMSLE</li><li>If both predicted and actual values are big: RMSE &gt; RMSLE (RMSLE becomes almost negligible)</li></ol><h1 id="11-R-Squared-Adjusted-R-Squared"><a href="#11-R-Squared-Adjusted-R-Squared" class="headerlink" title="11. R-Squared/Adjusted R-Squared"></a>11. R-Squared/Adjusted R-Squared</h1><p>We learned that when the RMSE decreases, the model’s performance will improve. But these values alone are not intuitive.</p><p>In the case of a classification problem, if the model has an accuracy of 0.8, we could gauge how good our model is against a random model, which has an accuracy of 0.5. So the random model can be treated as a benchmark. But when we talk about the RMSE metrics, we do not have a benchmark to compare.</p><p>This is where we can use R-Squared metric. The formula for R-Squared is as follows:</p><p><img src="/images/Screenshot2.png" alt="Screenshot2"></p><p><img src="/images/Screenshot3.png" alt="Screenshot3"></p><p>MSE(model): Mean Squared Error of the predictions against the actual values</p><p>MSE(baseline): Mean Squared Error of mean prediction against the actual values</p><p>In other words how good our regression model as compared to a very simple model that just predicts the mean value of target from the train set as predictions.</p><h2 id="Adjusted-R-Squared"><a href="#Adjusted-R-Squared" class="headerlink" title="Adjusted R-Squared"></a>Adjusted R-Squared</h2><p>A model performing equal to baseline would give R-Squared as 0. Better the model, higher the r2 value. The best model with all correct predictions would give R-Squared as 1. However, on adding new features to the model, the R-Squared value either increases or remains the same. R-Squared does not penalize for adding features that add no value to the model. So an improved version over the R-Squared is the adjusted R-Squared. The formula for adjusted R-Squared is given by:</p><p><img src="/images/Screenshot4.png" alt="Screenshot4"></p><p>k: number of features</p><p>n: number of samples</p><p>As you can see, this metric takes the number of features into account. When we add more features, the term in the denominator n-(k +1) decreases, so the whole expression increases.</p><p>If R-Squared does not increase, that means the feature added isn’t valuable for our model. So overall we subtract a greater value from 1 and adjusted r2, in turn, would decrease.</p><p>Beyond these 11 metrics, there is another method to check the model performance. These 7 methods are statistically prominent in data science. But, with arrival of machine learning, we are now blessed with more robust methods of model selection. Yes! I’m talking about Cross Validation.</p><p>Though, cross validation isn’t a really an evaluation metric which is used openly to communicate model accuracy. But, the result of cross validation provides good enough intuitive result to generalize the performance of a model.</p><p>Let’s now understand cross validation in detail.</p><h1 id="12-Cross-Validation"><a href="#12-Cross-Validation" class="headerlink" title="12. Cross Validation"></a>12. Cross Validation</h1><p>Let’s first understand the importance of cross validation. Due to busy schedules, these days I don’t get much time to participate in data science competitions. Long time back, I participated in TFI Competition on Kaggle. Without delving into my competition performance, I would like to show you the dissimilarity between my public and private leaderboard score.</p><p><strong>Here is an example of scoring on Kaggle!</strong></p><p>For TFI competition, following were three of my solution and scores (Lesser the better) :</p><p><img src="/images/kagglescores.png" alt="kagglescores"></p><p>You will notice that the third entry which has the worst Public score turned to be the best model on Private ranking. There were more than 20 models above the “submission_all.csv”, but I still chose “submission_all.csv” as my final entry (which really worked out well). What caused this phenomenon ? The dissimilarity in my public and private leaderboard is caused by over-fitting.</p><p>Over-fitting is nothing but when you model become highly complex that it starts capturing noise also. This ‘noise’ adds no value to model, but only inaccuracy.</p><p>In the following section, I will discuss how you can know if a solution is an over-fit or not before we actually know the test results.</p><h2 id="The-concept-Cross-Validation"><a href="#The-concept-Cross-Validation" class="headerlink" title="The concept : Cross Validation"></a>The concept : Cross Validation</h2><p>Cross Validation is one of the most important concepts in any type of data modelling. It simply says, try to leave a sample on which you do not train the model and test the model on this sample before finalizing the model.</p><p><img src="/images/validation.png" alt="validation"></p><p>Above diagram shows how to validate model with in-time sample. We simply divide the population into 2 samples, and build model on one sample. Rest of the population is used for in-time validation.</p><p>Could there be a negative side of the above approach?</p><p>I believe, a negative side of this approach is that we loose a good amount of data from training the model. Hence, the model is very high bias. And this won’t give best estimate for the coefficients. So what’s the next best option?</p><p>What if, we make a 50:50 split of training population and the train on first 50 and validate on rest 50. Then, we train on the other 50, test on first 50. This way we train the model on the entire population, however on 50% in one go. This reduces bias because of sample selection to some extent but gives a smaller sample to train the model on. This approach is known as 2-fold cross validation.</p><h2 id="k-fold-Cross-validation"><a href="#k-fold-Cross-validation" class="headerlink" title="k-fold Cross validation"></a>k-fold Cross validation</h2><p>Let’s extrapolate the last example to k-fold from 2-fold cross validation. Now, we will try to visualize how does a k-fold validation work.</p><p><img src="/images/kfolds.png" alt="kfolds"></p><p>This is a 7-fold cross validation.</p><p>Here’s what goes on behind the scene : we divide the entire population into 7 equal samples. Now we train models on 6 samples (Green boxes) and validate on 1 sample (grey box). Then, at the second iteration we train the model with a different sample held as validation. In 7 iterations, we have basically built model on each sample and held each of them as validation. This is a way to reduce the selection bias and reduce the variance in prediction power. Once we have all the 7 models, we take average of the error terms to find which of the models is best.</p><p><strong>How does this help to find best (non over-fit) model?</strong></p><p>k-fold cross validation is widely used to check whether a model is an overfit or not. If the performance metrics at each of the k times modelling are close to each other and the mean of metric is highest. In a Kaggle competition, you might rely more on the cross validation score and not on the Kaggle public score. This way you will be sure that the Public score is not just by chance.</p><p><strong>How do we implement k-fold with any model?</strong></p><p>Coding k-fold in R and Python are very similar. Here is how you code a k-fold in Python :</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#Simple K-Fold cross validation. 5 folds. </span></span><br><span class="line"><span class="comment">#(Note: in older scikit-learn versions the "n_folds" argument is named "k".) </span></span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> cross_validation </span><br><span class="line">model = RandomForestClassifier(n_estimators=<span class="number">100</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># "model" can be replaced by your model object </span></span><br><span class="line"><span class="comment"># "Error_function" can be replaced by the error function of your analysis for traincv, testcv in cv: </span></span><br><span class="line">cv = cross_validation.KFold(len(train), n_folds=<span class="number">5</span>, indices=<span class="literal">False</span>) </span><br><span class="line">results = [] </span><br><span class="line"></span><br><span class="line"><span class="comment">#print out the mean of the cross-validated results          </span></span><br><span class="line">probas = model.fit(train[traincv], target[traincv]).predict_proba(train[testcv])             results.append( Error_function ) </span><br><span class="line"></span><br><span class="line">print(<span class="string">"Results: "</span> + str( np.array(results).mean() ))</span><br></pre></td></tr></table></figure><p><strong>But how do we choose k?</strong></p><p>This is the tricky part. We have a trade off to choose k.</p><p>For a small k, we have a higher selection bias but low variance in the performances.</p><p>For a large k, we have a small selection bias but high variance in the performances.</p><p>Think of extreme cases :</p><p>k = 2 : We have only 2 samples similar to our 50-50 example. Here we build model only on 50% of the population each time. But as the validation is a significant population, the variance of validation performance is minimal.</p><p>k = number of observations (n) : This is also known as “Leave one out”. We have n samples and modelling repeated n number of times leaving only one observation out for cross validation. Hence, the selection bias is minimal but the variance of validation performance is very large.</p><p>Generally a value of k = 10 is recommended for most purpose.</p><h1 id="End-Notes"><a href="#End-Notes" class="headerlink" title="End Notes"></a>End Notes</h1><p>Measuring the performance on training sample is point less. And leaving a in-time validation batch aside is a waste of data. K-Fold gives us a way to use every singe datapoint which can reduce this selection bias to a good extent. Also, K-fold cross validation can be used with any modelling technique.</p><p>In addition, the metrics covered in this article are some of the most used metrics of evaluation in a classification and regression problems.</p><p>Which metric do you often use in classification and regression problem ? Have you used k-fold cross validation before for any kind of analysis? Did you see any significant benefits against using a batch validation? Do let us know your thoughts about this guide in the comments section below.</p></div><div class="popular-posts-header">相关文章</div><ul class="popular-posts"><li class="popular-posts-item"><div class="popular-posts-title"><a href="\深度学习环境搭建详细教程\" rel="bookmark">深度学习环境搭建详细教程</a></div></li><li class="popular-posts-item"><div class="popular-posts-title"><a href="\机器学习项目清单\" rel="bookmark">机器学习项目清单</a></div></li><li class="popular-posts-item"><div class="popular-posts-title"><a href="\机器学习算法工作流程简述\" rel="bookmark">机器学习算法工作流程简述</a></div></li></ul><div><div><div style="text-align:center;color:#ccc;font-size:14px">-------------本文结束<i class="fa fa-paw"></i>感谢您的阅读，欢迎分享！-------------</div></div></div><div><div class="my_post_copyright"><script src="//cdn.bootcss.com/clipboard.js/1.5.10/clipboard.min.js"></script><script type="text/javascript" src="http://jslibs.wuxubj.cn/sweetalert_mini/jquery-1.7.1.min.js"></script><script src="http://jslibs.wuxubj.cn/sweetalert_mini/sweetalert.min.js"></script><link rel="stylesheet" type="text/css" href="http://jslibs.wuxubj.cn/sweetalert_mini/sweetalert.mini.css"><p><span>本文标题:</span>ErrorMetrics</p><p><span>文章作者:</span>云主宰苍穹</p><p><span>原始链接:</span><a href="/ErrorMetrics/" title="ErrorMetrics">https://2694048168.github.io/ErrorMetrics/</a><span class="copy-path" title="点击复制文章链接"><i class="fa fa-clipboard" data-clipboard-text="https://2694048168.github.io/ErrorMetrics/" aria-label="复制成功！"></i></span></p><p><span>许可协议:</span><i class="fa fa-creative-commons"></i> <a rel="license" href="https://creativecommons.org/licenses/by-nc-nd/4.0/" target="_blank" title="Attribution-NonCommercial-NoDerivatives 4.0 International (CC BY-NC-ND 4.0)">署名-非商业性使用-禁止演绎 4.0 国际</a> 转载请保留原文链接及作者。</p></div><script>var clipboard=new Clipboard(".fa-clipboard");clipboard.on("success",$(function(){$(".fa-clipboard").click(function(){swal({title:"",text:"复制成功",html:!1,timer:500,showConfirmButton:!1})})}))</script></div><div id="reward-container"><div></div> <button id="reward-button" disable="enable" onclick="var qr = document.getElementById(&quot;qr&quot;); qr.style.display = (qr.style.display === 'none') ? 'block' : 'none';"> 打赏</button><div id="qr" style="display:none"><div style="display:inline-block"> <img src="/images/wechatpay.png" alt="云主宰苍穹 微信支付"><p>微信支付</p></div><div style="display:inline-block"> <img src="/images/alipay.png" alt="云主宰苍穹 支付宝"><p>支付宝</p></div></div></div><footer class="post-footer"><div class="post-tags"> <a href="/tags/MachineLearning/" rel="tag"># MachineLearning</a></div><div class="post-widgets"><div class="social-share"><div id="needsharebutton-postbottom"><span class="btn"><i class="fa fa-share-alt" aria-hidden="true"></i></span></div></div></div><div class="post-nav"><div class="post-nav-next post-nav-item"><a href="/深度学习环境搭建详细教程/" rel="next" title="深度学习环境搭建详细教程"><i class="fa fa-chevron-left"></i> 深度学习环境搭建详细教程</a></div><span class="post-nav-divider"></span><div class="post-nav-prev post-nav-item"> <a href="/OpenCV源码编译/" rel="prev" title="OpenCV源码编译">OpenCV源码编译<i class="fa fa-chevron-right"></i></a></div></div></footer></div></article></div></div><div class="comments" id="gitalk-container"></div></div><div class="sidebar-toggle"><div class="sidebar-toggle-line-wrap"><span class="sidebar-toggle-line sidebar-toggle-line-first"></span><span class="sidebar-toggle-line sidebar-toggle-line-middle"></span><span class="sidebar-toggle-line sidebar-toggle-line-last"></span></div></div><aside id="sidebar" class="sidebar"><div class="sidebar-inner"><ul class="sidebar-nav motion-element"><li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap"> 文章目录</li><li class="sidebar-nav-overview" data-target="site-overview-wrap"> 站点概览</li></ul><div class="site-overview-wrap sidebar-panel"><div class="site-overview"><div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person"> <img class="site-author-image" itemprop="image" src="/images/liwei.jpg" alt="云主宰苍穹"><p class="site-author-name" itemprop="name">云主宰苍穹</p><div class="site-description motion-element" itemprop="description">云主宰苍穹,物联网,计算机视觉、图形处理、深度学习、人工智能、机器学习</div></div><nav class="site-state motion-element"><div class="site-state-item site-state-posts"> <a href="/archives/"><span class="site-state-item-count">42</span> <span class="site-state-item-name">日志</span></a></div><div class="site-state-item site-state-categories"> <a href="/categories/"><span class="site-state-item-count">10</span> <span class="site-state-item-name">分类</span></a></div><div class="site-state-item site-state-tags"> <a href="/tags/"><span class="site-state-item-count">30</span> <span class="site-state-item-name">标签</span></a></div></nav><div class="feed-link motion-element"><a href="/atom.xml" rel="alternate"><i class="fa fa-rss"></i> RSS</a></div><div class="links-of-author motion-element"><span class="links-of-author-item"><span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tLzI2OTQwNDgxNjgv" title="GitHub &rarr; https://github.com/2694048168/"><i class="fa fa-fw fa-github"></i> GitHub</span></span><span class="links-of-author-item"><span class="exturl" data-url="aHR0cHM6Ly93ZWliby5jb20vNTk2MzU1MzMwOS8=" title="Weibo &rarr; https://weibo.com/5963553309/"><i class="fa fa-fw fa-weibo"></i> Weibo</span></span></div><div class="links-of-blogroll motion-element links-of-blogroll-block"><div class="links-of-blogroll-title"><i class="fa fa-fw fa-link"></i> Links</div><ul class="links-of-blogroll-list"><li class="links-of-blogroll-item"> <span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tLzI2OTQwNDgxNjgv" title="https://github.com/2694048168/">github</span></li><li class="links-of-blogroll-item"> <span class="exturl" data-url="aHR0cHM6Ly9naXRlZS5jb20vd2VpbGlfeXp6Y3Ev" title="https://gitee.com/weili_yzzcq/">gitee</span></li><li class="links-of-blogroll-item"> <span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80Njc4MjIxOC8=" title="https://blog.csdn.net/weixin_46782218/">csdn</span></li><li class="links-of-blogroll-item"> <span class="exturl" data-url="aHR0cHM6Ly9zcGFjZS5iaWxpYmlsaS5jb20vMzYyOTAxODc3Lw==" title="https://space.bilibili.com/362901877/">bilibili</span></li><li class="links-of-blogroll-item"> <span class="exturl" data-url="aHR0cHM6Ly9hdXRob3IuYmFpZHUuY29tL2hvbWUvMTYyMzY0NDY2NjE2MjYwMS8=" title="https://author.baidu.com/home/1623644666162601/">百家号-专注物联网知识</span></li><li class="links-of-blogroll-item"> <span class="exturl" data-url="aHR0cHM6Ly93d3cudG91dGlhby5jb20vYy91c2VyLzIwMDk1NDExMTY2OTkwNzkv" title="https://www.toutiao.com/c/user/2009541116699079/">头条号-专注物联网知识</span></li></ul></div></div></div><div class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active"><div class="post-toc"><div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#11-Important-Model-Evaluation-Metrics-for-Machine-Learning-Everyone-should-know"><span class="nav-number">1.</span> <span class="nav-text">11 Important Model Evaluation Metrics for Machine Learning Everyone should know</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Overview"><span class="nav-number">2.</span> <span class="nav-text">Overview</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Introduction"><span class="nav-number">3.</span> <span class="nav-text">Introduction</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Table-of-Contents"><span class="nav-number">4.</span> <span class="nav-text">Table of Contents</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Warming-up-Types-of-Predictive-models"><span class="nav-number">5.</span> <span class="nav-text">Warming up: Types of Predictive models</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Illustrative-Example"><span class="nav-number">5.1.</span> <span class="nav-text">Illustrative Example</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#1-Confusion-Matrix"><span class="nav-number">6.</span> <span class="nav-text">1. Confusion Matrix</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#2-F1-Score"><span class="nav-number">7.</span> <span class="nav-text">2. F1 Score</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#3-Gain-and-Lift-charts"><span class="nav-number">8.</span> <span class="nav-text">3. Gain and Lift charts</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#4-Kolomogorov-Smirnov-chart"><span class="nav-number">9.</span> <span class="nav-text">4. Kolomogorov Smirnov chart</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#5-Area-Under-the-ROC-curve-AUC-–-ROC"><span class="nav-number">10.</span> <span class="nav-text">5. Area Under the ROC curve (AUC – ROC)</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Advantages-of-using-ROC"><span class="nav-number">10.1.</span> <span class="nav-text">Advantages of using ROC</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#6-Log-Loss"><span class="nav-number">11.</span> <span class="nav-text">6. Log Loss</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#7-Gini-Coefficient"><span class="nav-number">12.</span> <span class="nav-text">7. Gini Coefficient</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#8-Concordant-–-Discordant-ratio"><span class="nav-number">13.</span> <span class="nav-text">8. Concordant – Discordant ratio</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#9-Root-Mean-Squared-Error-RMSE"><span class="nav-number">14.</span> <span class="nav-text">9. Root Mean Squared Error (RMSE)</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#10-Root-Mean-Squared-Logarithmic-Error"><span class="nav-number">15.</span> <span class="nav-text">10. Root Mean Squared Logarithmic Error</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#11-R-Squared-Adjusted-R-Squared"><span class="nav-number">16.</span> <span class="nav-text">11. R-Squared/Adjusted R-Squared</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Adjusted-R-Squared"><span class="nav-number">16.1.</span> <span class="nav-text">Adjusted R-Squared</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#12-Cross-Validation"><span class="nav-number">17.</span> <span class="nav-text">12. Cross Validation</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#The-concept-Cross-Validation"><span class="nav-number">17.1.</span> <span class="nav-text">The concept : Cross Validation</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#k-fold-Cross-validation"><span class="nav-number">17.2.</span> <span class="nav-text">k-fold Cross validation</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#End-Notes"><span class="nav-number">18.</span> <span class="nav-text">End Notes</span></a></li></ol></div></div></div><div class="back-to-top motion-element"><i class="fa fa-arrow-up"></i> <span id="scrollpercent"><span>0</span>%</span></div></div></aside><div id="sidebar-dimmer"></div></div></main><footer id="footer" class="footer"><div class="footer-inner"><div class="copyright">&copy; 2019 – <span itemprop="copyrightYear">2020</span><span class="with-love" id="animate"><i class="fa fa-heartbeat"></i></span> <span class="author" itemprop="copyrightHolder">云主宰苍穹</span> <span class="post-meta-divider">|</span><span class="post-meta-item-icon"><i class="fa fa-area-chart"></i></span> <span class="post-meta-item-text">站点总字数：</span> <span title="站点总字数">209k</span> <span class="post-meta-divider">|</span><span class="post-meta-item-icon"><i class="fa fa-coffee"></i></span> <span class="post-meta-item-text">站点阅读时长 &asymp;</span> <span title="站点阅读时长">3:10</span></div><div class="powered-by">由 <span class="exturl theme-link" data-url="aHR0cHM6Ly9oZXhvLmlv">Hexo</span> 强力驱动 v3.9.0</div> <span class="post-meta-divider">|</span><div class="theme-info">主题 – <span class="exturl theme-link" data-url="aHR0cHM6Ly90aGVtZS1uZXh0Lm9yZw==">NexT.Pisces</span> v7.3.0</div><div class="busuanzi-count"><script async="" src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><span class="site-uv"><i class="fa fa-user"></i> 访问用户：<span class="busuanzi-value" id="busuanzi_value_site_uv"></span> 人</span><div class="powered-by"></div><span class="site-uv"><i class="fa fa-eye"></i> 访问次数：<span class="busuanzi-value" id="busuanzi_value_site_pv"></span> 次</span></div></div></footer><div id="needsharebutton-float"><span class="btn"><i class="fa fa-share-alt" aria-hidden="true"></i></span></div><script src="//cdn.jsdelivr.net/gh/theme-next/theme-next-needmoreshare2@1/needsharebutton.min.js"></script><script>pbOptions={iconStyle:"box",boxForm:"horizontal",position:"bottomCenter",networks:"Weibo,Wechat,Douban,QQZone,Twitter,Facebook"},new needShareButton("#needsharebutton-postbottom",pbOptions),flOptions={iconStyle:"box",boxForm:"horizontal",position:"middleRight",networks:"Weibo,Wechat,Douban,QQZone,Twitter,Facebook"},new needShareButton("#needsharebutton-float",flOptions)</script></div><script src="//cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script><script src="/js/utils.js?v=7.3.0"></script><script src="/js/affix.js?v=7.3.0"></script><script src="/js/schemes/pisces.js?v=7.3.0"></script><script src="/js/next-boot.js?v=7.3.0"></script><script>!function(){var t=document.createElement("script"),e=window.location.protocol.split(":")[0];t.src="https"===e?"https://zz.bdstatic.com/linksubmit/push.js":"http://push.zhanzhang.baidu.com/push.js";var s=document.getElementsByTagName("script")[0];s.parentNode.insertBefore(t,s)}()</script><script src="/js/local-search.js?v=7.3.0"></script><script src="/js/scrollspy.js?v=7.3.0"></script><script src="/js/post-details.js?v=7.3.0"></script><link rel="stylesheet" href="//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.css"><script>NexT.utils.getScript("//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js",function(){new Gitalk({clientID:"aebff323e44f1516e521",clientSecret:"3934128e2a234e13b6118386667dee31ab703836",repo:"2694048168.github.io",owner:"2694048168",admin:["2694048168"],id:"a07c1deb77ed936c1e6db488f3621383",language:"en | es-ES | fr | ru | zh-CN | zh-TW",distractionFreeMode:"true"}).render("gitalk-container")},window.Gitalk)</script></body></html>